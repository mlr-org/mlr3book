---
author:
  - name: Author 1
    orcid:
    email:
    affiliations:
      - name: Affiliation 1
  - name: Author 2
    orcid:
    email:
    affiliations:
      - name: Affiliation 2
abstract: TODO (150-200 WORDS)
---

# Implementing new classes {#sec-extending}

{{< include _setup.qmd >}}

Hopefully having read the rest of this book you are now an `r mlr3` expert.
Maybe you will even want to extend the universe with new classes for more learners, measures, tasks, pipelines, tuners, filters, or more; if so, read on.

{{< include _optional.qmd >}}

In this chapter we will cover how to extend the four basic classes of the `r mlr3` universe: `r ref("Learner")`, `r ref("Measure")`, `r ref("Task")`, and `r ref("Prediction")`.
We will start with extending learners (@sec-extending-learners) and measures (@sec-extending-measures) in the context of regression, but this extends to any other machine learning task.
We will then look at implementing new task (@sec-extending-tasks) and prediction objects (@sec-extending-predictions).
If you are interested in implementing new pipelines, tuners, feature selection methods, or filters, then check out the vignettes in the respective packages: `r mlr3pipelines`, `r mlr3tuning`, `r mlr3fselect`, or `r mlr3filters`.

We welcome contributions from all levels of developers and if you want to add any of your new classes to our universe then please either start a new repository if you are implementing a new machine learning task, or make pull requests to aligning packages, for example tuners and filters would go to `r mlr3tuning` and `r mlr3filters` respectively, a new survival measure would go to `r mlr3proba`, and *all* new learners go to `r mlr3extralearners`.
Do not worry if you make a PR to the wrong repository, we will transfer it to the right one.

## Extending `Learner` Class {#sec-extending-learners}

```{r extending-001, include = F}
library(mlr3)
library(mlr3book)
```

Although many learners are already included in the `r mlr3` ecosystem, there might be a situation in which your algorithm of choice is not implemented.
Here, we show how to create a custom mlr3learner step-by-step using `r ref("mlr3extralearners::create_learner")`.
If you intend to add a learner to mlr3extralearners, **it is strongly recommended** to **first** open a [learner request issue](https://github.com/mlr-org/mlr3extralearners/issues/new?assignees=&labels=new+learner&template=learner-request-template.md&title=%5BLRNRQ%5D+Add+%3Calgorithm%3E+from+package+%3Cpackage%3E) to inform the `r mlr3` team about your idea.
This allows to discuss the implementation details and potential peculiarities of the learner before putting actual work in.

This section gives insights on how a mlr3learner is constructed and how to troubleshoot issues.
See the [Learner FAQ subsection](#learner-faq) for help.

**Summary of steps for adding a new learner**

1. Check that the learner does not already exist [here](https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html).
1. [Install](#setup) `r mlr3extralearners` and if you want to create a PR, also [fork and clone](#setup) it.
1. [Run](#create-learner) `r ref("mlr3extralearners::create_learner()")`.
1. Add the learner's [`ParamSet`](#param-set).
1. Manually add [`.train`](#learner-train) and [`.predict`](#learner-predict) private methods to the learner.
1. Implement supported [optional extractors](#optional-extractors) and [hotstarting](#hotstarting) if applicable.
1. Fill out the missing parts in the learner's description.
   To add references you first need to create an entry in bibentries.R
1. Check that [unit tests](#learner-test) and [parameter tests](#learner-test) pass (these are automatically created).
1. Run [cleaning functions](#cleaning).
1. Open a [pull request](https://github.com/mlr-org/mlr3extralearners/pulls) with the "new learner" template.

:::{.callout-warning}
Do not copy/paste the code shown in this section.
Use `r ref("create_learner()")` to start.
:::

### Setting-up mlr3extralearners {#sec-setup}

In order to use `r ref("mlr3extralearners::create_learner")` you must have mlr3extralearners installed.
Note that mlr3extralearners is not on CRAN and has to be installed from GitHub.
To ensure that you have the latest version, run `remotes::install_github("mlr-org/mlr3extralearners")` before proceeding.

If you want to create a pull request to mlr3extralearners you also need to

1. [Fork](https://docs.github.com/en/free-pro-team@latest/github/getting-started-with-github/fork-a-repo) the [repository](https://github.com/mlr-org/mlr3extralearners)
2. [Clone](https://docs.github.com/en/free-pro-team@latest/github/creating-cloning-and-archiving-repositories/cloning-a-repository) a local copy of your forked repository.

### Calling create_learner {#sec-create-learner}

The learner `classif.rpart` will be used as a running example throughout this section.

```{r extending-002, eval = FALSE, tidy = FALSE}
library("mlr3extralearners")
create_learner(
  path = "path/to/a/folder",
  classname = "Rpart",
  type = "classif",
  key = "rpart",
  algorithm = "Decision Tree",
  package = "rpart",
  caller = "rpart",
  feature_types = c("logical", "integer", "numeric", "factor", "ordered"),
  predict_types = c("response", "prob"),
  properties = c("importance", "missings", "multiclass", "twoclass", "weights"),
  gh_name = "RaphaelS1",
  label = "Regression and Partition Tree",
  data_formats = "data.table"
)
```

The full documentation for the function arguments is in `r ref("mlr3extralearners::create_learner")`, in this example we are doing the following:

1. `path = "path/to/a/folder"` - This determines where the templates are being generated.
If the path is the root of an R package, the learner is created in the ./R directory and the test files in ./tests/testthat.
Otherwise, all files are being created in the folder pointed to by path.
Already existing files will not be modified.
1. `classname = "Rpart"` - Set the R6 class name to LearnerClassifRpart (classif is below)
1. `algorithm = "Decision Tree"` - Create the title as "Classification Decision Tree Learner", where "Classification" is determined automatically from `type` and "Learner" is added for all learners.
1. `type = "classif"` - Setting the learner as a classification learner, automatically filling the title, class name, id (`"classif.rpart"`) and task type.
1. `key = "rpart"` - Used with `type` to create the unique ID of the learner, `"classif.rpart"`.
1. `package = "rpart"` - Setting the package from which the learner is implemented, this fills in things like the training function (along with `caller`) and the `man` field.
1. `caller = "rpart"` - This tells the `.train` function, and the description which function is called to run the algorithm, with `package` this automatically fills `rpart::rpart`.
1. `feature_types = c("logical", "integer", "numeric", "factor", "ordered")` - Sets the type of features that can be handled by the learner. See [meta information](#learner-meta-information).
1. `predict_types = c("response", "prob"),` - Sets the available prediction types as response (pointwise prediction) and prob (probabilities). See [meta information](#learner-meta-information).
1. `properties = c("importance", "missings", "multiclass", "twoclass", "weights")` - Sets the properties the learner supports.
By including `"importance"` a public method called `importance` will be created that must be manually filled.
See [meta information](#learner-meta-information) and [optional extractors](#optional-extractors).
1. `gh_name = "RaphaelS1"` - Fills the '\@author' tag with my GitHub handle, this is required as it identifies the maintainer of the learner.

The sections below show an exemplary execution of `r ref("mlr3extralearners::create_learner")`.

### `learner_package_type_key.R`

The first generated file which must be updated after running `r ref("create_learner()")` is the one following the structure `learner_<package>_<type>_<key>.R`; in this example `learner_rpart_classif_rpart.R`.

For our example, the resulting script looks like this:

```{r extending-003, eval = FALSE, tidy = FALSE}
#' @title Classification Decision Tree Learner
#' @author RaphaelS1
#' @name mlr_learners_classif.rpart
#'
#' @description
#' FIXME: BRIEF DESCRIPTION OF THE LEARNER.
#' Calls [rpart::rpart()] from FIXME: (CRAN VS NO CRAN): \CRANpkg{rpart} | 'rpart'.
#'
#' @section Custom mlr3 parameters:
#' FIXME: DEVIATIONS FROM UPSTREAM PARAMETERS. DELETE IF NOT APPLICABLE.
#'
#' @section Custom mlr3 defaults:
#' FIXME: DEVIATIONS FROM UPSTREAM DEFAULTS. DELETE IF NOT APPLICABLE.
#'
#' @section Installation:
#' FIXME: CUSTOM INSTALLATION INSTRUCTIONS. DELETE IF NOT APPLICABLE.
#'
#' @templateVar id classif.rpart
#' @template learner
#'
#' @references
#' FIXME: ADD REFERENCES
#'
#' @template seealso_learner
#' @template example
#' @export
LearnerClassifRpart = R6Class("LearnerClassifRpart",
  inherit = LearnerClassif,
  public = list(
    #' @description
    #' Creates a new instance of this [R6][R6::R6Class] class.
    initialize = function() {
      # FIXME: MANUALLY ADD PARAMETERS BELOW AND THEN DELETE THIS LINE
      param_set = ps()

      # FIXME: MANUALLY UPDATE PARAM VALUES BELOW IF APPLICABLE THEN DELETE THIS LINE.
      param_set$values = list()

      super$initialize(
        id = "classif.rpart",
        packages = "rpart",
        feature_types = c("logical", "integer", "numeric", "factor", "ordered"),
        predict_types = c("response", "prob"),
        param_set = param_set,
        properties = c("importance", "missings", "multiclass", "twoclass", "weights"),
        man = "mlr3extralearners::mlr_learners_classif.rpart",
        label = "Regression and Partition Tree"
      )
    },
    # FIXME: ADD IMPORTANCE METHOD IF APPLICABLE AND DELETE OTHERWISE
    # SEE mlr3extralearners::LearnerRegrRandomForest FOR AN EXAMPLE
    #' @description
    #' The importance scores are extracted from the slot FIXME:.
    #' @return Named `numeric()`.
    importance = function() {
      pars = self$param_set$get_values(tags = "importance")
      # FIXME: Implement importance
    }
  ),
  private = list(
    .train = function(task) {
      # get parameters for training
      pars = self$param_set$get_values(tags = "train")

      # FIXME: IF LEARNER DOES NOT HAVE 'weights' PROPERTY THEN DELETE THESE LINES.
      if ("weights" %in% task$properties) {
        # Add weights to learner
      }

      # FIXME: CREATE OBJECTS FOR THE TRAIN CALL
      # AT LEAST "data" AND "formula" ARE REQUIRED
      formula = task$formula()
      data = task$data()

      # FIXME: HERE IS SPACE FOR SOME CUSTOM ADJUSTMENTS BEFORE PROCEEDING TO THE
      # TRAIN CALL. CHECK OTHER LEARNERS FOR WHAT CAN BE DONE HERE
      # USE THE mlr3misc::invoke FUNCTION (IT'S SIMILAR TO do.call())

      invoke(
        rpart::rpart,
        formula = formula,
        data = data,
        .args = pars
      )
    },
    .predict = function(task) {
      # get parameters with tag "predict"
      pars = self$param_set$get_values(tags = "predict")

      # get newdata and ensure same ordering in train and predict
      newdata = ordered_features(task, self)

      # Calculate predictions for the selected predict type.
      type = self$predict_type

      pred = invoke(predict, self$model, newdata = newdata, type = type, .args = pars)

      # FIXME: ADD PREDICTIONS TO LIST BELOW
      list()
    }
  )
)

.extralrns_dict$add("classif.rpart", LearnerClassifRpart)
```

Now we have to do the following (the description will be addressed later):

1. Add the learner's parameters to the [ParamSet](#param-set).
1. Optionally [change default values](#param-set) for the parameters.
1. Fill in the private [`.train`](#learner-train) method, which takes a (filtered) `r ref("Task")` and returns a model.
1. Fill in the private [`.predict`](#learner-predict) method, which operates on the model in `self$model` (stored during `$train()`) and a (differently subsetted) `r ref("Task")` to return a named list of predictions.
1. As we included "importance" in `properties`, we have to add the public method `importance()` which returns a named numeric vectors with the decreasingly sorted importance scores (values) for the different features (names).

### Meta-information {#sec-learner-meta-information}

In the constructor (`initialize()`) the constructor of the super class (e.g. `r ref("LearnerClassif")`) is called with meta information about the learner which should be constructed.
This includes:

* `id`: The ID of the new learner. Usually consists of `<type>.<key>`, for example: `"classif.rpart"`.
* `packages`: The upstream package name(s) of the implemented learner.
* `param_set`: A set of hyperparameters and their descriptions provided as a `r ref("paradox::ParamSet")`.
  For each hyperparameter the appropriate class needs to be chosen. When using the `r ref("paradox::ps")` shortcut, a short constructor of the form `p_***` can be used:
  * `r ref("paradox::ParamLgl")` / [`paradox::p_lgl`](https://paradox.mlr-org.com/reference/Domain.html) for scalar logical hyperparameters.
  * `r ref("paradox::ParamInt")` / [`paradox::p_int`](https://paradox.mlr-org.com/reference/Domain.html) for scalar integer hyperparameters.
  * `r ref("paradox::ParamDbl")` / [`paradox::p_dbl`](https://paradox.mlr-org.com/reference/Domain.html) for scalar numeric hyperparameters.
  * `r ref("paradox::ParamFct")` / [`paradox::p_fct`](https://paradox.mlr-org.com/reference/Domain.html) for scalar factor hyperparameters (this includes characters).
  * `r ref("paradox::ParamUty")` / [`paradox::p_uty`](https://paradox.mlr-org.com/reference/Domain.html) for everything else (e.g. vector paramters or list parameters).
* `predict_types`: Set of predict types the learner supports.
  These differ depending on the type of the learner. See `r ref("mlr_reflections", text = "mlr_reflections$learner_predict_types")` for the full list of predict types supported by `r mlr3`.
  * `r ref("LearnerClassif")`
    * `response`: Only predicts a class label for each observation.
    * `prob`: Also predicts the posterior probability for each class for each observation.
  * `r ref("LearnerRegr")`
    * `response`: Only predicts a numeric response for each observation.
    * `se`: Also predicts the standard error for each value of response.
  * `r ref("LearnerSurv")`
    * `lp` - Linear predictor calculated as the fitted coefficients multiplied by the test data.
    * `distr` - Predicted survival distribution, either discrete or continuous.
      Implemented in `r ref_pkg("distr6")`.
    * `crank` - Continuous risk ranking.
    * `response` - Predicted survival time.
  * `r ref("LearnerDens")`
    * `pdf`- Predicts the probability density function.
    * `cdf` - Predicts the cumulative distribution function.
    * `distr` - Predicts a distribution as implemented in `r ref_pkg("distr6")`.
  * `r ref("LearnerClust")`
    * `partition` - Assigns the observation to a partition.
    * `prob` - Returns a probability for each partition.
* `feature_types`: Set of feature types the learner is able to handle.
  See `r ref("mlr_reflections", text = "mlr_reflections$task_feature_types")` for feature types supported by `r mlr3`.
* `properties`: Set of properties of the learner. See `r ref("mlr_reflections", text = "mlr_reflections$learner_properties")` for the full list of learner properties supported by `r mlr3`.
  The list of properties includes:
  * `"twoclass"`: The learner works on binary classification problems.
  * `"multiclass"`: The learner works on multi-class classification problems.
  * `"missings"`: The learner can natively handle missing values.
  * `"weights"`: The learner can work on tasks which have observation weights / case weights.
  * `"importance"`: The learner supports extracting importance values for features.
  * `"selected_features"`: The learner supports extracting the features which were selected by the model.
  * `"oob_error"`: The learner supports extracting the out of bag error.
  * `"loglik"`: The learner supports extracting the log-likelihood of the learner.
  * `"hotstart_forward"`: The learner allows to continue training the model e.g. by adding more trees to a random forest.
  * `"hotstart_backward"`: The learner allows to "undo" some of the training, e.g. by removing some trees from a model.
* `man`: The roxygen identifier of the learner.
  This is used within the `$help()` method of the super class to open the help page of the learner.
* `label`: The label of the learner.
  This should briefly describe the learner (similar to the description's title) and is for example used for printing.

### ParamSet {#sec-param-set}

The `ParamSet` is the set of hyperparameters used in model training and predicting, this is given as a `r ref("paradox::ParamSet")`.
The set consists of a list of hyperparameters, where each has a specific class for the hyperparameter type (see above).
In addition, each parameter has one or more tags, that determine in which method they are used.

Beyond that there are other tags that serve specific purposes:

* The tag `"threads"` should be used (if applicable) to tag the parameter that determines the number of threads used for the learner's internal parallelization.
  This parameter can be set using `r ref("set_threads")`.
* The tag `"required"` should be used to tag parameters that must be provided for the algorithm to be executable.
* In case [optional extractors](#optional-extractors) are available, the can (although this is rarely the case) also have parameters and can be tagged accordingly.
* If [hotstarting](#hotstarting) is available, the fidelity parameter should be tagged with `"hotstart"`.

For `classif.rpart` the `param_set` can be defined as follows

```{r extending-004, eval = FALSE}
param_set = ps(
  minsplit = p_int(lower = 1L, default = 20L, tags = "train"),
  minbucket = p_int(lower = 1L, tags = "train"),
  cp = p_dbl(lower = 0, upper = 1, default = 0.01, tags = "train"),
  maxcompete = p_int(lower = 0L, default = 4L, tags = "train"),
  maxsurrogate = p_int(lower = 0L, default = 5L, tags = "train"),
  maxdepth = p_int(lower = 1L, upper = 30L, default = 30L, tags = "train"),
  usesurrogate = p_int(lower = 0L, upper = 2L, default = 2L, tags = "train"),
  surrogatestyle = p_int(lower = 0L, upper = 1L, default = 0L, tags = "train"),
  xval = p_int(lower = 0L, default = 0L, tags = "train"),
  keep_model = p_lgl(default = FALSE, tags = "train")
)
param_set$values = list(xval = 0L)
```

Within `r mlr3` packages we suggest to stick to the shorthand notation above for consistency, however the `param_set` can be written with the underlying R6 classes as shown here

```{r extending-005, eval = FALSE}

param_set = ParamSet$new(list(
  ParamInt$new(id = "minsplit", default = 20L, lower = 1L, tags = "train"),
  ParamInt$new(id = "minbucket", lower = 1L, tags = "train"),
  ParamDbl$new(id = "cp", default = 0.01, lower = 0, upper = 1, tags = "train"),
  ParamInt$new(id = "maxcompete", default = 4L, lower = 0L, tags = "train"),
  ParamInt$new(id = "maxsurrogate", default = 5L, lower = 0L, tags = "train"),
  ParamInt$new(id = "maxdepth", default = 30L, lower = 1L, upper = 30L, tags = "train"),
  ParamInt$new(id = "usesurrogate", default = 2L, lower = 0L, upper = 2L, tags = "train"),
  ParamInt$new(id = "surrogatestyle", default = 0L, lower = 0L, upper = 1L, tags = "train"),
  ParamInt$new(id = "xval", default = 0L, lower = 0L, tags = "train"),
  ParamLgl$new(id = "keep_model", default = FALSE, tags = "train")
))
param_set$values = list(xval = 0L)
```

You should read though the learner documentation to find the full list of available parameters. Just looking at some of these in this example:

* `"cp"` is numeric, has a feasible range of `[0,1]` and defaults to `0.01`.
  The parameter is used during `"train"`.
* `"xval"` is integer has a lower bound of `0`, a default of `0` and the parameter is used during `"train"`.
* `"keep_model"` is logical with a default of `FALSE` and is used during `"train"`.

In some rare cases you may want to change the default parameter values.
You can do this by changing the `param_set$values`.
You can see we have done this for `"classif.rpart"` where the default for `xval` is changed to `0`.
Note that the default in the `r ref("ParamSet")` is recorded as our changed default (0), and not the original (10).
It is strongly recommended to only change the defaults if absolutely required, when this is the case add the following to the learner documentation:

```r
#' @section Custom mlr3 defaults:
#' - `<parameter>`:
#'   - Actual default: <value>
#'   - Adjusted default: <value>
#'   - Reason for change: <text>
```

### Train function {#sec-learner-train}

The train function takes a `r ref("Task")` as input and must return a model.
Let's say we want to translate the following call of `rpart::rpart()` into code that can be used inside the `.train()` method.

First, we write something down that works completely without `r mlr3`:

```{r extending-006,eval=TRUE}
data = iris
model = rpart::rpart(Species ~ ., data = iris, xval = 0)
```

We need to pass the formula notation `Species ~ .`, the data and the hyperparameters.
To get the hyperparameters, we call `self$param_set$get_values(tag = "train")` and thereby query all parameters that are using during `"train"`.
Then, the dataset is extracted from the `r ref("Task")`.
Because the learner has the property `"weights"`, we insert the weights of the task if there are any.

Last, we call the upstream function `rpart::rpart()` with the data and pass all hyperparameters via argument `.args` using the `r ref("mlr3misc::invoke()")` function.
The latter is simply an optimized version of `do.call()` that we use within the `r mlr3` ecosystem.

```{r extending-007,eval=TRUE}
.train = function(task) {
  pars = self$param_set$get_values(tags = "train")
  if ("weights" %in% task$properties) {
    pars$weights = task$weights$weight
  }
  formula = task$formula()
  data = task$data()
  invoke(
    rpart::rpart,
    formula = formula,
    data = data,
    .args = pars
  )
}
```

### Predict function {#sec-learner-predict}

The internal predict method `.predict()` also operates on a `r ref("Task")` as well as on the fitted model that has been created by the `train()` call previously and has been stored in `self$model`.

The return value is a `r ref("Prediction")` object.
We proceed analogously to what we did in the previous section.
We start with a version without any `r mlr3` objects and continue to replace objects until we have reached the desired interface:

```{r extending-008,eval=TRUE}
# inputs:
task = tsk("iris")
self = list(model = rpart::rpart(task$formula(), data = task$data()))

data = iris
response = predict(self$model, newdata = data, type = "class")
prob = predict(self$model, newdata = data, type = "prob")
```

The `"rpart::predict.rpart()"` function predicts class labels if argument `type` is set to to `"class"`, and class probabilities if set to `"prob"`.

Next, we transition from `data` to a `r ref("Task")` again and construct a list with the return type requested by the user, this is stored in the `$predict_type` slot of a learner class. Note that the `r ref("Task")` is automatically passed to the prediction object, so all you need to do is return the predictions! Make sure the list names are identical to the task predict types.

The final `.predict()` method is below, we could omit the `pars` line as there are no parameters with the `"predict"` tag but we keep it here to be consistent:

```{r extending-009, eval = TRUE}
.predict = function(task) {
  pars = self$param_set$get_values(tags = "predict")
  # get newdata and ensure same ordering in train and predict
  newdata = ordered_features(task, self)
  if (self$predict_type == "response") {
    response = invoke(
      predict,
      self$model,
      newdata = newdata,
      type = "class",
      .args = pars
    )

    return(list(response = response))
  } else {
    prob = invoke(
      predict,
      self$model,
      newdata = newdata,
      type = "prob",
      .args = pars
    )
    return(list(prob = prob))
  }
}
```

:::{.callout-warning}
You cannot rely on the column order of the data returned by `task$data()` as the order of columns may be different from the order of the columns during `$.train`.
The `newdata` line ensures the ordering is the same by calling the same order as in train!
:::

### Optional Extractors {#sec-optional-extractors}

Specific learner implementations are free to implement additional getters to ease the access of certain parts of the model in the inherited subclasses.
The blueprint for these methods is only included in the generated learner template, if the property is set when calling `create_learner()`.
The comments in the templates will include references to other learners that have this property and can be used as guiding examples.
To determine whether these methods are applicable, one has to determine whether the learner supports this method in principle **and** whether it is implemented in the upstream package.

For the following operations, extractors are standardized:

* `importance(...)` - Returns the feature importance score as numeric vector.
  The higher the score, the more important the variable.
  The returned vector is named with feature names and sorted in decreasing order.
  Note that the model might omit features it has not used at all. The learner must be tagged with property `"importance"`.
* `selected_features(...)` - Returns a subset of selected features as character().
  The learner must be tagged with property `"selected_features"`.
* `oob_error(...)` - Returns the out-of-bag error of the model as `numeric(1)`.
  The learner must be tagged with property `"oob_error"`.
* `loglik(...)` - Extracts the log-likelihood (c.f. `stats::logLik()`).
  The learner must be tagged with property `"loglik"`.

In this case, we only have to implement the `importance()` method.

```{r extending-010, eval = FALSE}
importance = function() {
  if (is.null(self$model)) {
    stopf("No model stored")
  }

  importance = sort(self$model$variable.importance, decreasing = TRUE)
  if (is.null(importance)) {
    importance = mlr3misc::set_names(numeric())
  }
  return(importance)
}
```

### Hotstarting  {#sec-hotstarting}

Some learners support resuming or continuing from an already fitted model.
We assume that hotstarting is only possible if a single hyperparameter (also called the fidelity parameter, usually controlling the complexity or expensiveness) is altered and all other hyperparameters are identical.
The fidelity parameters should be tagged with `"hotstart"`.
Examples are:

* Random Forest: Starting from a model with n trees, a random forest with n + k trees can be obtained by adding k trees (`"hotstart_forward"`) and a random forest with n - k trees can be obtained by removing k trees (`"hotstart_backward"`).
* Gradient Boosting: When having fitted a model with n iterations, we only need k iterations to obtain a model with n + k iterations. (`"hotstart_forward"`).

For more information see `r ref("HotstartStack")`.

### Control objects/functions of learners {#sec-learner-control}

Some learners rely on a "control" object/function such as `glmnet::glmnet.control()`.
Accounting for such depends on how the underlying package works:

* If the package forwards the control parameters via `...` and makes it possible to just pass control parameters as additional parameters directly to the train call, there is no need to distinguish both `"train"` and `"control"` parameters.
* If the control parameters need to be passed via a separate argument, one can e.g. use
  `formalArgs(glmnet::glmnet.control)` to get the names of the control parameters and then extract them from the `pars` like shown below.

```{r extending-011, eval = FALSE}
pars = self$param_set$get_values(tags = "train")
ii = names(pars) %in% formalArgs(glmnet::glmnet.control)
pars_ctrl = pars[ii]
pars_train = pars[!ii]

invoke([...], .args = pars_train, control = pars_ctrl)
```

### Adding the description

Once the learner is implemented - and is not only intended for personal use - it's description should be filled out.
Most steps should be clear from the instructions given in the template.
For the section '\@references', the entry first has to be added to the file `bibentries.R`, essentially by converting the bibtex file to a R `bibentry` function call.

### Testing the learner {#sec-learner-test}

Once your learner is created, you are ready to start testing if it works, there are three types of tests: [manual](#learner-test-manual), [unit](#learner-test-unit) and [parameter](#learner-test-parameter).

#### Train and Predict {#sec-learner-test-manual}

For a bare-bone check you can just try to run a simple `train()` call locally.

```{r extending-012, eval = FALSE}
task = tsk("iris") # assuming a Classif learner
lrn = lrn("classif.rpart")
lrn$train(task)
p = lrn$predict(task)
p$confusion
```

If it runs without erroring, that's a very good start!

#### Autotest {#sec-learner-test-unit}

To ensure that your learner is able to handle all kinds of different properties and feature types, we have written an "autotest" that checks the learner for different combinations of such.

The "autotest" setup is generated automatically by `r ref("create_learner()")`.
It will have a name with the form `test_package_type_key.R`, in our case this will actually be `test_rpart_classif_rpart.R`.
This will create the following script, for which no changes are required to pass (assuming the learner was correctly created):

```{r extending-013, eval = FALSE}
test_that("autotest", {
  learner = lrn("classif.rpart")
  expect_learner(learner)
  # note that you can skip tests using the exclude argument
  result = run_autotest(learner)
  expect_true(result, info = result$error)
})
```

For some learners that have required parameters, it is needed to set some values for required parameters after construction so that the learner can be run in the first place.

You can also exclude some specific test arrangements within the "autotest" via the argument `exclude` in the `run_autotest()` function.
Currently the `run_autotest()` function lives in [inst/testthat](https://github.com/mlr-org/mlr3/blob/f16326bf34bcac59c3b0a2fdbcf90dbebb3b4bbc/inst/testthat/helper_autotest.R) of the `r mlr3` and still lacks documentation.
This should change in the near future.

To finally run the test suite, call `devtools::test()` or hit `CTRL + Shift + T` if you are using RStudio.

#### Checking Parameters {#sec-learner-test-parameter}

Some learners have a high number of parameters and it is easy to miss out on some during the creation of a new learner.
In addition, if the maintainer of the upstream package changes something with respect to the arguments of the algorithm, the learner is in danger to break.
Also, new arguments could be added upstream and manually checking for new additions all the time is tedious.

Therefore we have written a "Parameter Check" that runs regularly for every learner.
This "Parameter Check" compares the parameters of the `r mlr3` ParamSet against all arguments available in the upstream function that is called during `$train()` and `$predict()`.
Again the file is automatically created by `r ref("create_learner()")`.
This will be named like `test_paramtest_package_type_key.R`, so in our example `test_paramtest_rpart_classif_rpart.R`.
When the `.train` function calls multiple functions (e.g. a control function as described above), a list of functions can be passed to the parameter test.

The test comes with an `exclude` argument that should be used to _exclude and explain_ why certain arguments of the upstream function are not within the ParamSet of the mlr3learner.
This will likely be required for all learners as common arguments like `x`, `target` or `data` are handled by the `r mlr3` interface and are therefore not included within the ParamSet.

However, there might be more parameters that need to be excluded, for example:

* Type dependent parameters, i.e. parameters that only apply for classification or regression learners.
* Parameters that are actually deprecated by the upstream package and which were therefore not included in the `r mlr3` ParamSet.

All excluded parameters should have a comment justifying their exclusion.

In our example, the final paramtest script looks like:

```{r extending-014, eval = FALSE}
test_that("classif.rpart train", {
  learner = lrn("classif.rpart")
  # this can also be a list of functions
  fun = rpart::rpart
  exclude = c(
    "formula", # handled internally
    "model", # handled internally
    "data", # handled internally
    "weights", # handled by task
    "subset", # handled by task
    "na.action", # handled internally
    "method", # handled internally
    "x", # handled internally
    "y", # handled internally
    "parms", # handled internally
    "control", # handled internally
    "cost" # handled internally
  )

  paramtest = run_paramtest(learner, fun, exclude, tag = "train")
  expect_paramtest(paramtest)
})

test_that("classif.rpart predict", {
  learner = lrn("classif.rpart")
  fun = rpart:::predict.rpart
  exclude = c(
    "object", # handled internally
    "newdata", # handled internally
    "type", # handled internally
    "na.action" # handled internally
  )

  paramtest = run_paramtest(learner, fun, exclude, tag = "predict")
  expect_paramtest(paramtest)
})
```

### Package Cleaning {#sec-cleaning}

Once all tests are passing, run the following functions to ensure that the package remains clean and tidy

1. `devtools::document(roclets = c('rd', 'collate', 'namespace'))`
1. If you haven't done this before run: `remotes::install_github('mlr-org/styler.mlr')`
1. `styler::style_pkg(style = styler.mlr::mlr_style)`
1. `usethis::use_tidy_description()`
1. `lintr::lint_package()`

Please fix any errors indicated by `lintr` before creating a pull request. Finally ensure that all `FIXME` are resolved and deleted in the generated files.

You are now ready to add your learner to the `r mlr3` ecosystem!
Simply open a pull request to \url{https://github.com/mlr-org/mlr3extralearners/pulls} with the new learner template and complete the checklist in there.
Creating this request will trigger an automated workflow that checks whether various conditions (such as `rcmdcheck::rcmdcheck()`) are satisfied.
Once the pull request is approved and merged, your learner will automatically appear on the [package website](https://mlr3extralearners.mlr-org.com/).

### Thanks and Maintenance

Thank you for contributing to the `r mlr3` ecosystem!

When you created the learner you would have given your GitHub handle, meaning that you are now listed as the learner author and maintainer. This means that if the learner breaks it is your responsibility to fix the learner - you can view the status of your learner [here](https://mlr3extralearners.mlr-org.com/articles/learners/test_overview.html).


### Learner FAQ {#sec-learner-faq}

**Question 1**

How to deal with Parameters which have no default?

**Answer**

If the learner does not work without providing a value, set a reasonable default in `param_set$values`, add tag `"required"` to the parameter and document your default properly.

**Question 2**

Where to add the package of the upstream package in the DESCRIPTION file?

Add it to the "Suggests" section.

**Question 3**

How to handle arguments from external "control" functions such as `glmnet::glmnet_control()`?

**Answer**

See ["Control objects/functions of learners"](#learner-control).

**Question 4**

How to document if my learner uses a custom default value that differs to the default of the upstream package?

**Answer**

If you set a custom default for the mlr3learner that does not cope with the one of the upstream package (think twice if this is really needed!), add this information to the help page of the respective learner.

You can use the following skeleton for this:

```r
#' @section Custom mlr3 defaults:
#' * `<parameter>`:
#'   * Actual default: <value>
#'   * Adjusted default: <value>
#'   * Reason for change: <text>
```

**Question 5**

When should the `"required"` tag be used when defining Params and what is its purpose?

**Answer**

The `"required"` tag should be used when the following conditions are met:

* The upstream function cannot be run without setting this parameter, i.e. it would throw an error.
* The parameter has no default in the upstream function.

In `r mlr3` we follow the principle that every learner should be constructable without setting custom parameters.
Therefore, if a parameter has no default in the upstream function, a custom value is usually set for this parameter in the mlr3learner (remember to document such changes in the help page of the learner).

Even though this practice ensures that no parameter is unset in an mlr3learner and partially removes the usefulness of the `"required"` tag, the tag is still useful in the following scenario:

If a user sets custom parameters after construction of the learner

```r
lrn = lrn("<id>")
lrn$param_set$values = list("<param>" = <value>)
```

Here, all parameters besides the ones set in the list would be unset.
See `paradox::ParamSet` for more information.
If a parameter is tagged as `"required"` in the ParamSet, the call above would error and prompt the user that required parameters are missing.

**Question 6**

What is this error when I run `devtools::load_all()`

```r
> devtools::load_all(".")
Loading mlr3extralearners
Warning message:
.onUnload failed in unloadNamespace() for 'mlr3extralearners', details:
  call: vapply(hooks, function(x) environment(x)$pkgname, NA_character_)
  error: values must be length 1,
 but FUN(X[[1]]) result is length 0
```

**Answer**

This is not an error but a warning and you can safely ignore it!

## Extending `Measure` Class {#sec-extending-measures}

We will now turn to extending the `r ref("Measure")` class to implement new metrics, again we will focus on regression.
As an example, let's consider the mean squared error defined by $f(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$ where $y$ is a vector of true observations and $\hat{y}$ are respective predictions.
In code this may be written as:

```{r extending-015}
mse = function(truth, response) mean((truth - response)^2)

mse(c(0, 0.5, 1), c(0.5, 0.5, 0.5))
```

As with extending learners, we now need to create a new `r ref("R6::R6Class")`, this time inheriting from `r ref("Measure")` and in this case specifically inheriting from `r ref("MeasureRegr")`.
We will once again show the final code and then explain each line, this can be used as a template for most performance measures.,

```{r extending-016}
MeasureRegrMSE = R6::R6Class("MeasureRegrMSE", # class name
  inherit = mlr3::MeasureRegr, # regression measure
  public = list(
    initialize = function() { # initialize class
      super$initialize(
        id = "mse", # unique ID
        packages = character(), # no dependencies
        properties = character(), #Â no special properties
        predict_type = "response", # measures response prediction
        range = c(0, Inf), # results in values between (0, Inf)
        minimize = TRUE # optimised at minimum
      )
    }
  ),

  private = list(
    .score = function(prediction, ...) { # define score as private method
      mse = function(truth, response) mean((truth - response)^2) # define loss
      mse(prediction$truth, prediction$response) # call loss function
    }
  )
)
```

1. In the first two lines we name the class, here "MeasureMSE", and then state this is a regression measure and inherits from `r ref("MeasureRegr")`.
2. We initialize the class by stating its unique ID is "mse", that it does not require any external packages (`packages = character()`) and that it has no special properties (`properties = character()`).
3. We then pass specific details of the loss function which are: it measures the quality of a "response" type prediction, its values range between (0, $\infty$), and that the loss is optimised as its minimum.
4. Finally we define the score itself as a private method called `.score` and simply pass the predictions to the function we defined earlier.

Sometimes measures require data from the training set, the task, or the learner.
These are usually complex edge-cases examples so we will not go into detail here, for working examples look at the code for `r ref("mlr3proba::MeasureSurvSongAUC")` and `r ref("mlr3proba::MeasureSurvAUC")`.

Once you have defined your measure you can either use it with the `R6` constructor, or by adding it to the `r ref("mlr_measures")` dictionary:

```{r}
library(mlr3verse)

t = tsk("mtcars")
l = lrn("regr.rpart")$train(t)$predict(t)
l$score(MeasureRegrMSE$new())

# or add to dictionary
mlr3::mlr_measures$add("regr.mse", MeasureRegrMSE)
l$score(msr("regr.mse"))
```

## Conclusion

In this final chapter we looked at how to implement new learners and measures using the language of `r mlr3`.
If you want to learn more about implementing new classes, we recommend familiarising yourself fully with `R6` and reading source code across different packages in the `mlr3verse`.
If you are struggling whilst implementing a new learner or measure, pleasr reach out and we would be very happy to help you.
If you are considering implementing a new machine learning task, please get in touch by email, GitHub, or Mattermost, and we would be happy to chat about your plans.

### Exercises

1. Implement your own version of a featureless classifier where all predictions are the majority class in the training dataset.
2. Implement your own version of the accuracy measure by $f(y, \hat{y}) = \frac{\mathbb{I}(y_i = \hat{y}_i)}{n}$ where $y$ is a vector of true observations and $\hat{y}$ are respective predictions of $n$ observations in the test set.
3. Set seed `42` then partition the `sonar` task using the default settings of `r ref("partition")`. Train the learner you implemented in question 1 on the training data and test it on the testing data. Score your predictions with the measure you created in question 2. Do your results match ours?
