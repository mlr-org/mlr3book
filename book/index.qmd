# Preamble {.unnumbered}
{{< include _setup.qmd >}}

```{r C0 seed}
set.seed(0)
```

Welcome to the Machine Learning in R 3 universe (mlr3verse), let us show you some of its magic.
Before we begin, make sure you have installed `r mlr3` if you want to follow along, we recommend installing the full universe at once:

```{r C0 install mlr3verse, eval = FALSE}
install.packages("mlr3verse")
```

You can also just install the base package:

```{r C0 install mlr3, eval = FALSE}
install.packages("mlr3")
```

In this first example we'll show you the most basic use-case, train and predict.

```{r C0 egBasic}
library("mlr3")
task = tsk("penguins")
split = partition(task)
learner = lrn("classif.rpart", predict_type = "prob")

learner$train(task, row_ids = split$train)
learner$model

predictions = learner$predict(task, row_ids = split$test)
predictions

predictions$score(msr("classif.acc"))
```

Here we have picked the 'penguins' task (which is `r mlr3` language for dataset), randomly split the task into 67% training data and 33% testing data, trained a random forest on the training data to learn the probability of an observation falling into one of the outcome classes, showed the fitted model, and then made prediction on the test data, showed these predictions and evaluated the model using the accuracy measure.

Whilst mlr3 makes training and predicting easy, it also uses a unified interface to perform some very complex operations in just a few lines of code:

```{r C0 egHard, output = FALSE}
library(mlr3verse)
library(mlr3pipelines)
library(mlr3benchmark)

tasks = tsks(c("breast_cancer", "sonar"))
tuned_rf = auto_tuner(
    tnr("grid_search", resolution = 5),
    lrn("classif.ranger", num.trees = to_tune(200, 500)),
    rsmp("holdout")
)
tuned_rf = pipeline_robustify(NULL, tuned_rf, TRUE) %>>%
    po("learner", tuned_rf)
stack_lrn = ppl(
    "stacking",
    base_learners = lrns(c("classif.rpart", "classif.kknn")),
    lrn("classif.log_reg"))
stack_lrn = pipeline_robustify(NULL, stack_lrn, TRUE) %>>%
    po("learner", stack_lrn)

learners = c(tuned_rf, stack_lrn)
bm = benchmark(benchmark_grid(tasks, learners, rsmp("holdout")))
```

```{r C0 egHardOut}
bma = bm$aggregate(msr("classif.acc"))[, c("task_id", "learner_id",
  "classif.acc")]
bma$learner_id = rep(c("RF", "Stack"), 2)
bma

as.BenchmarkAggr(bm)$friedman_test()
```

In this (much more complex!) example we picked two tasks, three machine learning algorithms ('learners'), and compared their performance. We demonstrated using automated tuning to optimise the number of trees in a random forest (Chapter 4), as well as pipelines to impute missing data, collapse factor levels and to create stacked models (Chapter 5). We also showed basic features like loading learners (Chapter 2) and picking resampling strategies for benchmarking (Chapter 3). Finally we compared the performance of the models using the sample mean and then use statistical tests to see if one model performed significantly better than another (they did not!).

You will learn all this and more by reading this book and we will take it slow to make sure you understand the components that make this universe run. There are a few different ways you can use this book and we will explain them in this preamble, as well as useful links, citaton information, and syntax. First, thank you for joining us on this journey, we hope you will love our software as much as we do.

## How to use this book {#howtouse}

The mlr3 ecosystem is the result of many years of 'traditional' scientific research as well as software research (design and implementation). This book reflects both types of work by showcasing features of the mlr3 universe as well as discussing best practices for machine learning, technical implementation details, extension guidelines, and in-depth considerations for optimising machine learning analysis. Therefore this book can be enjoyed by a wide range of readers at different levels and can be used in a few ways. We will discuss some of those here.

Chapters 1-3 cover the basics of mlr3. They will take you through loading the most important objects, training models and using them for new predictions, and evaluating predictions. In addition we discuss model comparison and resampling. These chapters are essential to understanding the core infrastrucure in mlr3. We recommend that all readers study these sections to get familiar with mlr terminology, syntax, and style.
Chapters 4-6 contain more advance implementation details as well as technical machine learning theory.
@sec-special delves into detail about domain-specific methods that are implemented in our extension packages. Readers may choose to selectively read sections in this chapter depending on your use-cases (i.e., if you have domain-specific problems to tackle), or to use these as introductions to new domains to explore.
@sec-technical contains technical implementation details that are essential reading for advanced users who require parallelisation, error handling, and fine control over hyperparameters and large databases.
Many readers will likely find that built-in model interpretability methods will fit the majority of needs, however readers that require more detailed methods for interpreting a model (for example those training deep neural networks or gradient boosting machines) will find @sec-interpretation very useful. Finally, anyone who would like to contribute to our ecosystem should read @sec-extending.

{{< include _complex.qmd >}}

Of course, you can also read the book chronologically, cover to cover from start to finish.
We have marked any section that contains complex technical information with this symbol: \emoji{warning}. You may wish to skip these sections if you are only interested in basic functionality.

{{< include _optional.qmd >}}

Similarly, we have marked sections that are optional, such as deep dives into machine learning theory, with this symbol: \emoji{sparkles}. Readers that are interested in the more technical detail will likely want to pay attention to the tables at the end of each chapter that show the relationship between our S3 'sugar' functions and the underlying R6 classes, this is explained in more detail in @sec-introduction.

This book tries to follow the Diátaxis framework for documentation and so we include tutorials, how-to guides, API references, and explanations. This means that the conclusion of each chapter includes a short reference to the core functions learnt in the chapter, links to relevant posts in the [mlr3gallery](https://mlr-org.com/gallery.html), as well as a few exercises that will cover content learnt in the chapter. You can find the solutions to these exercises in @sec-solutions.

Finally, if you want to reproduce any of the results in this book, firstly note the seed set at the top of each chapter (which are simply set as the chapter number) and the `sessionInfo` printed in @sec-session-info.

## Installation guidelines {#installguide}

All packages in the mlr3 ecosystem can be installed from GitHub and R-universe and the majority (but not all) can be installed from CRAN. We recommend adding the mlr-org R-universe[^runiverse] to your R options so that you can install all packages with `install.packages()` without having to worry whether it's being downloaded from CRAN or R-universe. To do this run the following:

[^runiverse]: R-universe is simply an alternative package repository to CRAN. The bit of code below tells R to look at R-universe, as well as CRAN, when trying to install packages. R will always install the latest version of a package.

```{r universe1, eval = FALSE}
usethis::edit_r_profile()
```

And in the file that opens add or change the `repos` argument in `options` so it looks something like this (you might need to add the full code block below or just edit the existing `options` function).

```{r universe2, eval = FALSE}
options(repos = c(
  mlrorg = "https://mlr-org.r-universe.dev",
  CRAN = "https://cloud.r-project.org/"
))
```

Save the file then restart your R session and you're ready to go!

```{r install verse, eval = FALSE}
install.packages("mlr3verse")
```

If you want latest development versions of any of our packages you can just run

```{r remotes, eval = FALSE}
remotes::install_github("mlr-org/{pkg}")
```

with `{pkg}` replaced by the package you want to install. You can see an up-to-date list of all our extension packages at [https://github.com/mlr-org/mlr3/wiki/Extension-Packages](https://github.com/mlr-org/mlr3/wiki/Extension-Packages).

## Community links

The mlr community is open to all and we welcome all people, from those completely new to machine learning and R up to advanced coders and data scientists. You can talk to us at anytime by joining our [Mattermost](https://lmmisld-lmu-stats-slds.srv.mwn.de/signup_email?id=6n7n67tdh7d4bnfxydqomjqspo).

For case-studies and how-to guides, check out [https://mlr-org.com/gallery.html](https://mlr-org.com/gallery.html) for extended practical blog posts. Or for mlr updates you might find our blog a useful point of reference [https://mlr-org.com/blog.html](https://mlr-org.com/blog.html).

We appreciate of all contributions to our codebase, whether they are bug reports, feature requests, or pull requests. Each of GitHub repositories includes issues and pull request templates to ensure we can help you as much as possible to work together. Please make sure you read our code of conduct and contribution guidelines to keep our community friendly and safe! With many packages in our universe it may be hard to keep track of where to open issues. As a general rule:

1. If you have a question about using any part of the mlr3 ecosystem then ask a question in [StackOverflow](https://stackoverflow.com/) and tag #mlr3 -- one of our team will answer you there. Be sure to include a reproducible example (reprex) and if we think you found a bug then we will transfer your question to the relevant GitHub repository.
1. Bug reports or pull requests about core functionality (train, predict, etc.) should be opened in the [mlr3](https://github.com/mlr3) GitHub repository.
1. Bug reports or pull requests about learners should be opened in the [mlr3extralearners](https://github.com/mlr3extralearners) GitHub repository.
1. Bug reports or pull requests about learners should be opened in the [mlr3measures](https://github.com/mlr3measures) GitHub repository.
1. Bug reports or pull requests about domain specific functionality should be opened in the GitHub repository of the respective package (see @sec-introduction).

Do not worry if you open an issue in the wrong place, we are happy to transfer it to the right one!

## Citation info {#citeus}

Every package in the mlr3verse has its own citation details that can be found on the respective GitHub repository.

To reference this book please use:

```
Becker M, Binder M, Bischl B, Foss N, Kotthoff L, Lang M, Pfisterer F,
Reich N G, Richter J, Schratz P, Sonabend R, Pulatov D.
`r strftime(Sys.Date(), "%Y")`. "{{< meta title >}}". https://mlr3book.mlr-org.com.
```

```
@misc{
    title = {{< meta title >}}
    author = {Marc Becker, Martin Binder, Bernd Bischl, Natalie Foss,
    Lars Kotthoff, Michel Lang, Florian Pfisterer, Nicholas G. Reich,
    Jakob Richter, Patrick Schratz, Raphael Sonabend, Damir Pulatov},
    url = {https://mlr3book.mlr-org.com},
    year = {`r strftime(Sys.Date(), "%Y")`}
}
```

To reference the `r mlr3` package, please cite our JOSS paper:

```
Lang M, Binder M, Richter J, Schratz P, Pfisterer F, Coors S, Au Q,
Casalicchio G, Kotthoff L, Bischl B (2019). “mlr3: A modern object-oriented
machine learning framework in R.” Journal of Open Source Software.
doi: 10.21105/joss.01903.

@Article{mlr3,
  title = {{mlr3}: A modern object-oriented machine learning framework in {R}},
  author = {Michel Lang and Martin Binder and Jakob Richter and Patrick Schratz and
  Florian Pfisterer and Stefan Coors and Quay Au and Giuseppe Casalicchio and
  Lars Kotthoff and Bernd Bischl},
  journal = {Journal of Open Source Software},
  year = {2019},
  month = {dec},
  doi = {10.21105/joss.01903},
  url = {https://joss.theoj.org/papers/10.21105/joss.01903},
}
```

## mlr3book styleguide {#styleguide}

Throughout this book we will use our own style guide that can be found in the Wiki of the mlr3 GitHub repo at https://github.com/mlr-org/mlr3/wiki/Style-Guide. Below are the most important style choices relevant to the book, we only list and do not explain the choices.

1. We always use `=` instead of `<-` for assignment.
2. Class names are in `UpperCamelCase`
3. Function and method names are in `lower_snake_case`
4. We write packages, fields, methods, functions as follows:

    * `package`
    * `package::function()` (for functions _outside_ the mlr-org ecosystem)
    * `function()` (for functions _inside_ the mlr-org ecosystem)
    * `$field`
    * `$method()`

5. We do not include required function parameter names in code chunks, only optional ones. But we always include the full function signature the first time it is introduced. For example say we are introducing a new function called `adding_function`:

```{r example backend, include = FALSE}
adding_function = function(x, y) x + y
```

```{r example style, eval = FALSE}
adding_function(x, y)
```

> This function adds two numbers together, `x` and `y`.

```{r example style 2}
adding_function(1, 2)
```
