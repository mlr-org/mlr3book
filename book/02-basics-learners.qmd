# Learners {#learners}

```{r 02-basics-learners-001, include = F}
library(mlr3)
library(mlr3book)
```

Objects of class `r ref("Learner")` provide a unified interface to many popular machine learning algorithms in R.
They consist of methods to train and predict a model for a `r ref("Task")` and provide meta-information about the learners, such as the hyperparameters (which control the behavior of the learner) you can set.

The base class of each learner is `r ref("Learner")`, specialized for regression as `r ref("LearnerRegr")` and for classification as `r ref("LearnerClassif")`.
Other types of learners, provided by extension packages, also inherit from the `r ref("Learner")` base class, e.g. `r ref("mlr3proba::LearnerSurv")` or `r ref("mlr3cluster::LearnerClust")`.
In contrast to `r ref("Task")`s, the creation of a custom Learner is usually not required and a more advanced topic.
Hence, we refer the reader to @sec-extending-learners and proceed with an overview of the interface of already implemented learners.

All Learners work in a two-stage procedure:

```{r 02-basics-learners-002, echo = FALSE, fig.align = "center"}
knitr::include_graphics("images/learner.svg")
```

* **Training stage**: The training data (features and target) is passed to the Learner's `$train()` function which trains and stores a model, i.e. the relationship of the target and features.
* **Predict stage**: The new data, usually a different slice of the original data than used for training, is passed to the `$predict()` method of the Learner.
  The model trained in the first step is used to predict the missing target, e.g. labels for classification problems or the numerical value for regression problems.

## Predefined Learners

The `r mlr3book::mlr_pkg("mlr3")` package ships with the following set of classification and regression learners.
We deliberately keep this small to avoid unnecessary dependencies:

* `r ref("mlr_learners_classif.featureless", text = "classif.featureless")`: Simple baseline classification learner.
  The default is to predict the label that is most frequent in the training set every time. While this is not very useful by itself, it can be used as a "[fallback learner](fallback-learners)" to make predictions in case another, more sophisticated, learner failed for some reason.
* `r ref("mlr_learners_regr.featureless", text = "regr.featureless")`: Simple baseline regression learner.
  The default is to predict the mean of the target in training set every time. Similar to `r ref("mlr_learners_classif.featureless")`, it makes for a good "[fallback learner](fallback-learners)"
* `r ref("mlr_learners_classif.rpart", text = "classif.rpart")`: Single classification tree from package `r mlr3book::cran_pkg("rpart")`.
* `r ref("mlr_learners_regr.rpart", text = "regr.rpart")`: Single regression tree from package `r mlr3book::cran_pkg("rpart")`.

This set of baseline learners is usually insufficient for a real data analysis.
Thus, we have cherry-picked implementations of the most popular machine learning method and collected them in the `r mlr3book::mlr_pkg("mlr3learners")` package:

* Linear (`r ref("mlr_learners_regr.lm", text = "regr.lm")`) and logistic (`r ref("mlr_learners_classif.log_reg", text = "classif.log_reg")`) regression
* Penalized Generalized Linear Models (regression: `r ref("mlr_learners_regr.glmnet", text = "regr.glmnet")`, `r ref("mlr_learners_regr.cv_glmnet", text = "regr.cv_glmnet")`; classification: `r ref("mlr_learners_classif.glmnet", text = "classif.glmnet")`, `ref("mlr_learners_classif.cv_glmnet", text = "classif.cv_glmnet")`; survival: `r ref("mlr_learners_surv.glmnet", text = "surv.glmnet")`, `ref("mlr_learners_surv.cv_glmnet", text = "surv.cv_glmnet")`)
* (Kernelized) $k$-Nearest Neighbors regression (`r ref("mlr_learners_regr.kknn", text = "regr.kknn")`) and classification (`r ref("mlr_learners_classif.kknn", text = "classif.kknn")`).
* Kriging / Gaussian Process Regression (`r ref("mlr_learners_regr.km", text = "regr.km")`)
* Linear (`r ref("mlr_learners_regr.lda", text = "regr.lda")`, `r ref("mlr_learners_classif.lda", text = "classif.lda")`) and Quadratic (`r ref("mlr_learners_regr.qda", text = "regr.qda")`, `r ref("mlr_learners_classif.qda", text = "classif.qda")`) Discriminant Analysis
* Naive Bayes Classification (`r ref("mlr_learners_classif.naive_bayes", text = "classif.naive_bayes")`)
* Support-Vector machines (`r ref("mlr_learners_regr.svm", text = "regr.svm")`, `r ref("mlr_learners_classif.svm", text = "classif.svm")`)
* Gradient Boosting (`r ref("mlr_learners_regr.xgboost", text = "regr.xgboost")`, `r ref("mlr_learners_classif.xgboost", text = "classif.xgboost")`, `r ref("mlr_learners_surv.xgboost", text = "surv.xgboost")`)
* Random Forests for regression, classification and survival (`r ref("mlr_learners_regr.ranger", text = "regr.ranger")`, `r ref("mlr_learners_classif.ranger", text = "classif.ranger")`, `r ref("mlr_learners_surv.ranger", text = "surv.ranger")`)

More machine learning methods and alternative implementations are collected in the [mlr3extralearners repository](https://github.com/mlr-org/mlr3extralearners/).

:::{.callout-tip}
A full list of available learners across all `r mlr3book::mlr_pkg("mlr3")` packages is provided in [this interactive list](https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html) and via `mlr3extralearners::list_mlr3learners()`.
:::

:::{.callout-note}
The full list of learners uses a large number of extra packages, which sometimes break.
We check the status of each learner's integration automatically, the latest build status of all learners is shown [here](https://mlr3extralearners.mlr-org.com/articles/learners/test_overview.html).
:::

To get one of the predefined learners, you need to access the `r ref("mlr_learners")` `r ref("Dictionary")` which, similar to `r ref("mlr_tasks")`, is automatically populated with more learners by extension packages.

```{r 02-basics-learners-004, R.options=list(max.print = 3)}
library("mlr3learners")       # load recommended learners provided by mlr3learners package
library("mlr3extralearners")  # load further less-well-supported learners
library("mlr3proba")          # load further survival and density estimation learners
library("mlr3cluster")        # load learners for clustering

mlr_learners
```

To obtain an object from the dictionary, use the `r ref("lrn()")` function.

```{r 02-basics-learners-004-2}
learner = lrn("classif.rpart")
learner
```

Alternatively, the `mlr_learners$get()` function can be used, for which `r ref("lrn()")` is a shortcut.

## Learner API

Each learner provides the following meta-information:

* `feature_types`: the type of features the learner can deal with.
* `packages`: the packages required to train a model with this learner and make predictions.
* `properties`: additional properties and capabilities.
  For example, a learner has the property "missings" if it is able to handle missing feature values, and "importance" if it computes and allows to extract data on the relative importance of the features.
  A complete list of these is available in the [mlr3 reference](https://mlr3.mlr-org.com/reference/mlr_reflections.html#examples).
* `predict_types`: possible prediction types. For example, a classification learner can predict labels ("response") or probabilities ("prob"). For a complete list of possible predict types see the [mlr3 reference](https://mlr3.mlr-org.com/reference/mlr_reflections.html#examples).

You can retrieve a specific learner using its ID:

```{r 02-basics-learners-005}
learner = lrn("classif.rpart")
print(learner)
```

Each learner has hyperparameters that control its behavior, for example the minimum number of samples in the leaf of a decision tree, or whether to provide verbose output durning training.
Setting hyperparameters to values appropriate for a given machine learning task is crucial.
The field `param_set` stores a description of the hyperparameters the learner has, their ranges, defaults, and current values:

```{r 02-basics-learners-006}
learner$param_set
```

The set of current hyperparameter values is stored in the `values` field of the `param_set` field.
You can change the current hyperparameter values by assigning a named list to this field:

```{r 02-basics-learners-007}
learner$param_set$values = list(cp = 0.01, xval = 0)
learner
```

:::{.callout-caution}
This operation overwrites all previously set parameters.
:::

You can also get the current set of hyperparameter values, modify it, and write it back to the learner:

```{r 02-basics-learners-008}
pv = learner$param_set$values
pv$cp = 0.02
learner$param_set$values = pv
```

This sets `cp` to `0.02` but keeps any other values that were set previously.

The `r ref("lrn()")` function also accepts additional arguments to update hyperparameters or set fields of the learner in one go:

```{r 02-basics-learners-009}
learner = lrn("classif.rpart", id = "rp", cp = 0.001)
learner$id
learner$param_set$values
```

More on this is discussed in the section on [Hyperparameter Tuning](https://mlr3book.mlr-org.com/optimization.html#tuning).

### Thresholding

Models trained on binary classification tasks that predict the probability for the positive class usually use a simple rule to determine the predicted class label: if the probability is more than 50%, predict the positive label, otherwise predict the negative label.
In some cases you may want to adjust this threshold, for example if the classes are very unbalanced (i.e. one is much more prevalent than the other).

In the example below, we change the threshold to 0.2, which improves the True Positive Rate (TPR).
Note that while the new threshold classifies more observations from the positive class correctly, the True Negative Rate (TNR) decreases.
Depending on the application, this may or may not be desired.

```{r 02-basics-learners-010}
data("Sonar", package = "mlbench")
task = as_task_classif(Sonar, target = "Class", positive = "M")
learner = lrn("classif.rpart", predict_type = "prob")
pred = learner$train(task)$predict(task)

measures = msrs(c("classif.tpr", "classif.tnr")) # use msrs() to get a list of multiple measures
pred$confusion
pred$score(measures)

pred$set_threshold(0.2)
pred$confusion
pred$score(measures)
```

:::{.callout-tip}
Thresholds can be tuned automatically with the `r mlr3book::mlr_pkg("mlr3pipelines")` package, i.e. using `r ref("mlr_pipeops_tunethreshold", text = "PipeOpTuneThreshold")`.
:::
