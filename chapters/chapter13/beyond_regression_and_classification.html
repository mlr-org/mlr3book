<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>13&nbsp; Beyond Regression and Classification – Applied Machine Learning Using mlr3 in R</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/chapter14/algorithmic_fairness.html" rel="next">
<link href="../../chapters/chapter12/model_interpretation.html" rel="prev">
<link href="../../Figures/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0d45b1ff1595a53868627e64e30aef28.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-54b1fec74e0844836633235e285d9714.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter10/advanced_technical_aspects_of_mlr3.html">Advanced Topics</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter13/beyond_regression_and_classification.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Beyond Regression and Classification</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Applied Machine Learning Using mlr3 in R</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/mlr-org/mlr3book/tree/main/book/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../Applied-Machine-Learning-Using-mlr3-in-R.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter1/introduction_and_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction and Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Fundamentals</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter2/data_and_basic_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Basic Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter3/evaluation_and_benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Evaluation and Benchmarking</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Tuning and Feature Selection</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter4/hyperparameter_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Hyperparameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter5/advanced_tuning_methods_and_black_box_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Advanced Tuning Methods and Black Box Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter6/feature_selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Feature Selection</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Pipelines and Preprocessing</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter7/sequential_pipelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Sequential Pipelines</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter8/non-sequential_pipelines_and_tuning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Non-sequential Pipelines and Tuning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter9/preprocessing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Preprocessing</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter10/advanced_technical_aspects_of_mlr3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Advanced Technical Aspects of mlr3</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter11/large-scale_benchmarking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Large-Scale Benchmarking</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter12/model_interpretation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model Interpretation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter13/beyond_regression_and_classification.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Beyond Regression and Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter14/algorithmic_fairness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Algorithmic Fairness</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/chapter15/predsets_valid_inttune.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Predict Sets, Validation and Internal Tuning (+)</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Solutions to exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/tasks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Tasks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/overview-tables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Overview Tables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/errata.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Errata</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/appendices/session_info.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Session Info</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#sec-cost-sens" id="toc-sec-cost-sens" class="nav-link active" data-scroll-target="#sec-cost-sens"><span class="header-section-number">13.1</span> Cost-Sensitive Classification</a>
  <ul class="collapse">
<li><a href="#cost-sensitive-measure" id="toc-cost-sensitive-measure" class="nav-link" data-scroll-target="#cost-sensitive-measure"><span class="header-section-number">13.1.1</span> Cost-Sensitive Measure</a></li>
  <li><a href="#thresholding" id="toc-thresholding" class="nav-link" data-scroll-target="#thresholding"><span class="header-section-number">13.1.2</span> Thresholding</a></li>
  </ul>
</li>
  <li>
<a href="#sec-survival" id="toc-sec-survival" class="nav-link" data-scroll-target="#sec-survival"><span class="header-section-number">13.2</span> Survival Analysis</a>
  <ul class="collapse">
<li><a href="#tasksurv" id="toc-tasksurv" class="nav-link" data-scroll-target="#tasksurv"><span class="header-section-number">13.2.1</span> TaskSurv</a></li>
  <li><a href="#learnersurv-predictionsurv-and-predict-types" id="toc-learnersurv-predictionsurv-and-predict-types" class="nav-link" data-scroll-target="#learnersurv-predictionsurv-and-predict-types"><span class="header-section-number">13.2.2</span> LearnerSurv, PredictionSurv and Predict Types</a></li>
  <li><a href="#measuresurv" id="toc-measuresurv" class="nav-link" data-scroll-target="#measuresurv"><span class="header-section-number">13.2.3</span> MeasureSurv</a></li>
  <li><a href="#sec-surv-comp" id="toc-sec-surv-comp" class="nav-link" data-scroll-target="#sec-surv-comp"><span class="header-section-number">13.2.4</span> Composition</a></li>
  <li><a href="#sec-survival-all" id="toc-sec-survival-all" class="nav-link" data-scroll-target="#sec-survival-all"><span class="header-section-number">13.2.5</span> Putting It All Together</a></li>
  </ul>
</li>
  <li>
<a href="#sec-density" id="toc-sec-density" class="nav-link" data-scroll-target="#sec-density"><span class="header-section-number">13.3</span> Density Estimation</a>
  <ul class="collapse">
<li><a href="#taskdens" id="toc-taskdens" class="nav-link" data-scroll-target="#taskdens"><span class="header-section-number">13.3.1</span> TaskDens</a></li>
  <li><a href="#learnerdens-and-predictiondens" id="toc-learnerdens-and-predictiondens" class="nav-link" data-scroll-target="#learnerdens-and-predictiondens"><span class="header-section-number">13.3.2</span> LearnerDens and PredictionDens</a></li>
  <li><a href="#measuredens-and-putting-it-all-together" id="toc-measuredens-and-putting-it-all-together" class="nav-link" data-scroll-target="#measuredens-and-putting-it-all-together"><span class="header-section-number">13.3.3</span> MeasureDens and Putting It All Together</a></li>
  </ul>
</li>
  <li>
<a href="#sec-cluster" id="toc-sec-cluster" class="nav-link" data-scroll-target="#sec-cluster"><span class="header-section-number">13.4</span> Cluster Analysis</a>
  <ul class="collapse">
<li><a href="#taskclust" id="toc-taskclust" class="nav-link" data-scroll-target="#taskclust"><span class="header-section-number">13.4.1</span> TaskClust</a></li>
  <li><a href="#learnerclust-and-predictionclust" id="toc-learnerclust-and-predictionclust" class="nav-link" data-scroll-target="#learnerclust-and-predictionclust"><span class="header-section-number">13.4.2</span> LearnerClust and PredictionClust</a></li>
  <li><a href="#measureclust" id="toc-measureclust" class="nav-link" data-scroll-target="#measureclust"><span class="header-section-number">13.4.3</span> MeasureClust</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization"><span class="header-section-number">13.4.4</span> Visualization</a></li>
  <li><a href="#sec-cluster-all" id="toc-sec-cluster-all" class="nav-link" data-scroll-target="#sec-cluster-all"><span class="header-section-number">13.4.5</span> Putting It All Together</a></li>
  </ul>
</li>
  <li>
<a href="#sec-spatiotemporal" id="toc-sec-spatiotemporal" class="nav-link" data-scroll-target="#sec-spatiotemporal"><span class="header-section-number">13.5</span> Spatial Analysis</a>
  <ul class="collapse">
<li><a href="#taskclassifst-and-taskregrst" id="toc-taskclassifst-and-taskregrst" class="nav-link" data-scroll-target="#taskclassifst-and-taskregrst"><span class="header-section-number">13.5.1</span> TaskClassifST and TaskRegrST</a></li>
  <li><a href="#spatiotemp-cv" id="toc-spatiotemp-cv" class="nav-link" data-scroll-target="#spatiotemp-cv"><span class="header-section-number">13.5.2</span> Spatiotemporal Cross-Validation</a></li>
  <li><a href="#sec-spatial-prediction" id="toc-sec-spatial-prediction" class="nav-link" data-scroll-target="#sec-spatial-prediction"><span class="header-section-number">13.5.3</span> Spatial Prediction</a></li>
  </ul>
</li>
  <li>
<a href="#sec-quantile-regression" id="toc-sec-quantile-regression" class="nav-link" data-scroll-target="#sec-quantile-regression"><span class="header-section-number">13.6</span> Quantile Regression (+)</a>
  <ul class="collapse">
<li><a href="#sec-data-generation" id="toc-sec-data-generation" class="nav-link" data-scroll-target="#sec-data-generation"><span class="header-section-number">13.6.1</span> Synthetic data set generation</a></li>
  <li><a href="#sec-quantile-regression-models" id="toc-sec-quantile-regression-models" class="nav-link" data-scroll-target="#sec-quantile-regression-models"><span class="header-section-number">13.6.2</span> Quantile Regression with Multiple Learners</a></li>
  </ul>
</li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">13.7</span> Conclusion</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">13.8</span> Exercises</a></li>
  <li><a href="#citation" id="toc-citation" class="nav-link" data-scroll-target="#citation"><span class="header-section-number">13.9</span> Citation</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/mlr-org/mlr3book/edit/main/book/chapters/chapter13/beyond_regression_and_classification.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mlr-org/mlr3book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/mlr-org/mlr3book/blob/main/book/chapters/chapter13/beyond_regression_and_classification.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/chapter10/advanced_technical_aspects_of_mlr3.html">Advanced Topics</a></li><li class="breadcrumb-item"><a href="../../chapters/chapter13/beyond_regression_and_classification.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Beyond Regression and Classification</span></a></li></ol></nav><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-special" class="quarto-section-identifier"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Beyond Regression and Classification</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p><strong>Raphael Sonabend</strong> <br><em>Imperial College London</em></p>
<p><strong>Patrick Schratz</strong> <br><em>Friedrich Schiller University Jena</em></p>
<p><strong>Damir Pulatov</strong> <br><em>University of Wyoming</em></p>
<p><strong>John Zobolas</strong> <br><em>Institute for Cancer Research, Oslo University Hospital</em></p>
<p><strong>Lona Koers</strong> <br><em>Ludwig-Maximilians-Universität München</em> <br><br></p>
<p>So far, this book has only considered two tasks. In <a href="../chapter2/data_and_basic_modeling.html" class="quarto-xref"><span>Chapter 2</span></a> we introduced deterministic regression as well as deterministic and probabilistic single-label classification (<a href="#tbl-alltasks" class="quarto-xref">Table&nbsp;<span>13.1</span></a>). But our infrastructure also works well for many other tasks, some of which are available in extension packages (<a href="../chapter1/introduction_and_overview.html#fig-mlr3verse" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>) and some are available by creating pipelines with <a href="https://mlr3pipelines.mlr-org.com"><code>mlr3pipelines</code></a>. In this chapter, we will take you through just a subset of these new tasks, focusing on the ones that have a stable API. As we work through this chapter we will refer to the ‘building blocks’ of <a href="https://mlr3.mlr-org.com"><code>mlr3</code></a>, this refers to the base classes that must be extended to create new tasks, these are <a href="https://mlr3.mlr-org.com/reference/Prediction.html"><code>Prediction</code></a>, <a href="https://mlr3.mlr-org.com/reference/Learner.html"><code>Learner</code></a>, <a href="https://mlr3.mlr-org.com/reference/Measure.html"><code>Measure</code></a>, and <a href="https://mlr3.mlr-org.com/reference/Task.html"><code>Task</code></a>. <a href="#tbl-alltasks" class="quarto-xref">Table&nbsp;<span>13.1</span></a> summarizes available extension tasks, including the package(s) they are implemented in and a brief description of the task.</p>
<div id="tbl-alltasks" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-alltasks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;13.1: Table of extension tasks that can be used with <code>mlr3</code> infrastructure. As we have a growing community of contributors, this list is far from exhaustive and many ‘experimental’ task implementations exist; this list just represents the tasks that have a functioning interface.
</figcaption><div aria-describedby="tbl-alltasks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead><tr class="header">
<th>Task</th>
<th>Package</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Deterministic regression</td>
<td><a href="https://mlr3.mlr-org.com"><code>mlr3</code></a></td>
<td>Point prediction of a continuous variable.</td>
</tr>
<tr class="even">
<td>Quantile regression</td>
<td><a href="https://mlr3.mlr-org.com"><code>mlr3</code></a></td>
<td>Prediction of conditional quantiles for a continuous variable.</td>
</tr>
<tr class="odd">
<td>Deterministic single-label classification</td>
<td><a href="https://mlr3.mlr-org.com"><code>mlr3</code></a></td>
<td>Prediction of a single class for each observation.</td>
</tr>
<tr class="even">
<td>Probabilistic single-label classification</td>
<td><a href="https://mlr3.mlr-org.com"><code>mlr3</code></a></td>
<td>Prediction of the probability of an observation falling into one or more mutually exclusive categories.</td>
</tr>
<tr class="odd">
<td>Cost-sensitive classification</td>
<td>
<a href="https://mlr3.mlr-org.com"><code>mlr3</code></a> and <a href="https://mlr3pipelines.mlr-org.com"><code>mlr3pipelines</code></a>
</td>
<td>Classification predictions with unequal costs associated with misclassifications.</td>
</tr>
<tr class="even">
<td>Survival analysis</td>
<td><a href="https://mlr3proba.mlr-org.com"><code>mlr3proba</code></a></td>
<td>Time-to-event predictions with possible ‘censoring’.</td>
</tr>
<tr class="odd">
<td>Density estimation</td>
<td><a href="https://mlr3proba.mlr-org.com"><code>mlr3proba</code></a></td>
<td>Unsupervised estimation of probability density functions.</td>
</tr>
<tr class="even">
<td>Spatiotemporal analysis</td>
<td>
<a href="https://mlr3spatiotempcv.mlr-org.com"><code>mlr3spatiotempcv</code></a> and <a href="https://mlr3spatial.mlr-org.com"><code>mlr3spatial</code></a>
</td>
<td>Supervised prediction of data with spatial (e.g., coordinates) and/or temporal outcomes.</td>
</tr>
<tr class="odd">
<td>Cluster analysis</td>
<td><a href="https://mlr3cluster.mlr-org.com"><code>mlr3cluster</code></a></td>
<td>Unsupervised estimation of homogeneous clusters of data points.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="sec-cost-sens" class="level2 page-columns page-full" data-number="13.1"><h2 data-number="13.1" class="anchored" data-anchor-id="sec-cost-sens">
<span class="header-section-number">13.1</span> Cost-Sensitive Classification</h2>
<div class="page-columns page-full"><p>We begin by discussing a task that does not require any additional packages or infrastructure, only the tools we have already learned about from earlier chapters. In ‘regular’ classification, the aim is to optimize a metric (often the misclassification rate) while assuming all misclassification errors are deemed equally severe. A more general approach is cost-sensitive classification, in which costs caused by different kinds of errors may not be equal. The objective of cost-sensitive classification is to minimize the expected costs. We will use <code>tsk("german_credit")</code> as a running example.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Cost-sensitive Classification</span></div></div>
<p>Imagine you are trying to calculate if giving someone a loan of $5K will result in a profit after one year, assuming they are expected to pay back $6K. To make this calculation, you will need to predict if the person will have good credit. This is a deterministic classification problem where we are predicting whether someone will be in class ‘Good’ or ‘Bad’. Now let us consider some potential costs associated with each prediction and the eventual truth. As cost-sensitive classification is a minimization problem, we assume lower costs correspond to higher profits/positive outcomes, hence we write profits as negative values and losses as positive values:</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">costs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">5</span>, <span class="fl">0</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span>, dimnames <span class="op">=</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="st">"Predicted Credit"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"good"</span>, <span class="st">"bad"</span><span class="op">)</span>,</span>
<span>    Truth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"good"</span>, <span class="st">"bad"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">costs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                Truth
Predicted Credit good bad
            good   -1   5
            bad     0   0</code></pre>
</div>
</div>
<p>In this example, if the model predicts that the individual has bad credit (bottom row) then there is no profit or loss, the loan is not provided. If the model predicts that the individual has good credit and indeed the customer repays the loan with interest (top left), then you will make a $1K profit. On the other hand, if they default (top right), you will lose $5K.</p>
<section id="cost-sensitive-measure" class="level3" data-number="13.1.1"><h3 data-number="13.1.1" class="anchored" data-anchor-id="cost-sensitive-measure">
<span class="header-section-number">13.1.1</span> Cost-Sensitive Measure</h3>
<p>We will now see how to implement a more nuanced approach to classification errors with <code>msr("classif.costs")</code>. This measure takes one argument, which is a matrix with row and column names corresponding to the class labels in the task of interest. Let us put our insurance example into practice, notice that we have already named the cost matrix as required for the measure:</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_german</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"german_credit"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">msr_costs</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.costs"</span>, costs <span class="op">=</span> <span class="va">costs</span><span class="op">)</span></span>
<span><span class="va">msr_costs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;MeasureClassifCosts&gt; (classif.costs): Cost-sensitive Classification ─
• Packages: mlr3
• Range: [-Inf, Inf]
• Minimize: TRUE
• Average: macro
• Parameters: normalize=TRUE
• Properties: weights
• Predict type: response
• Predict sets: test
• Aggregator: mean()</code></pre>
</div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span>, <span class="st">"classif.featureless"</span>,</span>
<span>  <span class="st">"classif.ranger"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_german</span>, <span class="va">learners</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_costs</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">7</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            learner_id classif.costs
1:     classif.log_reg        0.1791
2: classif.featureless        0.8002
3:      classif.ranger        0.2491</code></pre>
</div>
</div>
<p>In this experiment, we find that the logistic regression learner happens to perform best as it minimizes the expected costs (and maximizes expected profits) and the featureless learner performs the worst. All losses result in positive costs, which means each model results in us losing money. To improve our models, we will now turn to thresholding.</p>
</section><section id="thresholding" class="level3" data-number="13.1.2"><h3 data-number="13.1.2" class="anchored" data-anchor-id="thresholding">
<span class="header-section-number">13.1.2</span> Thresholding</h3>
<p>As we have discussed in <a href="../chapter2/data_and_basic_modeling.html" class="quarto-xref"><span>Chapter 2</span></a>, thresholding is a method to fine-tune the probability at which an observation will be predicted as one class label or another. Currently in our running example, the models above will predict a customer has good credit (in the class ‘Good’) if the probability of good credit is greater than 0.5. Here, this might not be a sensible approach as we would likely act more conservatively and reject more credit applications with a higher threshold due to the non-uniform costs. This is highlighted in the <code>"threshold"</code> <code>autoplot</code> (<a href="#fig-costsens-threshold" class="quarto-xref">Figure&nbsp;<span>13.1</span></a>), which plots <code>msr("classif.costs")</code> over all possible thresholds.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span>,</span>
<span>  predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_german</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_german</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, type <span class="op">=</span> <span class="st">"threshold"</span>, measure <span class="op">=</span> <span class="va">msr_costs</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-costsens-threshold" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Line graph with x-axis labeled 'Probability Threshold' ranging between 0-1, and y-axis labeled 'classif.costs' ranging between -0.3 and 0.7'. Line starts at (0,0.7) decreases linearly to around (0.8,-0.3) then increases linearly to (1, 0).">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-costsens-threshold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-costsens-threshold-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Line graph with x-axis labeled 'Probability Threshold' ranging between 0-1, and y-axis labeled 'classif.costs' ranging between -0.3 and 0.7'. Line starts at (0,0.7) decreases linearly to around (0.8,-0.3) then increases linearly to (1, 0).">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-costsens-threshold-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.1: Changing values of cost-sensitive measure as the prediction threshold is changed.
</figcaption></figure>
</div>
</div>
</div>
<p>As expected, the optimal threshold is greater than 0.5 which means the optimal model should predict ‘bad’ credit more often than not.</p>
<p>The optimal threshold can be automated by making use of <a href="https://mlr3tuning.mlr-org.com"><code>mlr3tuning</code></a> (<a href="../chapter4/hyperparameter_optimization.html" class="quarto-xref"><span>Chapter 4</span></a>) and <a href="https://mlr3pipelines.mlr-org.com"><code>mlr3pipelines</code></a> (<a href="../chapter7/sequential_pipelines.html" class="quarto-xref"><span>Chapter 7</span></a>) to tune <code>po("tunethreshold")</code>. Continuing the same example:</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">po_cv</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner_cv"</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">graph</span> <span class="op">=</span>  <span class="va">po_cv</span> <span class="op"><a href="https://mlr3pipelines.mlr-org.com/reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"tunethreshold"</span>, measure <span class="op">=</span> <span class="va">msr_costs</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">graph</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.log_reg"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_german</span>, <span class="va">learners</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in benchmark_grid(tsk_german, learners, rsmp("cv", folds = 3)):
Multiple predict types detected, this will mean that you cannot evaluate
the same measures on all learners.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>OptimInstanceSingleCrit is deprecated. Use OptimInstanceBatchSingleCrit instead.
OptimInstanceSingleCrit is deprecated. Use OptimInstanceBatchSingleCrit instead.
OptimInstanceSingleCrit is deprecated. Use OptimInstanceBatchSingleCrit instead.</code></pre>
</div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">msr_costs</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">7</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                      learner_id classif.costs
1: classif.log_reg.tunethreshold       -0.1060
2:               classif.log_reg        0.1481</code></pre>
</div>
</div>
<p>By using <code>po("learner_cv")</code> for internal resampling and <code>po("tunethreshold")</code> to find the optimal threshold we have improved our model performance considerably and can now even expect a profit.</p>
</section></section><section id="sec-survival" class="level2" data-number="13.2"><h2 data-number="13.2" class="anchored" data-anchor-id="sec-survival">
<span class="header-section-number">13.2</span> Survival Analysis</h2>
<p>Survival analysis is a field of statistics concerned with trying to predict/estimate the time until an event takes place. This predictive problem is unique as survival models are trained and tested on data that may include ‘censoring’, which occurs when the event of interest does <em>not</em> take place. Survival analysis can be hard to explain in the abstract, so as a working example consider a marathon runner in a race. Here the ‘survival problem’ is trying to predict the time when the marathon runner finishes the race. However, if the event of interest does not take place (e.g., the marathon runner gives up and does not finish the race), they are said to be censored. Instead of throwing away information about censored events, survival analysis datasets include a status variable that provides information about the ‘status’ of an observation. So in our example, we might write the runner’s outcome as <span class="math inline">\((4, 1)\)</span> if they finish the race at four hours, otherwise, if they give up at two hours we would write <span class="math inline">\((2, 0)\)</span>.</p>
<p>The key to modeling in survival analysis is that we assume there exists a hypothetical time the marathon runner would have finished if they had not been censored, it is then the job of a survival learner to estimate what the true survival time would have been for a similar runner, assuming they are <em>not</em> censored (see <a href="#fig-censoring" class="quarto-xref">Figure&nbsp;<span>13.2</span></a>). Mathematically, this is represented by the hypothetical event time, <span class="math inline">\(Y\)</span>, the hypothetical censoring time, <span class="math inline">\(C\)</span>, the observed outcome time, <span class="math inline">\(T = \min(Y, C)\)</span>, the event indicator <span class="math inline">\(\Delta := (T = Y)\)</span>, and as usual some features, <span class="math inline">\(X\)</span>. Learners are trained on <span class="math inline">\((T, \Delta)\)</span> but, critically, make predictions of <span class="math inline">\(Y\)</span> from previously unseen features. This means that unlike classification and regression, learners are trained on two variables, <span class="math inline">\((T, \Delta)\)</span>, which, in R, is often captured in a <a href="https://www.rdocumentation.org/packages/survival/topics/Surv"><code>Surv</code></a> object. Relating to our example above, the runner’s outcome would then be <span class="math inline">\((T = 4, \Delta = 1)\)</span> or <span class="math inline">\((T = 2, \Delta = 0)\)</span>. Another example is in the code below, where we randomly generate six survival times and six event indicators, an outcome with a <code>+</code> indicates the outcome is censored, otherwise, the event of interest occurred.</p>
<div class="cell">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival">survival</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'survival'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:future':

    cluster</code></pre>
</div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html">Surv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">6</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5523+ 0.2905  0.4404+ 0.1184  0.9216+ 0.7326 </code></pre>
</div>
</div>
<p>Readers familiar with survival analysis will recognize that the description above applies specifically to ‘right censoring’. Currently, this is the only form of censoring available in the <code>mlr3</code> universe, hence restricting our discussion to that setting. For a good introduction to survival analysis see <span class="citation" data-cites="Collett2014">Collett (<a href="../references.html#ref-Collett2014" role="doc-biblioref">2014</a>)</span> or for machine learning in survival analysis specifically see <span class="citation" data-cites="MLSA">R. Sonabend and Bender (<a href="../references.html#ref-MLSA" role="doc-biblioref">2023</a>)</span>.</p>
<p>For the remainder of this section, we will look at how <a href="https://mlr3proba.mlr-org.com"><code>mlr3proba</code></a> <span class="citation" data-cites="mlr3proba">(<a href="../references.html#ref-mlr3proba" role="doc-biblioref">R. Sonabend et al. 2021</a>)</span> extends the building blocks of <code>mlr3</code> for survival analysis. We will begin by looking at objects used to construct machine learning tasks for survival analysis, then we will turn to the learners we have implemented to solve these tasks, before looking at measures for evaluating survival analysis predictions, and then finally we will consider how to transform prediction types.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-censoring" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Figure shows give horizontal lines at 1,2,3,4,5 on the y-axis and a vertical line at 8 on the x-axis. Top line (subject 5) has a circle at x=8 and a diamond at x=9, second line (subject 4) has a circle at x=1 and a diamond at x=9, subject 3 has a circle at x=4 and a diamond at x=6, subject 2 has a diamond at x=8, and subject 1 has a diamond at x=7.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-censoring-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-censoring-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure shows give horizontal lines at 1,2,3,4,5 on the y-axis and a vertical line at 8 on the x-axis. Top line (subject 5) has a circle at x=8 and a diamond at x=9, second line (subject 4) has a circle at x=1 and a diamond at x=9, subject 3 has a circle at x=4 and a diamond at x=6, subject 2 has a diamond at x=8, and subject 1 has a diamond at x=7.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-censoring-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.2: Plot illustrating different censoring types. Dead and censored subjects (y-axis) over time (x-axis). Black diamonds indicate true death times and white circles indicate censoring times. Vertical line is the study end time. Subjects 1 and 2 die in the study time. Subject 3 is censored in the study and (unknown) dies within the study time. Subject 4 is censored in the study and (unknown) dies after the study. Subject 5 dies after the end of the study. Figure and caption from <span class="citation" data-cites="Sonabend2021b">R. E. B. Sonabend (<a href="../references.html#ref-Sonabend2021b" role="doc-biblioref">2021</a>)</span>.
</figcaption></figure>
</div>
</div>
</div>
<section id="tasksurv" class="level3" data-number="13.2.1"><h3 data-number="13.2.1" class="anchored" data-anchor-id="tasksurv">
<span class="header-section-number">13.2.1</span> TaskSurv</h3>
<p>As we saw in the introduction to this section, survival algorithms require two targets for training, this means the new <a href="https://mlr3proba.mlr-org.com/reference/TaskSurv.html"><code>TaskSurv</code></a> object expects two targets. The simplest way to create a survival task is to use <a href="https://mlr3proba.mlr-org.com/reference/as_task_surv.html"><code>as_task_surv()</code></a>, as in the following code chunk. Note this has more arguments than <a href="https://mlr3.mlr-org.com/reference/as_task_regr.html"><code>as_task_regr()</code></a> to reflect multiple target and censoring types, <code>time</code> and <code>event</code> arguments expect strings representing column names where the ‘time’ and ‘event’ variables are stored, <code>type</code> refers to the censoring type (currently only right censoring supported so this is the default). <code><a href="https://mlr3proba.mlr-org.com/reference/as_task_surv.html">as_task_surv()</a></code> coerces the target columns into a <a href="https://www.rdocumentation.org/packages/survival/topics/Surv"><code>Surv</code></a> object. In this section we will use the <code>rats</code> dataset as a running example, this dataset looks at predicting if a drug treatment was successful in preventing 150 rats from developing tumors. The dataset, by its own admission, is not perfect and should generally be treated as ‘dummy’ data, which is good for examples but not real-world analysis.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3proba.mlr-org.com">mlr3proba</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival">survival</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_rats</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3proba.mlr-org.com/reference/as_task_surv.html">as_task_surv</a></span><span class="op">(</span><span class="fu">survival</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/survival/man/rats.html">rats</a></span>, time <span class="op">=</span> <span class="st">"time"</span>,</span>
<span>  event <span class="op">=</span> <span class="st">"status"</span>, type <span class="op">=</span> <span class="st">"right"</span>, id <span class="op">=</span> <span class="st">"rats"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_rats</span><span class="op">$</span><span class="fu">head</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   time status litter rx sex
1:  101      0      1  1   f
2:   49      1      1  0   f
3:  104      0      1  0   f
4:   91      0      2  1   m
5:  104      0      2  0   m
6:  102      0      2  0   m</code></pre>
</div>
</div>
<p>Plotting the task with <code>autoplot</code> results in a Kaplan-Meier plot (<a href="#fig-autokm" class="quarto-xref">Figure&nbsp;<span>13.3</span></a>) which is a non-parametric estimator of the probability of survival for the average observation in the training set.</p>
<div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">tsk_rats</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-autokm" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Figure shows a line plot with &quot;Time&quot; on the x-axis from 0 to 100 and &quot;Survival&quot; on the y-axis from 0.80 to 1.00. The line plot is a black line from (0, 1) to (25, 1) then starts to drop slowly and then quickly down to (100, 0.80).">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-autokm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-autokm-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure shows a line plot with &quot;Time&quot; on the x-axis from 0 to 100 and &quot;Survival&quot; on the y-axis from 0.80 to 1.00. The line plot is a black line from (0, 1) to (25, 1) then starts to drop slowly and then quickly down to (100, 0.80).">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autokm-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.3: Kaplan-Meier plot of <code>tsk("rats")</code>. x-axis is time variable and y-axis is survival function, S(T), defined by <span class="math inline">\(1 -\)</span> F(T) where F is the cumulative distribution function. Crosses indicate points where censoring takes place.
</figcaption></figure>
</div>
</div>
</div>
<p>As well as creating your own tasks, you can load any of the tasks shipped with <code>mlr3proba</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_tasks</span><span class="op">)</span><span class="op">[</span><span class="va">task_type</span> <span class="op">==</span> <span class="st">"surv"</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       key                  label task_type nrow ncol properties lgl
1:    actg               ACTG 320      surv 1151   13              0
2:    gbcs   German Breast Cancer      surv  686   10              0
3:    gbsg   German Breast Cancer      surv  686   10              0
4:   grace             GRACE 1000      surv 1000    8              0
5:    lung            Lung Cancer      surv  168    9              0
6:    mgus                   MGUS      surv  176    9              0
7:    rats                   Rats      surv  300    5              0
8: veteran                Veteran      surv  137    8              0
9:    whas Worcester Heart Attack      surv  481   11              0
7 variables not shown: [int, dbl, chr, fct, ord, pxc, dte]</code></pre>
</div>
</div>
</section><section id="learnersurv-predictionsurv-and-predict-types" class="level3" data-number="13.2.2"><h3 data-number="13.2.2" class="anchored" data-anchor-id="learnersurv-predictionsurv-and-predict-types">
<span class="header-section-number">13.2.2</span> LearnerSurv, PredictionSurv and Predict Types</h3>
<p>The interface for <a href="https://mlr3proba.mlr-org.com/reference/LearnerSurv.html"><code>LearnerSurv</code></a> and <a href="https://mlr3proba.mlr-org.com/reference/PredictionSurv.html"><code>PredictionSurv</code></a> objects is identical to the regression and classification settings discussed in <a href="../chapter2/data_and_basic_modeling.html" class="quarto-xref"><span>Chapter 2</span></a>. Similarly to these settings, survival learners are constructed with <a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html"><code>lrn()</code></a>.</p>
<p><code>mlr3proba</code> has a different predict interface to <code>mlr3</code> as all possible types of prediction (‘predict types’) are returned when possible for all survival models – i.e., if a model <em>can</em> compute a particular predict type then <em>it will be</em> returned in <code>PredictionSurv</code>. The reason for this design decision is that all these predict types can be transformed to one another and it is therefore computationally simpler to return all at once instead of rerunning models to change predict type. In survival analysis, the following predictions can be made:</p>
<ul>
<li>
<code>response</code> – Predicted survival time.</li>
<li>
<code>distr</code> – Predicted survival distribution, either discrete or continuous.</li>
<li>
<code>lp</code> – Linear predictor calculated as the fitted coefficients multiplied by the test data.</li>
<li>
<code>crank</code> – Continuous risk ranking.</li>
</ul>
<p>We will go through each of these prediction types in more detail and with examples to make them less abstract. We will use <code>lrn("surv.coxph")</code> trained on <code>tsk("rats")</code> as a running example, since for this model, all predict types except <code>response</code> can be computed.</p>
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tsk_rats</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"rats"</span><span class="op">)</span></span>
<span><span class="va">split</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_rats</span><span class="op">)</span></span>
<span><span class="va">prediction_cph</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"surv.coxph"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">predict</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prediction_cph</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionSurv&gt; for 99 observations: ────────────────────────────────
 row_ids time status   crank      lp     distr
       3  104  FALSE -0.4356 -0.4356 &lt;list[1]&gt;
       5  104  FALSE -3.1265 -3.1265 &lt;list[1]&gt;
       7  104  FALSE  0.4090  0.4090 &lt;list[1]&gt;
     ---  ---    ---     ---     ---       ---
     297   79   TRUE  0.4300  0.4300 &lt;list[1]&gt;
     298   92  FALSE -1.4339 -1.4339 &lt;list[1]&gt;
     300  102  FALSE -2.2609 -2.2609 &lt;list[1]&gt;</code></pre>
</div>
</div>
<section id="predict_type-response" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="predict_type-response">predict_type = “response”</h4>
<p>Counterintuitively for many, the <code>response</code> prediction of predicted survival times is the least common predict type in survival analysis. The likely reason for this is due to the presence of censoring. We rarely observe the true survival time for many observations and therefore it is unlikely any survival model can confidently make predictions for survival times. This is illustrated in the code below.</p>
<p>In the example below we train and predict from a survival SVM (<code>lrn("surv.svm")</code>), note we use <code>type = "regression"</code> to select the algorithm that optimizes survival time predictions and <code>gamma.mu = 1e-3</code> is selected arbitrarily as this is a required parameter (this parameter should usually be tuned). We then compare the predictions from the model to the true data.</p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">mlr3extralearners</span><span class="op">)</span></span>
<span><span class="va">prediction_svm</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"surv.svm"</span>, type <span class="op">=</span> <span class="st">"regression"</span>, gamma <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">train</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>pred <span class="op">=</span> <span class="va">prediction_svm</span><span class="op">$</span><span class="va">response</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>,</span>
<span>  truth <span class="op">=</span> <span class="va">prediction_svm</span><span class="op">$</span><span class="va">truth</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   pred truth
1 86.36  104+
2 86.16  104+
3 85.95  104+</code></pre>
</div>
</div>
<p>As can be seen from the output, our predictions are all less than the true observed time, which means we know our model underestimated the truth. However, because each of the true values are censored times, we have absolutely no way of knowing if these predictions are slightly bad or absolutely terrible, (i.e., the true survival times could be <span class="math inline">\(105, 99, 92\)</span> or they could be <span class="math inline">\(300, 1000, 200\)</span>). Hence, with no realistic way to evaluate these models, survival time predictions are rarely useful.</p>
</section><section id="predict_type-distr" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="predict_type-distr">predict_type = “distr”</h4>
<p>Unlike regression in which deterministic/point predictions are most common, in survival analysis distribution predictions are much more common. You will therefore find that the majority of survival models in <code>mlr3proba</code> will make distribution predictions by default. These predictions are implemented using the <a href="https://alan-turing-institute.r-universe.dev/ui#package:distr6"><code>distr6</code></a> package, which allows visualization and evaluation of survival curves (defined as <span class="math inline">\(1 -\)</span> cumulative distribution function). Below we extract the first three <code>$distr</code> predictions from our running example and calculate the probability of survival at <span class="math inline">\(t = 77\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction_cph</span><span class="op">$</span><span class="va">distr</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">$</span><span class="fu">survival</span><span class="op">(</span><span class="fl">77</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]   [,2]   [,3]
77 0.9412 0.9959 0.8684</code></pre>
</div>
</div>
<p>The output indicates that there is a 94.1%, 99.6%, 86.8%, chance of the first three predicted rats being alive at time 77 respectively.</p>
</section><section id="predict_type-lp" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="predict_type-lp">predict_type = “lp”</h4>
<p><code>lp</code>, often written as <span class="math inline">\(\eta\)</span> in academic writing, is computationally the simplest prediction and has a natural analog in regression modeling. Readers familiar with linear regression will know that when fitting a simple linear regression model, <span class="math inline">\(Y = X\beta\)</span>, we are estimating the values for <span class="math inline">\(\beta\)</span>, and the estimated linear predictor (lp) is then <span class="math inline">\(X\hat{\beta}\)</span>, where <span class="math inline">\(\hat{\beta}\)</span> are our estimated coefficients. In simple survival models, the linear predictor is the same quantity (but estimated in a slightly more complicated way). The learner implementations in <code>mlr3proba</code> are primarily machine-learning focused and few of these models have a simple linear form, which means that <code>lp</code> cannot be computed for most of these. In practice, when used for prediction, <code>lp</code> is a proxy for a relative risk/continuous ranking prediction, which is discussed next.</p>
</section><section id="predict_type-crank" class="level4 unnumbered unlisted"><h4 class="unnumbered unlisted anchored" data-anchor-id="predict_type-crank">predict_type = “crank”</h4>
<p>The final prediction type, <code>crank</code>, is the most common in survival analysis and perhaps also the most confusing. Academic texts will often refer to ‘risk’ predictions in survival analysis (hence why survival models are often known as ‘risk prediction models’), without defining what ‘risk’ means. Often, risk is defined as <span class="math inline">\(\exp(\eta)\)</span> as this is a common quantity found in simple linear survival models. However, sometimes risk is defined as <span class="math inline">\(\exp(-\eta)\)</span>, and sometimes it can be an arbitrary quantity that does not have a meaningful interpretation. To prevent this confusion in <code>mlr3proba</code>, we define the predict type <code>crank</code>, which stands for <strong>c</strong>ontinuous <strong>rank</strong>ing. This is best explained by example; continuing from the previous we output the first three <code>crank</code> predictions.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction_cph</span><span class="op">$</span><span class="va">crank</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      1       2       3 
-0.4356 -3.1265  0.4090 </code></pre>
</div>
</div>
<p>The output tells us that the first rat is at the lowest risk of death (smaller values represent lower risk) and the third rat is at the highest risk. The distance between predictions also tells us that the difference in risk between the second and third rats is smaller than the difference between the first and second. The actual values themselves are meaningless and therefore comparing <code>crank</code> values between samples (or papers or experiments) is not meaningful.</p>
<p>The <code>crank</code> prediction type is informative and common in practice because it allows identifying observations at lower/higher risk to each other, which is useful for resource allocation, e.g., which patient should be given an expensive treatment, and clinical trials, e.g., are people in a treatment arm at lower risk of disease X than people in the control arm.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpreting Survival Risk
</div>
</div>
<div class="callout-body-container callout-body">
<p>The interpretation of ‘risk’ for survival predictions differs across R packages and sometimes even between models in the same package. In <code>mlr3proba</code> there is one consistent interpretation of <code>crank</code>: lower values represent a lower risk of the event taking place and higher values represent higher risk.</p>
</div>
</div>
</section></section><section id="measuresurv" class="level3" data-number="13.2.3"><h3 data-number="13.2.3" class="anchored" data-anchor-id="measuresurv">
<span class="header-section-number">13.2.3</span> MeasureSurv</h3>
<p>Survival models in <code>mlr3proba</code> are evaluated with <a href="https://mlr3proba.mlr-org.com/reference/MeasureSurv.html"><code>MeasureSurv</code></a> objects, which are constructed in the usual way with <code><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr()</a></code>.</p>
<p>In general survival measures can be grouped into the following:</p>
<ol type="1">
<li>Discrimination measures – Quantify if a model correctly identifies if one observation is at higher risk than another. Evaluate <code>crank</code> and/or <code>lp</code> predictions.</li>
<li>Calibration measures – Quantify if the average prediction is close to the truth (all definitions of calibration are unfortunately vague in a survival context). Evaluate <code>crank</code> and/or <code>lp</code> predictions.</li>
<li>Scoring rules – Quantify if probabilistic predictions are close to true values. Evaluate <code>distr</code> predictions.</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_measures</span><span class="op">)</span><span class="op">[</span></span>
<span>  <span class="va">task_type</span> <span class="op">==</span> <span class="st">"surv"</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"key"</span>, <span class="st">"predict_type"</span><span class="op">)</span><span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustFPC has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustFPC.
Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustFPC has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustFPC.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustSil has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustSil.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustFPC has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustFPC.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                  key predict_type
1:         surv.brier        distr
2:   surv.calib_alpha        distr
3:    surv.calib_beta           lp
4:   surv.calib_index        distr
5: surv.chambless_auc           lp</code></pre>
</div>
</div>
<p>There is not a consensus in the literature around the ‘best’ survival measures to use to evaluate models. We recommend ISBS (Integrated Survival Brier Score) (<code>msr("surv.graf")</code>) to evaluate the quality of <code>distr</code> predictions, concordance index (<code>msr("surv.cindex")</code>) to evaluate a model’s discrimination, and D-Calibration (<code>msr("surv.dcalib")</code>) to evaluate a model’s calibration.</p>
<p>Using these measures, we can now evaluate our predictions from the previous example.</p>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction_cph</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"surv.graf"</span>, <span class="st">"surv.cindex"</span>, <span class="st">"surv.dcalib"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  surv.graf surv.cindex surv.dcalib 
    0.06064     0.78928     0.82181 </code></pre>
</div>
</div>
<p>The model’s performance seems okay as the ISBS and DCalib are relatively low and the C-index is greater than 0.5 however it is very hard to determine the performance of any survival model without comparing it to some baseline (usually the Kaplan-Meier).</p>
</section><section id="sec-surv-comp" class="level3" data-number="13.2.4"><h3 data-number="13.2.4" class="anchored" data-anchor-id="sec-surv-comp">
<span class="header-section-number">13.2.4</span> Composition</h3>
<p>Throughout <code>mlr3proba</code> documentation we refer to “native” and “composed” predictions. We define a ‘native’ prediction as the prediction made by a model without any post-processing, whereas a ‘composed’ prediction is returned after post-processing.</p>
<section id="internal-composition" class="level4" data-number="13.2.4.1"><h4 data-number="13.2.4.1" class="anchored" data-anchor-id="internal-composition">
<span class="header-section-number">13.2.4.1</span> Internal Composition</h4>
<p><code>mlr3proba</code> makes use of composition internally to return a <code>"crank"</code> prediction for every learner. This is to ensure that we can meaningfully benchmark all models according to at least one criterion (discrimination performance). The package uses the following rules to create <code>"crank"</code> predictions:</p>
<ol type="1">
<li>If a model returns a ‘risk’ prediction then <code>crank = risk</code> (we may multiply this by <span class="math inline">\(-1\)</span> to ensure the ‘low-value low-risk’ interpretation).</li>
<li>Else if a model returns a <code>response</code> prediction then we set <code>crank = -response</code>.</li>
<li>Else if a model returns a <code>lp</code> prediction then we set <code>crank = lp</code> (or <code>crank = -lp</code> if needed).</li>
<li>Else if a model returns a <code>distr</code> prediction then we set <code>crank</code> as the sum of the cumulative hazard function (see <span class="citation" data-cites="Sonabend2022">R. Sonabend, Bender, and Vollmer (<a href="../references.html#ref-Sonabend2022" role="doc-biblioref">2022</a>)</span> for full discussion as to why we picked this method).</li>
</ol></section><section id="explicit-composition-and-pipelines" class="level4" data-number="13.2.4.2"><h4 data-number="13.2.4.2" class="anchored" data-anchor-id="explicit-composition-and-pipelines">
<span class="header-section-number">13.2.4.2</span> Explicit Composition and Pipelines</h4>
<p>At the start of this section, we mentioned that it is possible to transform prediction types between each other. In <code>mlr3proba</code> this is possible with ‘compositor’ pipelines (<a href="../chapter7/sequential_pipelines.html" class="quarto-xref"><span>Chapter 7</span></a>). There are several pipelines implemented in the package but three in particular focus on predict type transformation:</p>
<ol type="1">
<li>
<a href="https://mlr3proba.mlr-org.com/reference/mlr_graphs_crankcompositor.html"><code>pipeline_crankcompositor()</code></a> – Transforms a <code>"distr"</code> prediction to <code>"crank"</code>
</li>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/mlr_graphs_distrcompositor.html"><code>pipeline_distrcompositor()</code></a> – Transforms a <code>"lp"</code> prediction to <code>"distr"</code>
</li>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/mlr_graphs_responsecompositor.html"><code>pipeline_responsecompositor()</code></a> – Transforms a <code>"distr"</code> prediction to <code>"response"</code> (survival time)</li>
</ol>
<p>We internally use a version of the first pipeline whenever we return predictions from survival models so that every model has a <code>"crank"</code> prediction type - so only use the first pipeline to overwrite these ranking predictions. In practice, the second pipeline is more common as Cox or Accelerated Failure Time (AFT) type models always return a linear predictor (<code>"lp"</code>), but sometimes the internal <code><a href="https://rspatial.github.io/terra/reference/predict.html">predict()</a></code> functions don’t provide a transformation to a survival distribution prediction (<code>"distr"</code>). The third pipeline summarizes the predicted survival curves to a single number (expected survival time), and as previously mentioned, are rarely useful for evaluating the performance of survival machine learning models.</p>
<p>In the example below we load the <code>rats</code> dataset, remove factor columns, and then partition the data into training and testing. We construct the <code>distrcompositor</code> pipeline around a survival XGBoost Accelerated Failure Time (AFT) learner (<code>lrn("surv.xgboost.aft")</code>) which by default makes predictions for <code>"lp"</code>, <code>"crank"</code> and <code>"response"</code>. In the pipeline, we specify that we will estimate the baseline distribution with a Kaplan-Meier estimator (<code>estimator = "kaplan"</code>) and that we want to assume an AFT form for our estimated distribution (<code>form = "aft"</code>). We then train and predict in the usual way and in our output we can now see a <code>distr</code> prediction.</p>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">mlr3extralearners</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_rats</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"rats"</span><span class="op">)</span><span class="op">$</span><span class="fu">select</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"litter"</span>, <span class="st">"rx"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">split</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">tsk_rats</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"surv.xgboost.aft"</span>, nrounds <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># no distr output</span></span>
<span><span class="va">learner</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionSurv&gt; for 99 observations: ────────────────────────────────
 row_ids time status  crank     lp response
       1  101  FALSE -4.648 -4.648    104.3
       6  102  FALSE -5.576 -5.576    264.1
       9  104  FALSE -5.576 -5.576    264.1
     ---  ---    ---    ---    ---      ---
     294   64  FALSE -4.754 -4.754    116.0
     295  104  FALSE -4.661 -4.661    105.8
     296  104  FALSE -4.661 -4.661    105.8</code></pre>
</div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span></span>
<span>  <span class="st">"distrcompositor"</span>,</span>
<span>  learner <span class="op">=</span> <span class="va">learner</span>,</span>
<span>  estimator <span class="op">=</span> <span class="st">"kaplan"</span>,</span>
<span>  form <span class="op">=</span> <span class="st">"aft"</span>,</span>
<span>  graph_learner <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># now with distr</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">train</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_rats</span>, <span class="va">split</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionSurv&gt; for 99 observations: ────────────────────────────────
 row_ids time status  crank     lp response     distr
       1  101  FALSE -4.648 -4.648    104.3 &lt;list[1]&gt;
       6  102  FALSE -5.576 -5.576    264.1 &lt;list[1]&gt;
       9  104  FALSE -5.576 -5.576    264.1 &lt;list[1]&gt;
     ---  ---    ---    ---    ---      ---       ---
     294   64  FALSE -4.754 -4.754    116.0 &lt;list[1]&gt;
     295  104  FALSE -4.661 -4.661    105.8 &lt;list[1]&gt;
     296  104  FALSE -4.661 -4.661    105.8 &lt;list[1]&gt;</code></pre>
</div>
</div>
<p>Mathematically, we have done the following:</p>
<ol type="1">
<li>Assume our estimated distribution will have the form <span class="math inline">\(S(t) = S_0(\frac{t}{\exp(\eta)})\)</span> where <span class="math inline">\(S\)</span> is the survival function, <span class="math inline">\(S_0\)</span> is the baseline survival function and <span class="math inline">\(\eta\)</span> is the linear predictor.</li>
<li>Estimate <span class="math inline">\(\hat{\eta}\)</span> prediction using XGBoost</li>
<li>Estimate <span class="math inline">\(\hat{S}_0(t)\)</span> with the Kaplan-Meier estimator</li>
<li>Put this all together as <span class="math inline">\(S(t) = \hat{S}_0(\frac{t}{\exp(\hat{\eta})})\)</span>
</li>
</ol>
<p>For more detail about prediction types and composition we recommend <span class="citation" data-cites="Kalbfleisch2011">Kalbfleisch and Prentice (<a href="../references.html#ref-Kalbfleisch2011" role="doc-biblioref">2011</a>)</span>.</p>
</section></section><section id="sec-survival-all" class="level3" data-number="13.2.5"><h3 data-number="13.2.5" class="anchored" data-anchor-id="sec-survival-all">
<span class="header-section-number">13.2.5</span> Putting It All Together</h3>
<p>Finally, we will put all the above into practice in a small benchmark experiment. We first load <code>tsk("grace")</code> (which only has numeric features) and sample 500 rows randomly. We then select the ISBS, D-Calibration, and C-index to evaluate predictions, set up the same pipeline we used in the previous experiment, and load a Cox PH and Kaplan-Meier estimator. We run our experiment with three-fold CV and aggregate the results.</p>
<div class="cell">
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">mlr3extralearners</span><span class="op">)</span></span>
<span></span>
<span><span class="va">tsk_grace</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"grace"</span><span class="op">)</span></span>
<span><span class="va">tsk_grace</span><span class="op">$</span><span class="fu">filter</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">tsk_grace</span><span class="op">$</span><span class="va">nrow</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">msr_txt</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"surv.graf"</span>, <span class="st">"surv.cindex"</span>, <span class="st">"surv.dcalib"</span><span class="op">)</span></span>
<span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="va">msr_txt</span><span class="op">)</span></span>
<span></span>
<span><span class="va">graph_learner</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/ppl.html">ppl</a></span><span class="op">(</span></span>
<span>  <span class="st">"distrcompositor"</span>,</span>
<span>  learner <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"surv.xgboost.aft"</span>, nrounds <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>  estimator <span class="op">=</span> <span class="st">"kaplan"</span>,</span>
<span>  form <span class="op">=</span> <span class="st">"aft"</span>,</span>
<span>  graph_learner <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  scale_lp <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">graph_learner</span><span class="op">$</span><span class="va">id</span> <span class="op">=</span> <span class="st">"XGBoost-AFT"</span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"surv.coxph"</span>, <span class="st">"surv.kaplan"</span><span class="op">)</span><span class="op">)</span>, <span class="va">graph_learner</span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_grace</span>, <span class="va">learners</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"learner_id"</span>, <span class="va">..msr_txt</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    learner_id surv.graf surv.cindex surv.dcalib
1:  surv.coxph   0.09898      0.8422       5.329
2: surv.kaplan   0.20225      0.5000       4.149
3: XGBoost-AFT   0.21337      0.8372       5.790</code></pre>
</div>
</div>
<p>In this small experiment, XGBoost-AFT and Cox PH have the best discrimination, the Kaplan-Meier baseline has the best calibration, and Cox PH has the best overall predictive accuracy (with the lowest ISBS).</p>
</section></section><section id="sec-density" class="level2" data-number="13.3"><h2 data-number="13.3" class="anchored" data-anchor-id="sec-density">
<span class="header-section-number">13.3</span> Density Estimation</h2>
<p>Density estimation is a learning task to estimate the unknown distribution from which a univariate dataset is generated or put more simply to estimate the probability density (or mass) function for a single variable. As with survival analysis, density estimation is implemented in <code>mlr3proba</code>, as both can make probability distribution predictions (hence the name “<strong>mlr3proba</strong>bilistic”). Unconditional density estimation (i.e.&nbsp;estimation of a target without any covariates) is viewed as an unsupervised task, which means the ‘truth’ is never known. For a good overview of density estimation see <span class="citation" data-cites="Silverman1986">Silverman (<a href="../references.html#ref-Silverman1986" role="doc-biblioref">1986</a>)</span>.</p>
<p>The package <code>mlr3proba</code> extends <code>mlr3</code> with the following objects for density estimation:</p>
<ul>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/TaskDens.html"><code>TaskDens</code></a> to define density tasks.</li>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/LearnerDens.html"><code>LearnerDens</code></a> as the base class for density estimators.</li>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/PredictionDens.html"><code>PredictionDens</code></a> for density predictions.</li>
<li>
<a href="https://mlr3proba.mlr-org.com/reference/MeasureDens.html"><code>MeasureDens</code></a> as a specialized class for density performance measures.</li>
</ul>
<p>We will consider each in turn.</p>
<section id="taskdens" class="level3" data-number="13.3.1"><h3 data-number="13.3.1" class="anchored" data-anchor-id="taskdens">
<span class="header-section-number">13.3.1</span> TaskDens</h3>
<p>As density estimation is an unsupervised task, there is no target for prediction. In the code below we construct a density task using <a href="https://mlr3proba.mlr-org.com/reference/as_task_dens.html"><code>as_task_dens()</code></a> which takes one argument, a <code>data.frame</code> type object with exactly one column (which we will use to estimate the underlying distribution).</p>
<div class="cell">
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tsk_dens</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3proba.mlr-org.com/reference/as_task_dens.html">as_task_dens</a></span><span class="op">(</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/data.table.html">data.table</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tsk_dens</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;TaskDens&gt; (1000x1) ──────────────────────────────────────────────────
• Target:
• Properties: -
• Features (1):
  • dbl (1): x</code></pre>
</div>
</div>
<p>As with other tasks, we have included a couple of tasks that come shipped with <code>mlr3proba</code>:</p>
<div class="cell">
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_tasks</span><span class="op">)</span><span class="op">[</span><span class="va">task_type</span> <span class="op">==</span> <span class="st">"dens"</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        key                  label nrow ncol
1: faithful Old Faithful Eruptions  272    1
2:   precip   Annual Precipitation   70    1</code></pre>
</div>
</div>
</section><section id="learnerdens-and-predictiondens" class="level3" data-number="13.3.2"><h3 data-number="13.3.2" class="anchored" data-anchor-id="learnerdens-and-predictiondens">
<span class="header-section-number">13.3.2</span> LearnerDens and PredictionDens</h3>
<p>Density learners may return the following prediction types:</p>
<ol type="1">
<li>
<code>distr</code> – probability distribution</li>
<li>
<code>pdf</code> – probability density function</li>
<li>
<code>cdf</code> – cumulative distribution function</li>
</ol>
<p>All learners will return a <code>distr</code> and <code>pdf</code> prediction but only some can make <code>cdf</code> predictions. Again, the <code>distr</code> predict type is implemented using <code>distr6</code>. In the code below we train and ‘predict’ with a histogram learner and then plot the estimated probability density function (<a href="#fig-dens-hist" class="quarto-xref">Figure&nbsp;<span>13.4</span></a>), which closely matches the underlying Normally-distributed data.</p>
<div class="cell">
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_hist</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"dens.hist"</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_hist</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_dens</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">900</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_dens</span>, <span class="fl">901</span><span class="op">:</span><span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq.int</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span>, <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">prediction</span><span class="op">$</span><span class="va">distr</span><span class="op">$</span><span class="fu">pdf</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">df</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu">geom_line</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dens-hist" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Image shows a line plot with x-axis between (-2,2) and y-axis between (0,0.4). The plot closely resembles a Normal(0, 1) distribution with a peak at 0.4.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dens-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-dens-hist-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Image shows a line plot with x-axis between (-2,2) and y-axis between (0,0.4). The plot closely resembles a Normal(0, 1) distribution with a peak at 0.4.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dens-hist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.4: Predicted density from the histogram learner, which closely resembles the underlying N(0, 1) data.
</figcaption></figure>
</div>
</div>
</div>
<p>The <code>pdf</code> and <code>cdf</code> predict types are simply wrappers around <code>distr$pdf</code> and <code>distr$cdf</code> respectively:</p>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_hist</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_dens</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_dens</span>, <span class="fl">11</span><span class="op">:</span><span class="fl">13</span><span class="op">)</span></span>
<span><span class="co"># pdf and cdf columns in output</span></span>
<span><span class="va">prediction</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionDens&gt; for 3 observations: ─────────────────────────────────
 row_ids pdf    cdf
      11 0.6 0.4849
      12 0.2 0.3992
      13 0.6 0.6208
1 variable not shown: [distr]</code></pre>
</div>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># comparing cdf from prediction to $cdf method from distr</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">prediction</span><span class="op">$</span><span class="va">distr</span><span class="op">$</span><span class="fu">cdf</span><span class="op">(</span><span class="va">tsk_dens</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="fl">11</span><span class="op">:</span><span class="fl">13</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="va">prediction</span><span class="op">$</span><span class="va">cdf</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       [,1]   [,2]
[1,] 0.4849 0.4849
[2,] 0.3992 0.3992
[3,] 0.6208 0.6208</code></pre>
</div>
</div>
</section><section id="measuredens-and-putting-it-all-together" class="level3" data-number="13.3.3"><h3 data-number="13.3.3" class="anchored" data-anchor-id="measuredens-and-putting-it-all-together">
<span class="header-section-number">13.3.3</span> MeasureDens and Putting It All Together</h3>
<p>At the time of publication, the only measure implemented in <code>mlr3proba</code> for density estimation is logloss, which is defined in the same way as in classification, <span class="math inline">\(L(y) = -\log(\hat{f}_Y(y))\)</span>, where <span class="math inline">\(\hat{f}_Y\)</span> is our estimated probability density function. Putting this together with the above we are now ready to train a density learner, estimate a distribution, and evaluate our estimation:</p>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">msr_logloss</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"dens.logloss"</span><span class="op">)</span></span>
<span><span class="va">msr_logloss</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;MeasureDensLogloss&gt; (dens.logloss): Log Loss ────────────────────────
• Packages: mlr3 and mlr3proba
• Range: [0, Inf]
• Minimize: TRUE
• Average: macro
• Parameters: eps=1e-15
• Properties: -
• Predict type: pdf
• Predict sets: test
• Aggregator: mean()</code></pre>
</div>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">msr_logloss</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dens.logloss 
       0.877 </code></pre>
</div>
</div>
<p>This output is most easily interpreted when compared to other learners in a benchmark experiment, so let us put everything together to conduct a small benchmark study on <code>tsk("faithful")</code> task using some of the integrated density learners:</p>
<div class="cell">
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">mlr3extralearners</span><span class="op">)</span></span>
<span><span class="va">tsk_faithful</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"faithful"</span><span class="op">)</span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"dens.hist"</span>, <span class="st">"dens.pen"</span>, <span class="st">"dens.kde"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">measure</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"dens.logloss"</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_faithful</span>, <span class="va">learners</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measure</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">bmr</span>, measure <span class="op">=</span> <span class="va">measure</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-beyond-density" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Three boxplots labeled 'dens.hist', 'dens.pen', 'dens.kde'. y-axis is 'dens.logloss' between 0.9 and 1.2. 'dens.hist' is a narrow boxplot between 1.0 and 1.1. 'dens.pen' is very wide between 0.95 and 2.1. 'dens.kde' is narrow between 0.95 and 1.0.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-density-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Three boxplots labeled 'dens.hist', 'dens.pen', 'dens.kde'. y-axis is 'dens.logloss' between 0.9 and 1.2. 'dens.hist' is a narrow boxplot between 1.0 and 1.1. 'dens.pen' is very wide between 0.95 and 2.1. 'dens.kde' is narrow between 0.95 and 1.0.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-density-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.5: Three boxplots comparing performance of dens.hist, dens.pen, and dens.kde on <code>tsk("faithful")</code>.
</figcaption></figure>
</div>
</div>
</div>
<p>The results (<a href="#fig-beyond-density" class="quarto-xref">Figure&nbsp;<span>13.5</span></a>) of this experiment indicate that the sophisticated Penalized Density Estimator does not outperform the baseline histogram, but the Kernel Density Estimator has at least consistently better (i.e.&nbsp;lower) logloss results.</p>
</section></section><section id="sec-cluster" class="level2 page-columns page-full" data-number="13.4"><h2 data-number="13.4" class="anchored" data-anchor-id="sec-cluster">
<span class="header-section-number">13.4</span> Cluster Analysis</h2>
<p>Cluster analysis is another unsupervised task implemented in <code>mlr3</code>. The objective of cluster analysis is to group data into clusters, where each cluster contains similar observations. The similarity is based on specified metrics that are task and application-dependent. Unlike classification where we try to predict a class for each observation, in cluster analysis there is no ‘true’ label or class to predict.</p>
<p>The package <a href="https://mlr3cluster.mlr-org.com"><code>mlr3cluster</code></a> extends <code>mlr3</code> with the following objects for cluster analysis:</p>
<ul>
<li>
<a href="https://mlr3cluster.mlr-org.com/reference/TaskClust.html"><code>TaskClust</code></a> to define clustering tasks</li>
<li>
<a href="https://mlr3cluster.mlr-org.com/reference/LearnerClust.html"><code>LearnerClust</code></a> as the base class for clustering learners</li>
<li>
<a href="https://mlr3cluster.mlr-org.com/reference/PredictionClust.html"><code>PredictionClust</code></a> as the specialized class for <a href="https://mlr3.mlr-org.com/reference/Prediction.html"><code>Prediction</code></a> objects</li>
<li>
<a href="https://mlr3cluster.mlr-org.com/reference/MeasureClust.html"><code>MeasureClust</code></a> as the specialized class for performance measures</li>
</ul>
<p>We will consider each in turn.</p>
<section id="taskclust" class="level3" data-number="13.4.1"><h3 data-number="13.4.1" class="anchored" data-anchor-id="taskclust">
<span class="header-section-number">13.4.1</span> TaskClust</h3>
<p>Similarly to density estimation (<a href="#sec-density" class="quarto-xref"><span>Section 13.3</span></a>), there is no target for prediction and so no <code>truth</code> field in <a href="https://mlr3cluster.mlr-org.com/reference/TaskClust.html"><code>TaskClust</code></a>. By example, we will look at the <a href="https://www.rdocumentation.org/packages/cluster/topics/ruspini"><code>ruspini</code></a> dataset, which has 75 rows and two columns and was first introduced in <span class="citation" data-cites="Ruspini1970">Ruspini (<a href="../references.html#ref-Ruspini1970" role="doc-biblioref">1970</a>)</span> to illustrate different clustering techniques. The observations in the dataset form four natural clusters (<a href="#fig-beyond-clust-ruspini" class="quarto-xref">Figure&nbsp;<span>13.6</span></a>). In the code below we construct a cluster task using <a href="https://mlr3cluster.mlr-org.com/reference/as_task_clust.html"><code>as_task_clust()</code></a> which only takes one argument, a <code>data.frame</code> type object.</p>
<div class="cell">
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://svn.r-project.org/R-packages/trunk/cluster/">cluster</a></span><span class="op">)</span></span>
<span><span class="va">tsk_ruspini</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3cluster.mlr-org.com/reference/as_task_clust.html">as_task_clust</a></span><span class="op">(</span><span class="va">ruspini</span><span class="op">)</span></span>
<span><span class="va">tsk_ruspini</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;TaskClust&gt; (75x2) ───────────────────────────────────────────────────
• Target:
• Properties: -
• Features (2):
  • int (2): x, y</code></pre>
</div>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tsk_ruspini</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="co"># print first 3 rows</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    x  y
1:  4 53
2:  5 63
3: 10 59</code></pre>
</div>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-ruspini" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Four grids. Top-left shows a curve increasing sharply between (0,0.003) and (30,0.012) then decreasing to (120, 0.003). Top-right just says 'Corr: 0.065'. Bottom-left shows four distinct clusters of points. Bottom-right increases from (0, 50) to (140, 150) then decreases to (155, 100).">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-ruspini-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-ruspini-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Four grids. Top-left shows a curve increasing sharply between (0,0.003) and (30,0.012) then decreasing to (120, 0.003). Top-right just says 'Corr: 0.065'. Bottom-left shows four distinct clusters of points. Bottom-right increases from (0, 50) to (140, 150) then decreases to (155, 100).">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-ruspini-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.6: Distribution of the <code>ruspini</code> dataset.
</figcaption></figure>
</div>
</div>
</div>
<p>Technically, we did not need to create a new task for the <code>ruspini</code> dataset since it is already included in the package, along with one other task:</p>
<div class="cell">
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html">as.data.table</a></span><span class="op">(</span><span class="va">mlr_tasks</span><span class="op">)</span><span class="op">[</span><span class="va">task_type</span> <span class="op">==</span> <span class="st">"clust"</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">4</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         key      label nrow ncol
1:   ruspini    Ruspini   75    2
2: usarrests US Arrests   50    4</code></pre>
</div>
</div>
</section><section id="learnerclust-and-predictionclust" class="level3 page-columns page-full" data-number="13.4.2"><h3 data-number="13.4.2" class="anchored" data-anchor-id="learnerclust-and-predictionclust">
<span class="header-section-number">13.4.2</span> LearnerClust and PredictionClust</h3>
<p>As with density estimation, we refer to <code>training</code> and <code>predicting</code> for clustering to be consistent with the <code>mlr3</code> interface, but strictly speaking, this should be <code>clustering</code> and <code>assigning</code> (the latter we will return to shortly). Two <code>predict_types</code> are available for clustering learners:</p>
<ol type="1">
<li>
<code>"partition"</code> – Estimate of which cluster an observation falls into</li>
<li>
<code>"prob"</code> – Probability of an observation belonging to each cluster</li>
</ol>
<p>Similarly to classification, prediction types of clustering learners are either deterministic (<code>"partition"</code>) or probabilistic (<code>"prob"</code>).</p>
<p>Below we construct a C-Means clustering learner with <code>"prob"</code> prediction type and three clusters (<code>centers = 3</code>), train it on the <code>ruspini</code> dataset and then return the cluster assignments (<code>$assignments</code>) for six random observations.</p>
<div class="cell">
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_cmeans</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.cmeans"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span>, centers <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">lrn_cmeans</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;LearnerClustCMeans&gt; (clust.cmeans): Fuzzy C-Means Clustering Learner 
• Model: -
• Parameters: centers=3
• Packages: mlr3, mlr3cluster, and e1071
• Predict Types: partition and [prob]
• Feature Types: logical, integer, and numeric
• Encapsulation: none (fallback: -)
• Properties: complete, fuzzy, and partitional
• Other settings: use_weights = 'error'</code></pre>
</div>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_cmeans</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span></span>
<span><span class="va">lrn_cmeans</span><span class="op">$</span><span class="va">assignments</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">$</span><span class="va">nrow</span>, <span class="fl">6</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1 1 1 3 1 1</code></pre>
</div>
</div>
<p>As clustering is unsupervised, it often does not make sense to use <code>predict</code> for new data however this is still possible using the <code>mlr3</code> interface.</p>
<div class="cell">
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using different data for estimation (rare use case)</span></span>
<span><span class="va">lrn_cmeans</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ruspini</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">30</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_ruspini</span>, <span class="fl">31</span><span class="op">:</span><span class="fl">32</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionClust&gt; for 2 observations: ────────────────────────────────
 row_ids partition prob.1 prob.2   prob.3
      31         2 0.2750 0.7167 0.008326
      32         2 0.3724 0.6212 0.006467</code></pre>
</div>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># using same data as for estimation (common use case)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="va">lrn_cmeans</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, <span class="va">tsk_ruspini</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-ruspini-estimated" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Four grids. Top-left shows three overlapping curves in purple (cluster 1), blue (cluster 2) and green (cluster 3). The purple and blue curves are zero in most places but then peak at (30, 120) and (60, 120) respectively. The green curve starts at (0,0) then increases slowly to (40, 120) then decreases bumpily to (120, 60). Top-right says '-0.78' in green (cluster 3), '0' in blue (cluster 2), and '-0.05' in purple (cluster 1). Bottom-left shows four distinct clusters of points, two clusters are green, one (bottom) is blue, one (bottom left) is purple. Bottom-right: line graphs that show a similar but inverted shape as top-left.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-ruspini-estimated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-ruspini-estimated-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Four grids. Top-left shows three overlapping curves in purple (cluster 1), blue (cluster 2) and green (cluster 3). The purple and blue curves are zero in most places but then peak at (30, 120) and (60, 120) respectively. The green curve starts at (0,0) then increases slowly to (40, 120) then decreases bumpily to (120, 60). Top-right says '-0.78' in green (cluster 3), '0' in blue (cluster 2), and '-0.05' in purple (cluster 1). Bottom-left shows four distinct clusters of points, two clusters are green, one (bottom) is blue, one (bottom left) is purple. Bottom-right: line graphs that show a similar but inverted shape as top-left.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-ruspini-estimated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.7: Distribution of the estimated clusters.
</figcaption></figure>
</div>
</div>
</div>
<div class="page-columns page-full"><p>While two prediction types are possible, there are some learners where ‘prediction’ can never make sense, for example in hierarchical clustering. In hierarchical clustering, the goal is to build a hierarchy of nested clusters by either splitting large clusters into smaller ones or merging smaller clusters into bigger ones. The final result is a tree or dendrogram which can change if a new data point is added. For consistency, <code>mlr3cluster</code> offers a <code>predict</code> method for hierarchical clusters but with a warning:</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Hierarchical Clustering</span></div></div>
<div class="cell">
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_hclust</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.hclust"</span>, k <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">lrn_hclust</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_ruspini</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in warn_prediction_useless(self$id): Learner 'clust.hclust'
doesn't predict on new data and predictions may not make sense on new
data.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionClust&gt; for 75 observations: ───────────────────────────────
 row_ids partition
       1         1
       2         1
       3         1
     ---       ---
      73         1
      74         1
      75         1</code></pre>
</div>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">lrn_hclust</span><span class="op">)</span> <span class="op">+</span> <span class="fu">theme</span><span class="op">(</span>axis.text <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">5.5</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-dend" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Plot shows a horizontal line that connects two vertical lines. Each vertical line connects to another horizontal line that splits into two more vertical lines, which continues for up to nine breaks.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-dend-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-dend-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Plot shows a horizontal line that connects two vertical lines. Each vertical line connects to another horizontal line that splits into two more vertical lines, which continues for up to nine breaks.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-dend-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.8: Dendrogram representing hierarchical clustering of the <code>ruspini</code> dataset. y-axis is similarity of points such that the lower observations (x-axis) are connected, the greater their similarity. The top split represents the separation of the two clusters.
</figcaption></figure>
</div>
</div>
</div>
<p>In this case, the <code>predict</code> method simply cuts the dendrogram into the number of clusters specified by <code>k</code> parameter of the learner.</p>
</section><section id="measureclust" class="level3" data-number="13.4.3"><h3 data-number="13.4.3" class="anchored" data-anchor-id="measureclust">
<span class="header-section-number">13.4.3</span> MeasureClust</h3>
<p>As previously discussed, unsupervised tasks do not have ground truth data to compare to in model evaluation. However, we can still measure the quality of cluster assignments by quantifying how closely objects within the same cluster are related (cluster cohesion) as well as how distinct different clusters are from each other (cluster separation). There are a few built-in evaluation metrics available to assess the quality of clustering, which can be found by searching the <a href="https://mlr3.mlr-org.com/reference/mlr_measures.html"><code>mlr_measures</code></a> dictionary.</p>
<p>Two common measures are the within sum of squares (WSS) measure (<code>msr("clust.wss")</code>) and the silhouette coefficient (<code>msr("clust.silhouette")</code>). WSS calculates the sum of squared differences between observations and centroids, which is a quantification of cluster cohesion (smaller values indicate the clusters are more compact). The silhouette coefficient quantifies how well each point belongs to its assigned cluster versus neighboring clusters, where scores closer to <code>1</code> indicate well clustered and scores closer to <code>-1</code> indicate poorly clustered. Note that the silhouette measure in <code>mlr3cluster</code> returns the mean silhouette score across all observations and when there is only a single cluster, the measure simply outputs 0.</p>
<p>Putting this together with the above we can now score our cluster estimation (note we must pass the <code>task</code> to <code>$score</code>):</p>
<div class="cell">
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msrs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"clust.wss"</span>, <span class="st">"clust.silhouette"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustFPC has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustFPC.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustSil has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustSil.</code></pre>
</div>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span>, task <span class="op">=</span> <span class="va">tsk_ruspini</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       clust.wss clust.silhouette 
       5.116e+04        6.414e-01 </code></pre>
</div>
</div>
<p>The very high WSS and middling mean silhouette coefficient indicate that our clusters could do with a bit more work.</p>
<p>Often reducing an unsupervised task to a quantitative measure may not be useful (given no ground truth) and instead visualization (discussed next) may be a more effective tool for assessing the quality of the clusters.</p>
</section><section id="visualization" class="level3" data-number="13.4.4"><h3 data-number="13.4.4" class="anchored" data-anchor-id="visualization">
<span class="header-section-number">13.4.4</span> Visualization</h3>
<p>As clustering is an unsupervised task, visualization can be essential not just for ‘evaluating’ models but also for determining if our learners are performing as expected for our task. This section will look at visualizations for supporting clustering choices and following that we will consider plots for evaluating model performance.</p>
<section id="visualizing-clusters" class="level4" data-number="13.4.4.1"><h4 data-number="13.4.4.1" class="anchored" data-anchor-id="visualizing-clusters">
<span class="header-section-number">13.4.4.1</span> Visualizing Clusters</h4>
<p>It is easy to rely on clustering measures to assess the quality of clustering however this should be done with care as choosing between models may come down to other decisions such as how clusters are formed. By example, consider data generated by <a href="https://www.rdocumentation.org/packages/mlbench/topics/mlbench.spirals"><code>mlbench.spirals</code></a>, which results in two individual lines that spiral around each other (<a href="#fig-beyond-clust-spirals" class="quarto-xref">Figure&nbsp;<span>13.9</span></a>).</p>
<div class="cell">
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">spirals</span> <span class="op">=</span> <span class="fu">mlbench</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mlbench/man/mlbench.spirals.html">mlbench.spirals</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">300</span>, sd <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">tsk_spirals</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3cluster.mlr-org.com/reference/as_task_clust.html">as_task_clust</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">spirals</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">tsk_spirals</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-spirals" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Grid of four plots. Top-left: line increasing from (-1,0.1) to (0,0.5) then decreasing to (1,0.1). Top-right: text that says 'Corr: -0.145'. Bottom-left: two lines of dots that are in tight, non-overlapping spirals around each other. Bottom-right: same shape as top-left.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-spirals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-spirals-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Grid of four plots. Top-left: line increasing from (-1,0.1) to (0,0.5) then decreasing to (1,0.1). Top-right: text that says 'Corr: -0.145'. Bottom-left: two lines of dots that are in tight, non-overlapping spirals around each other. Bottom-right: same shape as top-left.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-spirals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.9: Distribution of <code>spirals</code> data.
</figcaption></figure>
</div>
</div>
</div>
<p>Now let us see what happens when fit two clustering learners on this data:</p>
<div class="cell">
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.kmeans"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.dbscan"</span>, eps <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_spirals</span>, <span class="va">learners</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"insample"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"clust.silhouette"</span><span class="op">)</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">7</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Superclass MeasureClust has cloneable=FALSE, but subclass MeasureClustSil has cloneable=TRUE. A subclass cannot be cloneable when its superclass is not cloneable, so cloning will be disabled for MeasureClustSil.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     learner_id clust.silhouette
1: clust.kmeans          0.37283
2: clust.dbscan          0.02932</code></pre>
</div>
</div>
<p>We can see that K-means clustering gives us a higher average silhouette score and so we might conclude that a K-means learner with two centroids is a better choice than the DBSCAN method. However, now take a look at the cluster assignment plots in <a href="#fig-beyond-clust-spirals-pred" class="quarto-xref">Figure&nbsp;<span>13.10</span></a> (<code>autoplot.PredictionClust</code> is available but we do not use it here so we can highlight two particular plots).</p>
<div class="cell">
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span><span class="co"># get K-Means and DBSCAN partitions</span></span>
<span><span class="va">pred_kmeans</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">bmr</span><span class="op">$</span><span class="fu">resample_result</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">$</span><span class="fu">prediction</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">partition</span><span class="op">)</span></span>
<span><span class="va">pred_dbscan</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">bmr</span><span class="op">$</span><span class="fu">resample_result</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">$</span><span class="fu">prediction</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">partition</span><span class="op">)</span></span>
<span><span class="co"># plot</span></span>
<span><span class="va">df_kmeans</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">tsk_spirals</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span>, clust <span class="op">=</span> <span class="va">pred_kmeans</span><span class="op">)</span></span>
<span><span class="va">df_dbscan</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">tsk_spirals</span><span class="op">$</span><span class="fu">data</span><span class="op">(</span><span class="op">)</span>, clust <span class="op">=</span> <span class="va">pred_dbscan</span><span class="op">)</span></span>
<span><span class="va">map</span> <span class="op">=</span> <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">V1</span>, y <span class="op">=</span> <span class="va">V2</span>, color <span class="op">=</span> <span class="va">clust</span><span class="op">)</span></span>
<span><span class="va">p_kmeans</span> <span class="op">=</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">df_kmeans</span>, <span class="va">map</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"K-means"</span><span class="op">)</span></span>
<span><span class="va">p_dbscan</span> <span class="op">=</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">df_dbscan</span>, <span class="va">map</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"DBSCAN"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_kmeans</span> <span class="op">+</span> <span class="va">p_dbscan</span> <span class="op">+</span> <span class="fu"><a href="https://patchwork.data-imaginist.com/reference/plot_layout.html">plot_layout</a></span><span class="op">(</span>guides <span class="op">=</span> <span class="st">"collect"</span><span class="op">)</span> <span class="op">&amp;</span> <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span> <span class="op">&amp;</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">&amp;</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_colour_viridis_d</a></span><span class="op">(</span>end <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-spirals-pred" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Two plots of the same spirals as in the previous plot. Left (K-means): points above the line x=y are purple (cluster 1) and other points are green (cluster 2). Right (DBSCAN): One of the spirals is purple and the other is green.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-spirals-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-spirals-pred-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Two plots of the same spirals as in the previous plot. Left (K-means): points above the line x=y are purple (cluster 1) and other points are green (cluster 2). Right (DBSCAN): One of the spirals is purple and the other is green.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-spirals-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.10: Comparing estimated clusters from <code>lrn("clust.kmeans")</code> and <code>lrn("clust.dbscan")</code>. Both create two distinct clusters that are separated in different ways.
</figcaption></figure>
</div>
</div>
</div>
<p>The two learners arrived at two different results to cleanly separate clusters – the K-means algorithm assigned points that are part of the same line into two different clusters whereas DBSCAN assigned each line to its own cluster. Which one of these approaches is correct? The answer is it depends on your specific task and the goal of cluster analysis. If we had only relied on the silhouette score, then the details of how the clustering was performed would have been masked and we would have been unable to decide which method was appropriate for the task.</p>
</section><section id="pca-and-silhouette-plots" class="level4" data-number="13.4.4.2"><h4 data-number="13.4.4.2" class="anchored" data-anchor-id="pca-and-silhouette-plots">
<span class="header-section-number">13.4.4.2</span> PCA and Silhouette Plots</h4>
<p>The two most important plots implemented in <a href="https://mlr3viz.mlr-org.com"><code>mlr3viz</code></a> to support the evaluation of cluster learners are PCA and silhouette plots.</p>
<p>Principal components analysis (PCA) is a commonly used dimension reduction method in ML to reduce the number of variables in a dataset or to visualize the most important ‘components’, which are linear transformations of the dataset features. Components are considered more important if they have higher variance (and therefore more predictive power). In the context of clustering, by plotting observations against the first two components, and then coloring them by cluster, we could visualize our high-dimensional dataset and we would expect to see observations in distinct groups.</p>
<p>Since our running example only has two features, PCA does not make sense to visualize the data. So we will use a task based on the <code>USArrests</code> dataset instead. By plotting the result of PCA (<a href="#fig-beyond-clust-usarrests" class="quarto-xref">Figure&nbsp;<span>13.11</span></a>), we see that our model has done a good job of separating observations into two clusters along the first two principal components.</p>
<div class="cell">
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tsk_usarrests</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"usarrests"</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.kmeans"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_usarrests</span><span class="op">)</span><span class="op">$</span></span>
<span>  <span class="fu">predict</span><span class="op">(</span><span class="va">tsk_usarrests</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, <span class="va">tsk_usarrests</span>, type <span class="op">=</span> <span class="st">"pca"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-usarrests" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Scatter plot of green (cluster 2) and purple (cluster 1) points. x-axis: PC1 (96.55%) between -0.3 and 0.2. y-axis: PC2 (2.78%) between -0.3 and 0.2. Points are cleanly separated into two clusters by color.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-usarrests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-usarrests-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Scatter plot of green (cluster 2) and purple (cluster 1) points. x-axis: PC1 (96.55%) between -0.3 and 0.2. y-axis: PC2 (2.78%) between -0.3 and 0.2. Points are cleanly separated into two clusters by color.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-usarrests-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.11: First two principal components using PCA on <code>tsk("usarrests")</code>.
</figcaption></figure>
</div>
</div>
</div>
<p>Silhouette plots visually assess the quality of the estimated clusters by visualizing if observations in a cluster are well-placed both individually and as a group. The plots include a dotted line which visualizes the average silhouette coefficient across all data points and each data point’s silhouette value is represented by a bar colored by their assigned cluster. In our particular case, the average silhouette index is 0.59. If the average silhouette value for a given cluster is below the average silhouette coefficient line then this implies that the cluster is not well defined.</p>
<p>Continuing with our new example, we find (<a href="#fig-beyond-clust-sil" class="quarto-xref">Figure&nbsp;<span>13.12</span></a>) that a lot of observations are actually below the average line and close to zero, and therefore the quality of our cluster assignments is not very good, meaning that many observations are likely assigned to the wrong cluster.</p>
<div class="cell">
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">prediction</span>, <span class="va">tsk_usarrests</span>, type <span class="op">=</span> <span class="st">"sil"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-clust-sil" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Horizontal barplot with 'Silhouette Values' on x-axis between 0 and 1; y-axis is 'Observations' between 0 and 50. Observations between 0-20 are all colored purple (cluster 1) and observations between 21-50 are colored green (cluster 2). A dashed vertical line passes through x=0.59. The majority of bars finish before this line.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-clust-sil-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-clust-sil-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Horizontal barplot with 'Silhouette Values' on x-axis between 0 and 1; y-axis is 'Observations' between 0 and 50. Observations between 0-20 are all colored purple (cluster 1) and observations between 21-50 are colored green (cluster 2). A dashed vertical line passes through x=0.59. The majority of bars finish before this line.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-clust-sil-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.12: Silhouette plot from predictions made by <code>lrn("clust.kmeans")</code> on <code>tsk("usarrests")</code>.
</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="sec-cluster-all" class="level3" data-number="13.4.5"><h3 data-number="13.4.5" class="anchored" data-anchor-id="sec-cluster-all">
<span class="header-section-number">13.4.5</span> Putting It All Together</h3>
<p>Finally, we conduct a small benchmark study using <code>tsk("usarrests")</code> and a few integrated cluster learners:</p>
<div class="cell">
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tsk_usarrests</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">tsk</a></span><span class="op">(</span><span class="st">"usarrests"</span><span class="op">)</span></span>
<span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.featureless"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.kmeans"</span>, centers <span class="op">=</span> <span class="fl">4L</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"clust.cmeans"</span>, centers <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"clust.wss"</span><span class="op">)</span>, <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"clust.silhouette"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_usarrests</span>, <span class="va">learners</span>,</span>
<span>  <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"insample"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">7</span>, <span class="fl">8</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          learner_id clust.wss clust.silhouette
1: clust.featureless    355808           0.0000
2:      clust.kmeans     37653           0.4774
3:      clust.cmeans     47964           0.5319</code></pre>
</div>
</div>
<p>The C-means and K-means algorithms are both considerably better than the featureless baseline but further analysis (and visualizations) would be required to decide which of those two is suitable for our needs.</p>
</section></section><section id="sec-spatiotemporal" class="level2 page-columns page-full" data-number="13.5"><h2 data-number="13.5" class="anchored" data-anchor-id="sec-spatiotemporal">
<span class="header-section-number">13.5</span> Spatial Analysis</h2>
<p>The final task we will discuss in this book is spatial analysis. Spatial analysis can be a subset of any other machine learning task (e.g., regression or classification) and is defined by the presence of spatial information in a dataset, usually stored as coordinates that are often named “x” and “y” or “lat” and “lon” (for ‘latitude’ and ‘longitude’ respectively.)</p>
<div class="page-columns page-full"><p>Spatial analysis is its own task as spatial data must be handled carefully due to the complexity of ‘autocorrelation’. Where correlation is defined as a statistical association <em>between two</em> variables, autocorrelation is a statistical association <em>within one</em> variable. In ML terms, in a dataset with features and observations, correlation occurs when two or more features are statistically associated in some way, whereas autocorrelation occurs when two or more observations are statistically associated across one feature. Autocorrelation, therefore, violates one of the fundamental assumptions of ML that all observations in a dataset are independent, which results in lower confidence about the quality of a trained machine learning model and the resulting performance estimates <span class="citation" data-cites="hastie2001">(<a href="../references.html#ref-hastie2001" role="doc-biblioref">Hastie, Friedman, and Tibshirani 2001</a>)</span>.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Autocorrelation</span></div></div>
<p>Autocorrelation is present in spatial data as there is implicit information encoded in coordinates, such as whether two observations (e.g., cities, countries, continents) are close together or far apart. By example, let us imagine we are predicting the number of cases of a disease two months after an outbreak in Germany (<a href="#fig-autocorrelation" class="quarto-xref">Figure&nbsp;<span>13.13</span></a>). Outbreaks radiate outwards from an epicenter and therefore countries closer to Germany will have higher numbers of cases and countries further away will have lower numbers (<a href="#fig-autocorrelation" class="quarto-xref">Figure&nbsp;<span>13.13</span></a>, bottom). Thus, looking at the data spatially shows clear signs of autocorrelation across nearby observations. Note in this example the autocorrelation is radial but in practice, this will not always be the case.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-autocorrelation" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Image shows two separate maps of Europe. Top map has a random distribution of colors from white to dark gray. Bottom map shows darkest color (dark gray) at Germany with increasing lightness as the countries are increasingly further away.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-autocorrelation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-autocorrelation-1.png" style="width:60.0%;height:60.0%" alt="Image shows two separate maps of Europe. Top map has a random distribution of colors from white to dark gray. Bottom map shows darkest color (dark gray) at Germany with increasing lightness as the countries are increasingly further away." class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autocorrelation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.13: Heatmaps where darker countries indicate higher number of cases and lighter countries indicate lower number of cases of imaginary Disease X with epicenter in Germany. The top map imagines a world in which there is no spatial autocorrelation and the number of cases of a disease is randomly distributed. The bottom map shows a more accurate world in which the number of cases radiate outwards from the epicenter (Germany).
</figcaption></figure>
</div>
</div>
</div>
<p>Unlike other tasks we have looked at in this chapter, there is no underlying difference between the implemented learners or measures. Instead, we provide additional resampling methods in <a href="https://mlr3spatiotempcv.mlr-org.com"><code>mlr3spatiotempcv</code></a> to account for the similarity in the train and test sets during resampling that originates from spatiotemporal autocorrelation.</p>
<p>Throughout this section we will use the <a href="https://mlr3spatiotempcv.mlr-org.com/reference/ecuador.html"><code>ecuador</code></a> dataset and task as a working example.</p>
<section id="taskclassifst-and-taskregrst" class="level3" data-number="13.5.1"><h3 data-number="13.5.1" class="anchored" data-anchor-id="taskclassifst-and-taskregrst">
<span class="header-section-number">13.5.1</span> TaskClassifST and TaskRegrST</h3>
<p>To make use of spatial resampling methods, we have implemented two extensions of <a href="https://mlr3.mlr-org.com/reference/TaskClassif.html"><code>TaskClassif</code></a> and <a href="https://mlr3.mlr-org.com/reference/TaskRegr.html"><code>TaskRegr</code></a> to accommodate spatial data, <a href="https://mlr3spatiotempcv.mlr-org.com/reference/TaskClassifST.html"><code>TaskClassifST</code></a> and <a href="https://mlr3spatiotempcv.mlr-org.com/reference/TaskRegrST.html"><code>TaskRegrST</code></a> respectively. Below we only show classification examples but regression follows trivially.</p>
<div class="cell">
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3spatial.mlr-org.com">mlr3spatial</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3spatiotempcv.mlr-org.com/">mlr3spatiotempcv</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create task from `data.frame`</span></span>
<span><span class="va">tsk_ecuador</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3spatial.mlr-org.com/reference/as_task_classif_st.html">as_task_classif_st</a></span><span class="op">(</span><span class="va">ecuador</span>, id <span class="op">=</span> <span class="st">"ecuador_task"</span>,</span>
<span>  target <span class="op">=</span> <span class="st">"slides"</span>, positive <span class="op">=</span> <span class="st">"TRUE"</span>,</span>
<span>  coordinate_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"y"</span><span class="op">)</span>, crs <span class="op">=</span> <span class="st">"32717"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># or create task from 'sf' object</span></span>
<span><span class="va">data_sf</span> <span class="op">=</span> <span class="fu">sf</span><span class="fu">::</span><span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_as_sf.html">st_as_sf</a></span><span class="op">(</span><span class="va">ecuador</span>, coords <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="st">"y"</span><span class="op">)</span>, crs <span class="op">=</span> <span class="st">"32717"</span><span class="op">)</span></span>
<span><span class="va">tsk_ecuador</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3spatial.mlr-org.com/reference/as_task_classif_st.html">as_task_classif_st</a></span><span class="op">(</span><span class="va">data_sf</span>, target <span class="op">=</span> <span class="st">"slides"</span>,</span>
<span>  positive <span class="op">=</span> <span class="st">"TRUE"</span><span class="op">)</span></span>
<span><span class="va">tsk_ecuador</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;TaskClassifST&gt; (751x11) ─────────────────────────────────────────────
• Target: slides
• Properties: twoclass
• Features (10):
  • dbl (10): carea, cslope, dem, distdeforest, distroad,
  distslidespast, hcurv, log.carea, slope, vcurv
* Coordinates:
          X       Y
  1: 712882 9560002
  2: 715232 9559582
  3: 715392 9560172
  4: 715042 9559312
  5: 715382 9560142
 ---               
747: 714472 9558482
748: 713142 9560992
749: 713322 9560562
750: 715392 9557932
751: 713802 9560862</code></pre>
</div>
</div>
<p>Once a task is created, you can train and predict as normal.</p>
<div class="cell">
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_ecuador</span><span class="op">)</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">tsk_ecuador</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionClassif&gt; for 751 observations: ────────────────────────────
 row_ids truth response
       1  TRUE     TRUE
       2  TRUE     TRUE
       3  TRUE     TRUE
     ---   ---      ---
     749 FALSE    FALSE
     750 FALSE    FALSE
     751 FALSE     TRUE</code></pre>
</div>
</div>
<p>However as discussed above, it is best to use the specialized resampling methods to achieve bias-reduced estimates of model performance.</p>
</section><section id="spatiotemp-cv" class="level3" data-number="13.5.2"><h3 data-number="13.5.2" class="anchored" data-anchor-id="spatiotemp-cv">
<span class="header-section-number">13.5.2</span> Spatiotemporal Cross-Validation</h3>
<p>Before we look at the spatial resampling methods implemented in <code>mlr3spatiotempcv</code> we will first show what can go wrong if non-spatial resampling methods are used for spatial data. Below we benchmark a decision tree on <code>tsk("ecuador")</code> using two different repeated cross-validation resampling methods, the first (“NSpCV” (non-spatial cross-validation)) is a non-spatial resampling method from <code>mlr3</code>, the second (“SpCV” (spatial cross-validation)) is from <code>mlr3spatiotempcv</code> and is optimized for spatial data. The example highlights how “NSpCV” makes it appear as if the decision tree is performing better than it is with considerably higher estimated performance, however, this is an overconfident prediction due to the autocorrelation in the data.</p>
<div class="cell">
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_rpart</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.rpart"</span>, predict_type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span>
<span><span class="va">rsmp_nsp</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"repeated_cv"</span>, folds <span class="op">=</span> <span class="fl">3</span>, repeats <span class="op">=</span> <span class="fl">2</span>, id <span class="op">=</span> <span class="st">"NSpCV"</span><span class="op">)</span></span>
<span><span class="va">rsmp_sp</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"repeated_spcv_coords"</span>, folds <span class="op">=</span> <span class="fl">3</span>, repeats <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  id <span class="op">=</span> <span class="st">"SpCV"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">tsk_ecuador</span>, <span class="va">lrn_rpart</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">rsmp_nsp</span>, <span class="va">rsmp_sp</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span>
<span><span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"classif.acc"</span><span class="op">)</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">7</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   resampling_id classif.acc
1:         NSpCV      0.6864
2:          SpCV      0.5842</code></pre>
</div>
</div>
<p>In the above example, applying non-spatial resampling results in train and test sets that are very similar due to the underlying spatial autocorrelation. Hence there is little difference from testing a model on the same data it was trained on, which should be avoided for an honest performance result (see <a href="../chapter2/data_and_basic_modeling.html" class="quarto-xref"><span>Chapter 2</span></a>). In contrast, the spatial method has accommodated autocorrelation and the test data is less correlated (though some association will remain) with the training data. Visually this can be seen using <a href="https://mlr3spatiotempcv.mlr-org.com/reference/autoplot.html"><code>autoplot()</code></a> methods. In <a href="#fig-sprsmp" class="quarto-xref">Figure&nbsp;<span>13.14</span></a> we visualize how the task is partitioned according to the spatial resampling method (<a href="#fig-sprsmp" class="quarto-xref">Figure&nbsp;<span>13.14</span></a>, left) and non-spatial resampling method (<a href="#fig-sprsmp" class="quarto-xref">Figure&nbsp;<span>13.14</span></a>, right). There is a clear separation in space for the respective partitions when using the spatial resampling whereas the train and test splits overlap a lot (and are therefore more correlated) using the non-spatial method.</p>
<div class="cell">
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span></span>
<span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">rsmp_sp</span>, <span class="va">tsk_ecuador</span>, fold_id <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Spatial Resampling"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">rsmp_nsp</span>, <span class="va">tsk_ecuador</span>, fold_id <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"Non-spatial Resampling"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://patchwork.data-imaginist.com/reference/plot_layout.html">plot_layout</a></span><span class="op">(</span>guides <span class="op">=</span> <span class="st">"collect"</span><span class="op">)</span> <span class="op">&amp;</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> <span class="op">&amp;</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>axis.text <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>, legend.position <span class="op">=</span> <span class="st">"bottom"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-sprsmp" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Two scatter plots with points in blue (training data) and orange (test data). Left plot (Spatial Resampling) shows a clean separation between orange and blue points. Right plot (Non-spatial Resampling) shows blue and orange dots randomly scattered among each other.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-sprsmp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-sprsmp-1.png" class="img-fluid figure-img" style="width:100.0%" alt="Two scatter plots with points in blue (training data) and orange (test data). Left plot (Spatial Resampling) shows a clean separation between orange and blue points. Right plot (Non-spatial Resampling) shows blue and orange dots randomly scattered among each other.">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sprsmp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.14: Scatterplots show separation of train (blue) and test (orange) data for the first fold of the first repetition of the cross-validation. Left is spatial resampling where train and test data are clearly separated. Right is non-spatial resampling where there is overlap in train and test data.
</figcaption></figure>
</div>
</div>
</div>
<p>Now we have seen why spatial resampling matters we can take a look at what methods are available in <code>mlr3spatiotempcv</code>. The resampling methods we have added can be categorized into:</p>
<ul>
<li>Blocking – Create rectangular blocks in 2D or 3D space</li>
<li>Buffering – Create buffering zones to remove observations between train and test sets</li>
<li>Spatiotemporal clustering – Clusters based on coordinates (and/or time points)</li>
<li>Feature space clustering – Clusters based on feature space and not necessarily spatiotemporal</li>
<li>Custom (partitioning) – Grouped by factor variables</li>
</ul>
<p>The choice of method may depend on specific characteristics of the dataset and there is no easy rule to pick one method over another, full details of different methods can be found in <span class="citation" data-cites="Schratz2021">Schratz et al. (<a href="../references.html#ref-Schratz2021" role="doc-biblioref">2021</a>)</span> – the paper deliberately avoids recommending one method over another as the ‘optimal’ choice is highly dependent on the predictive task, autocorrelation in the data, and the spatial structure of the sampling design. The documentation for each of the implemented methods includes details of each method as well as references to original publications.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Spatio<em>temporal</em> Resampling
</div>
</div>
<div class="callout-body-container callout-body">
<p>We have focused on spatial analysis but referred to “spatiotemporal” and “spatiotemp”. The spatial-only resampling methods discussed in this section can be extended to temporal analysis (or spatial and temporal analysis combined) by setting the <code>"time"</code> <code>col_role</code> in the task (<a href="../chapter2/data_and_basic_modeling.html#sec-row-col-roles" class="quarto-xref"><span>Section 2.6</span></a>) – this is an advanced topic that may be added in future editions of this book. See the <code>mlr3spatiotempcv</code> visualization vignette at <a href="https://mlr3spatiotempcv.mlr-org.com/articles/spatiotemp-viz.html">https://mlr3spatiotempcv.mlr-org.com/articles/spatiotemp-viz.html</a> for specific details about 3D spatiotemporal visualization.</p>
</div>
</div>
</section><section id="sec-spatial-prediction" class="level3" data-number="13.5.3"><h3 data-number="13.5.3" class="anchored" data-anchor-id="sec-spatial-prediction">
<span class="header-section-number">13.5.3</span> Spatial Prediction</h3>
<p>Until now we have looked at resampling to accommodate spatiotemporal <em>features</em>, but what if you want to make spatiotemporal <em>predictions</em>? In this case, the goal is to make classification or regression predictions at the pixel level, i.e., for an area, defined by the geometric resolution, of a raster image.</p>
<p>To enable these predictions we have created a new function, <a href="https://mlr3spatial.mlr-org.com/reference/predict_spatial.html"><code>predict_spatial()</code></a>, to allow spatial predictions using any of the following spatial data classes:</p>
<ul>
<li>
<code>stars</code> (from package <a href="https://cran.r-project.org/package=stars"><code>stars</code></a>)</li>
<li>
<code>SpatRaster</code> (from package <a href="https://cran.r-project.org/package=terra"><code>terra</code></a>)</li>
<li>
<code>RasterLayer</code> (from package <a href="https://cran.r-project.org/package=raster"><code>raster</code></a>)</li>
<li>
<code>RasterStack</code> (from package <a href="https://cran.r-project.org/package=raster"><code>raster</code></a>)</li>
</ul>
<p>In the example below we load the <code>leipzig_points</code> dataset for training and coerce this to a spatiotemporal task with <a href="https://mlr3spatiotempcv.mlr-org.com/reference/as_task_classif_st.html"><code>as_task_classif_st</code></a>, and we load the <code>leipzig_raster</code> raster. Both files are included as example data in <a href="https://mlr3spatial.mlr-org.com"><code>mlr3spatial</code></a>.</p>
<div class="cell">
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3spatial.mlr-org.com">mlr3spatial</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-spatial.github.io/sf/">sf</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rspatial.org/">terra</a></span>, exclude <span class="op">=</span> <span class="st">"resample"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load sample points</span></span>
<span><span class="va">leipzig_vector</span> <span class="op">=</span> <span class="fu">sf</span><span class="fu">::</span><span class="fu"><a href="https://r-spatial.github.io/sf/reference/st_read.html">read_sf</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/system.file.html">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>,</span>
<span>  <span class="st">"leipzig_points.gpkg"</span>, package <span class="op">=</span> <span class="st">"mlr3spatial"</span><span class="op">)</span>,</span>
<span>  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co"># create training data</span></span>
<span><span class="va">tsk_leipzig</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3spatial.mlr-org.com/reference/as_task_classif_st.html">as_task_classif_st</a></span><span class="op">(</span><span class="va">leipzig_vector</span>, target <span class="op">=</span> <span class="st">"land_cover"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load raster image</span></span>
<span><span class="va">leipzig_raster</span> <span class="op">=</span> <span class="fu">terra</span><span class="fu">::</span><span class="fu"><a href="https://rspatial.github.io/terra/reference/rast.html">rast</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/system.file.html">system.file</a></span><span class="op">(</span><span class="st">"extdata"</span>, <span class="st">"leipzig_raster.tif"</span>,</span>
<span>  package <span class="op">=</span> <span class="st">"mlr3spatial"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can continue as normal to train and predict with a classification learner, in this case, a random forest.</p>
<div class="cell">
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_ranger</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"classif.ranger"</span><span class="op">)</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">tsk_leipzig</span><span class="op">)</span></span>
<span><span class="va">prediction</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3spatial.mlr-org.com/reference/predict_spatial.html">predict_spatial</a></span><span class="op">(</span><span class="va">leipzig_raster</span>, <span class="va">lrn_ranger</span>,</span>
<span>  format <span class="op">=</span> <span class="st">"terra"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in warn_deprecated("DataBackend$data_formats"):
DataBackend$data_formats is deprecated and will be removed in the
future.</code></pre>
</div>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prediction</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>class       : SpatRaster 
size        : 206, 154, 1  (nrow, ncol, nlyr)
resolution  : 10, 10  (x, y)
extent      : 731810, 733350, 5692030, 5694090  (xmin, xmax, ymin, ymax)
coord. ref. : WGS 84 / UTM zone 32N (EPSG:32632) 
source      : file12b5526b8c89.tif 
categories  : categories 
name        : land_cover 
min value   :     forest 
max value   :      water </code></pre>
</div>
</div>
<p>In this example, we specified the creation of a <code>terra</code> object, which can be visualized with in-built plotting methods.</p>
<div class="cell">
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rspatial.github.io/terra/reference/plot.html">plot</a></span><span class="op">(</span><span class="va">prediction</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"#440154FF"</span>, <span class="st">"#443A83FF"</span>, <span class="st">"#31688EFF"</span>,</span>
<span>  <span class="st">"#21908CFF"</span>, <span class="st">"#35B779FF"</span>, <span class="st">"#8FD744FF"</span>, <span class="st">"#FDE725FF"</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-beyond-raster" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Very zoomed-in map with x-axis from 732000 to 733000 and 5692500 to 5693500 on y-axis. Different clusters are colored in green, blue, purple and yellow.">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-beyond-raster-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-beyond-raster-1.png" style="width:50.0%;height:50.0%" alt="Very zoomed-in map with x-axis from 732000 to 733000 and 5692500 to 5693500 on y-axis. Different clusters are colored in green, blue, purple and yellow." class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-beyond-raster-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.15: Spatial predictions for forest (purple), pasture (blue), urban (green), and water (yellow) categories.
</figcaption></figure>
</div>
</div>
</div>
</section></section><section id="sec-quantile-regression" class="level2" data-number="13.6"><h2 data-number="13.6" class="anchored" data-anchor-id="sec-quantile-regression">
<span class="header-section-number">13.6</span> Quantile Regression (+)</h2>
<p>Regression models typically predict the conditional mean of the target given the input features. Quantile regression allows for the prediction of conditional quantiles, enabling more uncertainty-aware and informative predictions or an approximation of the conditional distribution. Instead of answering “What is the expected outcome given these features?”, quantile regression asks, “What is the outcome at a given probability level (e.g., 10th percentile, median, 90th percentile)?”.</p>
<p>This is particularly useful in scenarios where we want to model uncertainty and extremes in data:</p>
<ul>
<li>Constructing prediction intervals, by asking for a lower bound, a central prediction, and an upper bound (e.g.&nbsp;0.05, 0.5, or 0.95)</li>
<li>Identifying extreme values: In applications such as risk analysis, financial modeling, or weather forecasting, we may be particularly interested in predicting the worst-case or best-case outcomes (e.g., the 5th quantile for a stock price drop).</li>
<li>Handling heteroscedastic data: When the variance of the response variable changes with the input features, quantile regression is usually a more robust solution.</li>
</ul>
<p>A key concept in estimating quantile regression models is the pinball loss, which generalizes the L1 loss, or mean absolute error (MAE), to optimize for arbitrary quantiles <span class="math inline">\(\tau\)</span>. To understand this, we need to recall that the median (i.e.&nbsp;the 0.5-quantile) minimizes the MAE. The pinball loss modifies the L1 loss by introducing an asymmetry that encourages the model to penalize under- or over-prediction more heavily, based on the chosen quantile level. For instance, setting <span class="math inline">\(\tau = 0.1\)</span> means overpredictions are nine times more expensive than underpredictions, leading the model to systematically underestimate the target. This pushes the model to estimate not the center of the (conditional) distribution, but the selected quantile. We can connect this directly to quantiles: If the model is trained to minimize pinball loss for a given quantile <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\tau \%\)</span> of the observed values should be below the predicted value, and <span class="math inline">\((1 - \tau) \%\)</span> should be above it. For example, a model trained with <span class="math inline">\(\tau = 0.1\)</span> will produce predictions such that 10% of observed values fall below its predictions, making it an estimator of the 10th percentile. The pinball loss will reappear as an evaluation metric at the end of this chapter.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-pinball" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-pinball-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="beyond_regression_and_classification_files/figure-html/fig-pinball-1.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pinball-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.16: Values of the pinball loss function for different quantiles.
</figcaption></figure>
</div>
</div>
</div>
<p>But note: While many ML models based on empirical risk minimization use the pinball loss for estimating quantiles, some model classes might work differently. However, since the underlying training procedure of a model is external to <code>mlr3</code>, we are more concerned with resampling and evaluating quantile regression models. This works in exactly the same manner as for other tasks. Because we provide only a brief overview of quantile regression, we recommend <span class="citation" data-cites="yu_quantile_2003">Yu, Lu, and Stander (<a href="../references.html#ref-yu_quantile_2003" role="doc-biblioref">2003</a>)</span> if you are interested in a methodological introduction to the topic and <span class="citation" data-cites="koenker_quantile_2005">Koenker (<a href="../references.html#ref-koenker_quantile_2005" role="doc-biblioref">2005</a>)</span> for a more expansive treatment of quantile regression.</p>
<section id="sec-data-generation" class="level3" data-number="13.6.1"><h3 data-number="13.6.1" class="anchored" data-anchor-id="sec-data-generation">
<span class="header-section-number">13.6.1</span> Synthetic data set generation</h3>
<p>Let us construct a simple synthetic data set to demonstrate how quantile regression works.</p>
<p>We generate 10,000 data points where the univariate feature <code>x</code> is drawn from a uniform distribution between 1 and 15 and the target <code>y</code> follows a non-linear function of <code>x</code>. To make the problem more interesting, we use heteroscedastic Gaussian noise on the target, i.e.&nbsp;the variance increases as <code>x</code> increases.</p>
<div class="cell">
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">10000</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">1</span>, max <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="va">f</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="op">(</span><span class="fl">10</span> <span class="op">*</span> <span class="va">x</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">cos</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">variance</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu">variance</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">=</span> <span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/data.table.html">data.table</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="va">noise</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us plot the data to get a better feel for it. The points are a random subset of the data (10%). The line is the true underlying function <span class="math inline">\(f(x)\)</span>, from which we sampled and which we would ideally recover as our estimated posterior median.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="beyond_regression_and_classification_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>This plot reveals two essential properties of our data. Firstly, <span class="math inline">\(f(x)\)</span> oscillates more for small <code>x</code> but becomes smoother for larger values. Secondly, we clearly see heteroscedasticity as the variance of <code>y</code> increases as <code>x</code> grows.</p>
<p>Because of the latter, mean-based models will struggle to provide robust predictions, especially for larger values of <code>x</code>, as they will be heavily influenced by extreme deviations. In contrast, the median (0.5-quantile) provides a more stable estimate, while other quantiles (e.g., 0.05 and 0.95) allow us to estimate uncertainty and extreme outcomes.</p>
<p>Now that we have generated our data set, we transform it into a regular regression task and split it into a train and test set. We also specify five quantiles to estimate. The median, which we will soon set as the intended <code>response</code> and four other quantiles to to capture lower and upper dispersion.</p>
<div class="cell">
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mlr3verse.mlr-org.com">mlr3verse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">task</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_task_regr.html">as_task_regr</a></span><span class="op">(</span><span class="va">data</span>, target <span class="op">=</span> <span class="st">"y"</span><span class="op">)</span></span>
<span><span class="va">splits</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/partition.html">partition</a></span><span class="op">(</span><span class="va">task</span><span class="op">)</span></span>
<span></span>
<span><span class="va">qs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="sec-quantile-regression-models" class="level3" data-number="13.6.2"><h3 data-number="13.6.2" class="anchored" data-anchor-id="sec-quantile-regression-models">
<span class="header-section-number">13.6.2</span> Quantile Regression with Multiple Learners</h3>
<section id="sec-quantile-ranger" class="level4" data-number="13.6.2.1"><h4 data-number="13.6.2.1" class="anchored" data-anchor-id="sec-quantile-ranger">
<span class="header-section-number">13.6.2.1</span> Random Regression Forest</h4>
<p>The first learner we apply is a random regression forest (<code>lrn("regr.ranger")</code>), implemented in <a href="https://mlr3learners.mlr-org.com"><code>mlr3learners</code></a>, a tree-based ensemble which can nicely handle complex interactions and non-linear relationships. We configure the learner to predict the specified quantiles and mark the median quantile as the dedicated response. We then train and predict as usual.</p>
<div class="cell">
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_ranger</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.ranger"</span>, predict_type <span class="op">=</span> <span class="st">"quantiles"</span>,</span>
<span>                     quantiles <span class="op">=</span> <span class="va">qs</span>, quantile_response <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">lrn_ranger</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="fu">set_values</span><span class="op">(</span>min.node.size <span class="op">=</span> <span class="fl">10</span>, num.trees <span class="op">=</span> <span class="fl">100</span>, mtry <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">lrn_ranger</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prds_ranger</span> <span class="op">=</span> <span class="va">lrn_ranger</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span>
<span><span class="va">prds_ranger</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
── &lt;PredictionRegr&gt; for 3300 observations: ──────────────────────────────
 row_ids   truth   q0.05   q0.25    q0.5   q0.75   q0.95 response
       8  0.7049 -1.9776 -1.5508 -0.6527 -0.1498  0.4523  -0.6527
      11  4.0826 -0.4254  0.7368  1.5577  2.6857  3.2571   1.5577
      14 -0.7935 -3.0278 -2.2801 -1.9397 -1.4621 -1.1065  -1.9397
     ---     ---     ---     ---     ---     ---     ---      ---
    9996  0.2617 -2.4376  0.8023  1.3672  2.1066  3.5946   1.3672
    9998  1.7711  1.5584  1.7121  2.1643  2.5118  4.7028   2.1643
    9999  3.2066  1.1793  1.2247  2.0793  2.3075  4.7419   2.0793</code></pre>
</div>
</div>
<p>The predict object has additional columns for all quantiles. We set <code>$quantile_response = 0.5</code> which means that <code>response</code> is equal to the 0.5-quantile.</p>
<p>We now plot the predicted quantiles against the true test data. Each colored line represents a different quantile estimate, and the black curve represents the true function.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="beyond_regression_and_classification_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Results of quantile regression with GAM. 90%-prediction interval in green and 50%-prediction interval in blue. The black line is the underlying function.</figcaption></figure>
</div>
</div>
</div>
<p>We can see that the random forest captures the overall trend of the function. It provides quantile estimates that increase as <code>x</code> increases and handles the non-linearity of our data well due to its ensemble nature.</p>
<p>But the predicted quantiles appear overly jagged and spiky, which suggests that the model might be overfitting to the noise in the training data rather than capturing smooth trends. The median estimate oscillates around the true function but does not consistently align with it. The reason for these limitations lies in how random forests construct quantiles. In quantile regression forests, predictions are derived from the empirical distribution of the response values within the terminal nodes of individual trees. Each tree partitions the feature space into regions, and all observations that fall into the same region (terminal node) share the same conditional distribution estimate. Quantiles are computed based on the sorted values of these observations. Because the number of samples in each terminal node is finite, the estimated quantiles are discrete rather than continuous, leading to the characteristic “stair-step” appearance in the predictions. If a particular terminal node contains only a small number of observations, the estimated quantiles may shift abruptly between adjacent nodes, creating jagged or spiky predictions. Additionally, the aggregation across trees averages over multiple step functions, which can result in piecewise-constant and noisy quantile estimates.</p>
</section><section id="sec-quantile-qgam" class="level4" data-number="13.6.2.2"><h4 data-number="13.6.2.2" class="anchored" data-anchor-id="sec-quantile-qgam">
<span class="header-section-number">13.6.2.2</span> Smooth Additive Model with PipeOpLearnerQuantiles</h4>
<p>To address the limitations that we observed with the random regression forest, we will now consider quantile regression with smooth generalized additive models (GAM) as an alternative method. This approach allows for smoother estimates and may improve the robustness of quantile predictions. Unlike tree-based methods, GAMs construct their prediction function using smooth splines rather than discrete splits. This makes them well-suited for handling continuous and structured data – which here aligns well with our simulation setup, although, in a more realistic scencario, we would not know this.</p>
<p>The predictive intervals we obtain from the quantile GAM differ from conventional confidence intervals in GAMs: rather than quantifying uncertainty around the estimated function itself, our quantile estimates enable direct predictive inference. This allows us to construct observation-wise prediction intervals.</p>
<p>We will begin to demonstrate this using <a href="https://mlr3extralearners.mlr-org.com/reference/mlr_learners_regr.mqgam.html"><code>lrn("regr.mqgam")</code></a> from <a href="https://mlr3extralearners.mlr-org.com"><code>mlr3extralearners</code></a>. As we have done above for the random regression forest, we fit a model using the previously specified quantiles.</p>
<div class="cell">
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">mlr3extralearners</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lrn_mqgam</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.mqgam"</span>, predict_type <span class="op">=</span> <span class="st">"quantiles"</span>,</span>
<span>                quantiles <span class="op">=</span> <span class="va">qs</span>, quantile_response <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">lrn_mqgam</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">form</span> <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">lrn_mqgam</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prds_mqgam</span> <span class="op">=</span> <span class="va">lrn_mqgam</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After training, we generate predictions for the test set and visualize the results.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="beyond_regression_and_classification_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Results of quantile regression with GAM. 90%-prediction interval in green and 50%-prediction interval in blue. The black line is the underlying function.</figcaption></figure>
</div>
</div>
</div>
<p>Compared to the random regression forest, the quantile GAM produces smoother estimates, as expected from an additive model. The predicted median closely follows the true function, and the estimated prediction intervals capture the heteroscedastic variance of the target well. Notably, the coverage of the quantiles is more stable, without the fluctuations seen in the random forest approach.</p>
<p>There are multiple learners in the <code>mlr3verse</code> which cannot predict multiple quantiles simultaneously. Because of this, we are also going to show how to use the <code>po("learner_quantiles")</code> from <a href="https://mlr3pipelines.mlr-org.com"><code>mlr3pipelines</code></a>, which wraps a learner and extends its functionality to handle multiple quantiles in one step. <a href="../chapter7/sequential_pipelines.html" class="quarto-xref"><span>Chapter 7</span></a> and <a href="../chapter8/non-sequential_pipelines_and_tuning.html" class="quarto-xref"><span>Chapter 8</span></a> have already given an introduction to <a href="https://mlr3pipelines.mlr-org.com"><code>mlr3pipelines</code></a>. We use this pipeop with <a href="https://mlr3extralearners.mlr-org.com/reference/mlr_learners_regr.qgam.html"><code>lrn("regr.qgam")</code></a>, a quantile regression GAM learner that can only be trained on one quantile.</p>
<div class="cell">
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lrn_qgam</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrn</a></span><span class="op">(</span><span class="st">"regr.qgam"</span><span class="op">)</span></span>
<span><span class="va">lrn_qgam</span><span class="op">$</span><span class="va">param_set</span><span class="op">$</span><span class="va">values</span><span class="op">$</span><span class="va">form</span> <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu">s</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">po_qgam</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3pipelines.mlr-org.com/reference/po.html">po</a></span><span class="op">(</span><span class="st">"learner_quantiles"</span>, learner <span class="op">=</span> <span class="va">lrn_qgam</span>,</span>
<span>                  quantiles.q_response <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>                  quantiles.q_vals <span class="op">=</span> <span class="va">qs</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then use <a href="https://mlr3pipelines.mlr-org.com/reference/GraphLearner.html"><code>GraphLearner</code></a> to predict for the test set.</p>
<div class="cell">
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">graph_lrn_qgam</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/as_learner.html">as_learner</a></span><span class="op">(</span><span class="va">po_qgam</span><span class="op">)</span></span>
<span><span class="va">graph_lrn_qgam</span><span class="op">$</span><span class="fu">train</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">train</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prds_qgam</span> <span class="op">=</span> <span class="va">graph_lrn_qgam</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">task</span>, row_ids <span class="op">=</span> <span class="va">splits</span><span class="op">$</span><span class="va">test</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="sec-comparison" class="level4" data-number="13.6.2.3"><h4 data-number="13.6.2.3" class="anchored" data-anchor-id="sec-comparison">
<span class="header-section-number">13.6.2.3</span> Comparison of methods</h4>
<p>So far, we have only looked at a visualization of the predictions on the test data. We will now evaluate and benchmark the two models.</p>
<p>To evaluate how well each model predicts quantiles on our test data, we compute the pinball loss. In general, a lower absolute pinball loss indicates better accuracy for a given quantile <code>alpha</code>. Since extreme quantiles (e.g.&nbsp;0.05 or 0.95) represent rare events and rely on less data for estimation, we would typically expect them to have higher loss than the median.</p>
<div class="cell">
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">measures</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.pinball"</span>, alpha <span class="op">=</span> <span class="fl">0.05</span>, id <span class="op">=</span> <span class="st">"q0.05"</span><span class="op">)</span>,</span>
<span>          <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.pinball"</span>, alpha <span class="op">=</span> <span class="fl">0.25</span>, id <span class="op">=</span> <span class="st">"q0.25"</span><span class="op">)</span>,</span>
<span>          <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.pinball"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, id <span class="op">=</span> <span class="st">"q0.5"</span><span class="op">)</span>,</span>
<span>          <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.pinball"</span>, alpha <span class="op">=</span> <span class="fl">0.75</span>, id <span class="op">=</span> <span class="st">"q0.75"</span><span class="op">)</span>,</span>
<span>          <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">msr</a></span><span class="op">(</span><span class="st">"regr.pinball"</span>, alpha <span class="op">=</span> <span class="fl">0.95</span>, id <span class="op">=</span> <span class="st">"q0.95"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prds_ranger</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> q0.05  q0.25   q0.5  q0.75  q0.95 
0.1564 0.4311 0.5322 0.4429 0.1706 </code></pre>
</div>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">prds_mqgam</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> q0.05  q0.25   q0.5  q0.75  q0.95 
0.1237 0.3794 0.4743 0.3880 0.1286 </code></pre>
</div>
</div>
<p>In this case, the loss for more extreme quantiles is lower than that of the median. The quantiles modeled with the GAM provide a better fit than the random forest. This aligns with our previous results, where the GAM produced smoother quantile estimates than the random forest.</p>
<p>To further assess the quality of our models, we resample and benchmark the models with 10-fold cross validation. After resampling, the results can then be aggregated and scored. This works as established in <a href="../chapter3/evaluation_and_benchmarking.html" class="quarto-xref"><span>Chapter 3</span></a>.</p>
<div class="cell">
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cv10</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">rsmp</a></span><span class="op">(</span><span class="st">"cv"</span>, folds <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">cv10</span><span class="op">$</span><span class="fu">instantiate</span><span class="op">(</span><span class="va">task</span><span class="op">)</span></span>
<span><span class="va">rr_ranger</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">task</span>, <span class="va">lrn_ranger</span>, <span class="va">cv10</span><span class="op">)</span></span>
<span><span class="va">rr_mqgam</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/resample.html">resample</a></span><span class="op">(</span><span class="va">task</span>, <span class="va">lrn_mqgam</span>, <span class="va">cv10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Score and aggregate resampling results</span></span>
<span><span class="va">acc_ranger</span> <span class="op">=</span> <span class="va">rr_ranger</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="va">rr_ranger</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> q0.05  q0.25   q0.5  q0.75  q0.95 
0.1548 0.4305 0.5338 0.4356 0.1605 </code></pre>
</div>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">acc_mqgam</span> <span class="op">=</span> <span class="va">rr_mqgam</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="va">rr_mqgam</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> q0.05  q0.25   q0.5  q0.75  q0.95 
0.1213 0.3762 0.4726 0.3782 0.1227 </code></pre>
</div>
</div>
<p>Finally, we compare both learners in a benchmark:</p>
<div class="cell">
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">learners</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/mlr_sugar.html">lrns</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"regr.ranger"</span>, <span class="st">"regr.mqgam"</span><span class="op">)</span>, predict_type <span class="op">=</span> <span class="st">"quantiles"</span>,</span>
<span>     quantiles <span class="op">=</span> <span class="va">qs</span>, quantile_response <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">design</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark_grid.html">benchmark_grid</a></span><span class="op">(</span><span class="va">task</span>, <span class="va">learners</span>, <span class="va">cv10</span><span class="op">)</span></span>
<span><span class="va">bmr</span> <span class="op">=</span> <span class="fu"><a href="https://mlr3.mlr-org.com/reference/benchmark.html">benchmark</a></span><span class="op">(</span><span class="va">design</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">bmr_scores</span> <span class="op">=</span> <span class="va">bmr</span><span class="op">$</span><span class="fu">score</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="va">bmr_agg</span> <span class="op">=</span> <span class="va">bmr</span><span class="op">$</span><span class="fu">aggregate</span><span class="op">(</span><span class="va">measures</span><span class="op">)</span></span>
<span><span class="va">bmr_agg</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">6</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   task_id  learner_id  q0.05  q0.25   q0.5  q0.75  q0.95
1:    data regr.ranger 0.1746 0.4582 0.5774 0.4656 0.1819
2:    data  regr.mqgam 0.1660 0.5514 0.7232 0.5786 0.1843</code></pre>
</div>
</div>
<p>In general, all standard <code>mlr3</code>-workflows, i.e.&nbsp;resampling, benchmarking, tuning, and the use of pipelines, can be applied to quantile regression learners just as they are applied to regression learners with other predict types.</p>
<p>In this section, we learned how we can use quantile regression in <code>mlr3</code>. Although both models capture the general trend of the data, the GAM-based approach provides smoother quantile estimates and better coverage of predictive intervals. The random forest model exhibits more variability and struggles with overfitting, particularly at extreme quantiles.</p>
</section></section></section><section id="conclusion" class="level2" data-number="13.7"><h2 data-number="13.7" class="anchored" data-anchor-id="conclusion">
<span class="header-section-number">13.7</span> Conclusion</h2>
<p>In this chapter, we explored going beyond regression and classification to see how classes in <code>mlr3</code> can be used to implement other ML tasks. Cost-sensitive classification extends the ‘normal’ classification setting by assuming that costs associated with false negatives and false positives are unequal. Running cost-sensitive classification experiments is possible using only features in <code>mlr3</code>. Survival analysis, available in <a href="https://mlr3proba.mlr-org.com"><code>mlr3proba</code></a>, can be thought of as a regression problem when the outcome may be censored, which means it may never be observed within a given time frame. The final task in <code>mlr3proba</code> is density estimation, the unsupervised task concerned with estimating univariate probability distributions. Using <a href="https://mlr3cluster.mlr-org.com"><code>mlr3cluster</code></a>, you can perform cluster analysis on observations, which involves grouping observations according to similarities in their variables. It is possible to perform spatial analysis with <a href="https://mlr3spatial.mlr-org.com"><code>mlr3spatial</code></a> and <a href="https://mlr3spatiotempcv.mlr-org.com"><code>mlr3spatiotempcv</code></a> to make predictions using coordinates as features and to make spatial predictions. Finally, we saw how we can use the predict type <code>"quantiles"</code> to predict conditional quantiles and construct prediction intervals. The <code>mlr3</code> interface is highly extensible, which means future ML tasks can (and will) be added to our universe and we will add these to this chapter of the book in future editions.</p>
<div id="tbl-beyond-api" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-beyond-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;13.2: Important classes and functions covered in this chapter with underlying class (if applicable), class constructor or function, and important class fields and methods (if applicable).
</figcaption><div aria-describedby="tbl-beyond-api-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead><tr class="header">
<th>Class</th>
<th>Constructor/Function</th>
<th>Fields/Methods</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="https://mlr3.mlr-org.com/reference/MeasureClassifCosts.html"><code>MeasureClassifCosts</code></a></td>
<td><code>msr("classif.costs")</code></td>
<td>-</td>
</tr>
<tr class="even">
<td><a href="https://mlr3pipelines.mlr-org.com/reference/PipeOpTuneThreshold.html"><code>PipeOpTuneThreshold</code></a></td>
<td><code>po("tunethreshold")</code></td>
<td>-</td>
</tr>
<tr class="odd">
<td><a href="https://mlr3proba.mlr-org.com/reference/TaskSurv.html"><code>TaskSurv</code></a></td>
<td><a href="https://mlr3proba.mlr-org.com/reference/as_task_surv.html"><code>as_task_surv()</code></a></td>
<td><code>$data()</code></td>
</tr>
<tr class="even">
<td><a href="https://mlr3proba.mlr-org.com/reference/PipeOpDistrCompositor.html"><code>PipeOpDistrCompositor</code></a></td>
<td><code>po("distrcompose")</code></td>
<td>-</td>
</tr>
<tr class="odd">
<td><a href="https://mlr3proba.mlr-org.com/reference/TaskDens.html"><code>TaskDens</code></a></td>
<td><a href="https://mlr3proba.mlr-org.com/reference/as_task_dens.html"><code>as_task_dens()</code></a></td>
<td><code>$data()</code></td>
</tr>
<tr class="even">
<td><a href="https://mlr3cluster.mlr-org.com/reference/TaskClust.html"><code>TaskClust</code></a></td>
<td><a href="https://mlr3cluster.mlr-org.com/reference/as_task_clust.html"><code>as_task_clust()</code></a></td>
<td><code>$data()</code></td>
</tr>
<tr class="odd">
<td><a href="https://mlr3spatiotempcv.mlr-org.com/reference/TaskClassifST.html"><code>TaskClassifST</code></a></td>
<td><a href="https://mlr3spatiotempcv.mlr-org.com/reference/as_task_classif_st.html"><code>as_task_classif_st()</code></a></td>
<td><code>$data()</code></td>
</tr>
<tr class="even">
<td>-</td>
<td><a href="https://mlr3spatiotempcv.mlr-org.com/reference/predict_spatial.html"><code>predict_spatial()</code></a></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="exercises" class="level2" data-number="13.8"><h2 data-number="13.8" class="anchored" data-anchor-id="exercises">
<span class="header-section-number">13.8</span> Exercises</h2>
<ol type="1">
<li>Run a benchmark experiment on <code>tsk("german_credit")</code> with <code>lrn("classif.featureless")</code>, <code>lrn("classif.log_reg")</code>, and <code>lrn("classif.ranger")</code>. Tune the prediction thresholds of all learners by encapsulating them in a <code>po("learner_cv")</code> (with two-fold CV), followed by a <code>po("tunethreshold")</code>. Use <code>msr("classif.costs", costs = costs)</code>, where the <code>costs</code> matrix is as follows: true positive is <code>-10</code>, true negative is <code>-1</code>, false positive is <code>2</code>, and false negative is <code>3</code>. Use this measure in <code>po("tunethreshold")</code> and when evaluating your benchmark experiment.</li>
<li>Train and test a survival forest using <code>lrn("surv.rfsrc")</code> (from <code>mlr3extralearners</code>). Run this experiment using <code>tsk("rats")</code> and <code><a href="https://mlr3.mlr-org.com/reference/partition.html">partition()</a></code>. Evaluate your model with the RCLL measure.</li>
<li>Estimate the density of the “precip” task from the <code>mlr3proba</code> package using <code>lrn("dens.hist")</code>, evaluate your estimation with the logloss measure. As a stretch goal, look into the documentation of <code>distr6</code> to learn how to analyse your estimated distribution further.</li>
<li>Run a benchmark clustering experiment on the “wine” dataset without a label column. Compare the performance of k-means learner with <code>k</code> equal to <code>2</code>, <code>3</code> and <code>4</code> using the silhouette measure and the insample resampling technique. What value of <code>k</code> would you choose based on the silhouette scores?</li>
<li>Manually <code>$train()</code> a GBM regression model from <a href="https://mlr3extralearners.mlr-org.com"><code>mlr3extralearners</code></a> on <code>tsk("mtcars")</code> to predict the 95th percentile of the target variable. Make sure that you split the data and only use the test data for fitting the learner. Use the test data to evaluate your learner with the pinball loss.</li>
</ol></section><section id="citation" class="level2" data-number="13.9"><h2 data-number="13.9" class="anchored" data-anchor-id="citation">
<span class="header-section-number">13.9</span> Citation</h2>
<p>Please cite this chapter as:</p>
<p>Sonabend R, Schratz P, Pulatov D, Zobolas J, Koers L. (2024). Beyond Regression and Classification. In Bischl B, Sonabend R, Kotthoff L, Lang M, (Eds.), <em>Applied Machine Learning Using mlr3 in R</em>. CRC Press. https://mlr3book.mlr-org.com/beyond_regression_and_classification.html.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode bibtex code-with-copy"><code class="sourceCode bibtex"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="va">@incollection</span>{<span class="ot">citekey</span>, </span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">author</span> = "<span class="st">Raphael Sonabend and Patrick Schratz and Damir Pulatov and John Zobolas and Lona Koers</span>", </span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">title</span> = "<span class="st">Beyond Regression and Classification</span>",</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">booktitle</span> = "<span class="st">Applied Machine Learning Using {m}lr3 in {R}</span>",</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">publisher</span> = "<span class="st">CRC Press</span>", <span class="st">year</span> = "<span class="st">2024</span>",</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">editor</span> = "<span class="st">Bernd Bischl and Raphael Sonabend and Lars Kotthoff and Michel Lang</span>", </span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">url</span> = "<span class="st">https://mlr3book.mlr-org.com/beyond_regression_and_classification.html</span>"</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Collett2014" class="csl-entry" role="listitem">
Collett, David. 2014. <em>Modelling Survival Data in Medical Research</em>. 3rd ed. CRC. <a href="https://doi.org/10.1201/b18041">https://doi.org/10.1201/b18041</a>.
</div>
<div id="ref-hastie2001" class="csl-entry" role="listitem">
Hastie, Trevor, Jerome Friedman, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Springer New York. <a href="https://doi.org/10.1007/978-0-387-21606-5">https://doi.org/10.1007/978-0-387-21606-5</a>.
</div>
<div id="ref-Kalbfleisch2011" class="csl-entry" role="listitem">
Kalbfleisch, John D, and Ross L Prentice. 2011. <em>The Statistical Analysis of Failure Time Data</em>. Vol. 360. John Wiley &amp; Sons. <a href="https://doi.org/10.1002/9781118032985">https://doi.org/10.1002/9781118032985</a>.
</div>
<div id="ref-koenker_quantile_2005" class="csl-entry" role="listitem">
Koenker, Roger. 2005. <em>Quantile Regression</em>. Econometric Society Monographs. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511754098">https://doi.org/10.1017/CBO9780511754098</a>.
</div>
<div id="ref-Ruspini1970" class="csl-entry" role="listitem">
Ruspini, Enrique H. 1970. <span>“Numerical Methods for Fuzzy Clustering.”</span> <em>Information Sciences</em> 2 (3): 319–50. <a href="https://doi.org/10.1016/S0020-0255(70)80056-1">https://doi.org/10.1016/S0020-0255(70)80056-1</a>.
</div>
<div id="ref-Schratz2021" class="csl-entry" role="listitem">
Schratz, Patrick, Marc Becker, Michel Lang, and Alexander Brenning. 2021. <span>“<span class="nocase">mlr3spatiotempcv</span>: Spatiotemporal Resampling Methods for Machine Learning in <span>R</span>,”</span> October. <a href="https://arxiv.org/abs/2110.12674">https://arxiv.org/abs/2110.12674</a>.
</div>
<div id="ref-Silverman1986" class="csl-entry" role="listitem">
Silverman, Bernard W. 1986. <em>Density Estimation for Statistics and Data Analysis</em>. Vol. 26. CRC press.
</div>
<div id="ref-Sonabend2021b" class="csl-entry" role="listitem">
Sonabend, Raphael Edward Benjamin. 2021. <span>“A Theoretical and Methodological Framework for Machine Learning in Survival Analysis: Enabling Transparent and Accessible Predictive Modelling on Right-Censored Time-to-Event Data.”</span> PhD, University College London (UCL). <a href="https://discovery.ucl.ac.uk/id/eprint/10129352/">https://discovery.ucl.ac.uk/id/eprint/10129352/</a>.
</div>
<div id="ref-MLSA" class="csl-entry" role="listitem">
Sonabend, Raphael, and Andreas Bender. 2023. <em>Machine Learning in Survival Analysis</em>. <a href="https://www.mlsabook.com">https://www.mlsabook.com</a>.
</div>
<div id="ref-Sonabend2022" class="csl-entry" role="listitem">
Sonabend, Raphael, Andreas Bender, and Sebastian Vollmer. 2022. <span>“Avoiding <span>C</span>-Hacking When Evaluating Survival Distribution Predictions with Discrimination Measures.”</span> Edited by Zhiyong Lu. <em>Bioinformatics</em> 38 (17): 4178–84. <a href="https://doi.org/10.1093/bioinformatics/btac451">https://doi.org/10.1093/bioinformatics/btac451</a>.
</div>
<div id="ref-mlr3proba" class="csl-entry" role="listitem">
Sonabend, Raphael, Franz J Király, Andreas Bender, Bernd Bischl, and Michel Lang. 2021. <span>“<span class="nocase">mlr3proba</span>: An <span>R</span> Package for Machine Learning in Survival Analysis.”</span> <em>Bioinformatics</em>, February. <a href="https://doi.org/10.1093/bioinformatics/btab039">https://doi.org/10.1093/bioinformatics/btab039</a>.
</div>
<div id="ref-yu_quantile_2003" class="csl-entry" role="listitem">
Yu, Keming, Zudi Lu, and Julian Stander. 2003. <span>“Quantile Regression: Applications and Current Research Areas.”</span> <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em> 52 (3): 331–50. <a href="https://doi.org/10.1111/1467-9884.00363">https://doi.org/10.1111/1467-9884.00363</a>.
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/chapter12/model_interpretation.html" class="pagination-link" aria-label="Model Interpretation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Model Interpretation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/chapter14/algorithmic_fairness.html" class="pagination-link" aria-label="Algorithmic Fairness">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Algorithmic Fairness</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb124" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="an">aliases:</span></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a><span class="co">  - "/beyond_regression_and_classification.html"</span></span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - "/survival.html"</span></span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="fu"># Beyond Regression and Classification {#sec-special}</span></span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>{{&lt; include ../../common/_setup.qmd &gt;}}</span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-11"><a href="#cb124-11" aria-hidden="true" tabindex="-1"></a><span class="in">`r chapter = "Beyond Regression and Classification"`</span></span>
<span id="cb124-12"><a href="#cb124-12" aria-hidden="true" tabindex="-1"></a><span class="in">`r authors(chapter)`</span></span>
<span id="cb124-13"><a href="#cb124-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-14"><a href="#cb124-14" aria-hidden="true" tabindex="-1"></a>So far, this book has only considered two tasks.</span>
<span id="cb124-15"><a href="#cb124-15" aria-hidden="true" tabindex="-1"></a>In @sec-basics we introduced deterministic regression as well as deterministic and probabilistic single-label classification (@tbl-alltasks).</span>
<span id="cb124-16"><a href="#cb124-16" aria-hidden="true" tabindex="-1"></a>But our infrastructure also works well for many other tasks, some of which are available in extension packages (@fig-mlr3verse) and some are available by creating pipelines with <span class="in">`r mlr3pipelines`</span>.</span>
<span id="cb124-17"><a href="#cb124-17" aria-hidden="true" tabindex="-1"></a>In this chapter, we will take you through just a subset of these new tasks, focusing on the ones that have a stable API.</span>
<span id="cb124-18"><a href="#cb124-18" aria-hidden="true" tabindex="-1"></a>As we work through this chapter we will refer to the 'building blocks' of <span class="in">`r mlr3`</span>, this refers to the base classes that must be extended to create new tasks, these are <span class="in">`r ref("Prediction")`</span>, <span class="in">`r ref("Learner")`</span>, <span class="in">`r ref("Measure")`</span>, and <span class="in">`r ref("Task")`</span>.</span>
<span id="cb124-19"><a href="#cb124-19" aria-hidden="true" tabindex="-1"></a>@tbl-alltasks summarizes available extension tasks, including the package(s) they are implemented in and a brief description of the task.</span>
<span id="cb124-20"><a href="#cb124-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-21"><a href="#cb124-21" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Task <span class="pp">|</span> Package <span class="pp">|</span> Description <span class="pp">|</span></span>
<span id="cb124-22"><a href="#cb124-22" aria-hidden="true" tabindex="-1"></a><span class="pp">| ----</span> <span class="pp">|</span> -- <span class="pp">| ----</span> <span class="pp">|</span></span>
<span id="cb124-23"><a href="#cb124-23" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Deterministic regression <span class="pp">|</span> <span class="in">`r mlr3`</span>  <span class="pp">|</span> Point prediction of a continuous variable. <span class="pp">|</span></span>
<span id="cb124-24"><a href="#cb124-24" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Quantile regression <span class="pp">|</span> <span class="in">`r mlr3`</span>  <span class="pp">|</span> Prediction of conditional quantiles for a continuous variable. <span class="pp">|</span></span>
<span id="cb124-25"><a href="#cb124-25" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Deterministic single-label classification <span class="pp">|</span> <span class="in">`r mlr3`</span>  <span class="pp">|</span> Prediction of a single class for each observation. <span class="pp">|</span></span>
<span id="cb124-26"><a href="#cb124-26" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Probabilistic single-label classification <span class="pp">|</span> <span class="in">`r mlr3`</span>  <span class="pp">|</span> Prediction of the probability of an observation falling into one or more mutually exclusive categories. <span class="pp">|</span></span>
<span id="cb124-27"><a href="#cb124-27" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Cost-sensitive classification <span class="pp">|</span> <span class="in">`r mlr3`</span> and <span class="in">`r mlr3pipelines`</span>  <span class="pp">|</span> Classification predictions with unequal costs associated with misclassifications. <span class="pp">|</span></span>
<span id="cb124-28"><a href="#cb124-28" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Survival analysis <span class="pp">|</span> <span class="in">`r mlr3proba`</span>  <span class="pp">|</span> Time-to-event predictions with possible 'censoring'. <span class="pp">|</span></span>
<span id="cb124-29"><a href="#cb124-29" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Density estimation <span class="pp">|</span> <span class="in">`r mlr3proba`</span>  <span class="pp">|</span> Unsupervised estimation of probability density functions. <span class="pp">|</span></span>
<span id="cb124-30"><a href="#cb124-30" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Spatiotemporal analysis <span class="pp">|</span> <span class="in">`r mlr3spatiotempcv`</span> and <span class="in">`r mlr3spatial`</span>  <span class="pp">|</span> Supervised prediction of data with spatial (e.g., coordinates) and/or temporal outcomes. <span class="pp">|</span></span>
<span id="cb124-31"><a href="#cb124-31" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Cluster analysis <span class="pp">|</span> <span class="in">`r mlr3cluster`</span>  <span class="pp">|</span> Unsupervised estimation of homogeneous clusters of data points. <span class="pp">|</span></span>
<span id="cb124-32"><a href="#cb124-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-33"><a href="#cb124-33" aria-hidden="true" tabindex="-1"></a>: Table of extension tasks that can be used with <span class="in">`mlr3`</span> infrastructure. As we have a growing community of contributors, this list is far from exhaustive and many 'experimental' task implementations exist; this list just represents the tasks that have a functioning interface. {#tbl-alltasks}</span>
<span id="cb124-34"><a href="#cb124-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-35"><a href="#cb124-35" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cost-Sensitive Classification {#sec-cost-sens}</span></span>
<span id="cb124-36"><a href="#cb124-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-37"><a href="#cb124-37" aria-hidden="true" tabindex="-1"></a>We begin by discussing a task that does not require any additional packages or infrastructure, only the tools we have already learned about from earlier chapters.</span>
<span id="cb124-38"><a href="#cb124-38" aria-hidden="true" tabindex="-1"></a>In 'regular' classification, the aim is to optimize a metric (often the misclassification rate) while assuming all misclassification errors are deemed equally severe.</span>
<span id="cb124-39"><a href="#cb124-39" aria-hidden="true" tabindex="-1"></a>A more general approach is <span class="in">`r index("cost-sensitive classification", "cost-sensitive", parent = "classification", aside = TRUE)`</span>, in which costs caused by different kinds of errors may not be equal.</span>
<span id="cb124-40"><a href="#cb124-40" aria-hidden="true" tabindex="-1"></a>The objective of cost-sensitive classification is to minimize the expected costs.</span>
<span id="cb124-41"><a href="#cb124-41" aria-hidden="true" tabindex="-1"></a>We will use <span class="in">`tsk("german_credit")`</span> as a running example.</span>
<span id="cb124-42"><a href="#cb124-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-43"><a href="#cb124-43" aria-hidden="true" tabindex="-1"></a>Imagine you are trying to calculate if giving someone a loan of \$5K will result in a profit after one year, assuming they are expected to pay back \$6K.</span>
<span id="cb124-44"><a href="#cb124-44" aria-hidden="true" tabindex="-1"></a>To make this calculation, you will need to predict if the person will have good credit.</span>
<span id="cb124-45"><a href="#cb124-45" aria-hidden="true" tabindex="-1"></a>This is a deterministic classification problem where we are predicting whether someone will be in class 'Good' or 'Bad'.</span>
<span id="cb124-46"><a href="#cb124-46" aria-hidden="true" tabindex="-1"></a>Now let us consider some potential costs associated with each prediction and the eventual truth.</span>
<span id="cb124-47"><a href="#cb124-47" aria-hidden="true" tabindex="-1"></a>As cost-sensitive classification is a minimization problem, we assume lower costs correspond to higher profits/positive outcomes, hence we write profits as negative values and losses as positive values:</span>
<span id="cb124-48"><a href="#cb124-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-49"><a href="#cb124-49" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-001}</span></span>
<span id="cb124-50"><a href="#cb124-50" aria-hidden="true" tabindex="-1"></a>costs <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">0</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">dimnames =</span></span>
<span id="cb124-51"><a href="#cb124-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="st">"Predicted Credit"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"good"</span>, <span class="st">"bad"</span>),</span>
<span id="cb124-52"><a href="#cb124-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">Truth =</span> <span class="fu">c</span>(<span class="st">"good"</span>, <span class="st">"bad"</span>)))</span>
<span id="cb124-53"><a href="#cb124-53" aria-hidden="true" tabindex="-1"></a>costs</span>
<span id="cb124-54"><a href="#cb124-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-55"><a href="#cb124-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-56"><a href="#cb124-56" aria-hidden="true" tabindex="-1"></a>In this example, if the model predicts that the individual has bad credit (bottom row) then there is no profit or loss, the loan is not provided.</span>
<span id="cb124-57"><a href="#cb124-57" aria-hidden="true" tabindex="-1"></a>If the model predicts that the individual has good credit and indeed the customer repays the loan with interest (top left), then you will make a \$1K profit.</span>
<span id="cb124-58"><a href="#cb124-58" aria-hidden="true" tabindex="-1"></a>On the other hand, if they default (top right), you will lose \$5K.</span>
<span id="cb124-59"><a href="#cb124-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-60"><a href="#cb124-60" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cost-Sensitive Measure</span></span>
<span id="cb124-61"><a href="#cb124-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-62"><a href="#cb124-62" aria-hidden="true" tabindex="-1"></a>We will now see how to implement a more nuanced approach to classification errors with <span class="in">`msr("classif.costs")`</span>.</span>
<span id="cb124-63"><a href="#cb124-63" aria-hidden="true" tabindex="-1"></a>This measure takes one argument, which is a matrix with row and column names corresponding to the class labels in the task of interest.</span>
<span id="cb124-64"><a href="#cb124-64" aria-hidden="true" tabindex="-1"></a>Let us put our insurance example into practice, notice that we have already named the cost matrix as required for the measure:</span>
<span id="cb124-65"><a href="#cb124-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-66"><a href="#cb124-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-002}</span></span>
<span id="cb124-67"><a href="#cb124-67" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb124-68"><a href="#cb124-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-69"><a href="#cb124-69" aria-hidden="true" tabindex="-1"></a>tsk_german <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"german_credit"</span>)</span>
<span id="cb124-70"><a href="#cb124-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-71"><a href="#cb124-71" aria-hidden="true" tabindex="-1"></a>msr_costs <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"classif.costs"</span>, <span class="at">costs =</span> costs)</span>
<span id="cb124-72"><a href="#cb124-72" aria-hidden="true" tabindex="-1"></a>msr_costs</span>
<span id="cb124-73"><a href="#cb124-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-74"><a href="#cb124-74" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"classif.log_reg"</span>, <span class="st">"classif.featureless"</span>,</span>
<span id="cb124-75"><a href="#cb124-75" aria-hidden="true" tabindex="-1"></a>  <span class="st">"classif.ranger"</span>))</span>
<span id="cb124-76"><a href="#cb124-76" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_german, learners,</span>
<span id="cb124-77"><a href="#cb124-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)))</span>
<span id="cb124-78"><a href="#cb124-78" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_costs)[, <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">7</span>)]</span>
<span id="cb124-79"><a href="#cb124-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-80"><a href="#cb124-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-81"><a href="#cb124-81" aria-hidden="true" tabindex="-1"></a>In this experiment, we find that the logistic regression learner happens to perform best as it minimizes the expected costs (and maximizes expected profits) and the featureless learner performs the worst.</span>
<span id="cb124-82"><a href="#cb124-82" aria-hidden="true" tabindex="-1"></a>All losses result in positive costs, which means each model results in us losing money.</span>
<span id="cb124-83"><a href="#cb124-83" aria-hidden="true" tabindex="-1"></a>To improve our models, we will now turn to thresholding.</span>
<span id="cb124-84"><a href="#cb124-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-85"><a href="#cb124-85" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thresholding</span></span>
<span id="cb124-86"><a href="#cb124-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-87"><a href="#cb124-87" aria-hidden="true" tabindex="-1"></a>As we have discussed in @sec-basics, <span class="in">`r index("thresholding")`</span> is a method to fine-tune the probability at which an observation will be predicted as one class label or another.</span>
<span id="cb124-88"><a href="#cb124-88" aria-hidden="true" tabindex="-1"></a>Currently in our running example, the models above will predict a customer has good credit (in the class 'Good') if the probability of good credit is greater than 0.5.</span>
<span id="cb124-89"><a href="#cb124-89" aria-hidden="true" tabindex="-1"></a>Here, this might not be a sensible approach as we would likely act more conservatively and reject more credit applications with a higher threshold due to the non-uniform costs.</span>
<span id="cb124-90"><a href="#cb124-90" aria-hidden="true" tabindex="-1"></a>This is highlighted in the <span class="in">`"threshold"`</span> <span class="in">`autoplot`</span> (@fig-costsens-threshold), which plots <span class="in">`msr("classif.costs")`</span> over all possible thresholds.</span>
<span id="cb124-91"><a href="#cb124-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-92"><a href="#cb124-92" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-003}</span></span>
<span id="cb124-93"><a href="#cb124-93" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb124-94"><a href="#cb124-94" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: false</span></span>
<span id="cb124-95"><a href="#cb124-95" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>,</span>
<span id="cb124-96"><a href="#cb124-96" aria-hidden="true" tabindex="-1"></a>  <span class="at">predict_type =</span> <span class="st">"prob"</span>)<span class="sc">$</span><span class="fu">train</span>(tsk_german)<span class="sc">$</span><span class="fu">predict</span>(tsk_german)</span>
<span id="cb124-97"><a href="#cb124-97" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, <span class="at">type =</span> <span class="st">"threshold"</span>, <span class="at">measure =</span> msr_costs)</span>
<span id="cb124-98"><a href="#cb124-98" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-99"><a href="#cb124-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-100"><a href="#cb124-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-004}</span></span>
<span id="cb124-101"><a href="#cb124-101" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb124-102"><a href="#cb124-102" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb124-103"><a href="#cb124-103" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb124-104"><a href="#cb124-104" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-costsens-threshold</span></span>
<span id="cb124-105"><a href="#cb124-105" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Changing values of cost-sensitive measure as the prediction threshold is changed.</span></span>
<span id="cb124-106"><a href="#cb124-106" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Line graph with x-axis labeled 'Probability Threshold' ranging between 0-1, and y-axis labeled 'classif.costs' ranging between -0.3 and 0.7'. Line starts at (0,0.7) decreases linearly to around (0.8,-0.3) then increases linearly to (1, 0)."</span></span>
<span id="cb124-107"><a href="#cb124-107" aria-hidden="true" tabindex="-1"></a>plt <span class="ot">=</span> ggplot2<span class="sc">::</span><span class="fu">last_plot</span>()</span>
<span id="cb124-108"><a href="#cb124-108" aria-hidden="true" tabindex="-1"></a>plt<span class="sc">$</span>layers[[<span class="dv">1</span>]]<span class="sc">$</span>aes_params<span class="sc">$</span>colour <span class="ot">=</span> <span class="st">"grey30"</span></span>
<span id="cb124-109"><a href="#cb124-109" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(plt)</span>
<span id="cb124-110"><a href="#cb124-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-111"><a href="#cb124-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-112"><a href="#cb124-112" aria-hidden="true" tabindex="-1"></a>As expected, the optimal threshold is greater than 0.5 which means the optimal model should predict 'bad' credit more often than not.</span>
<span id="cb124-113"><a href="#cb124-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-114"><a href="#cb124-114" aria-hidden="true" tabindex="-1"></a>The optimal threshold can be automated by making use of <span class="in">`r mlr3tuning`</span> (@sec-optimization) and <span class="in">`r mlr3pipelines`</span> (@sec-pipelines) to tune <span class="in">`po("tunethreshold")`</span>.</span>
<span id="cb124-115"><a href="#cb124-115" aria-hidden="true" tabindex="-1"></a>Continuing the same example:</span>
<span id="cb124-116"><a href="#cb124-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-117"><a href="#cb124-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-005}</span></span>
<span id="cb124-118"><a href="#cb124-118" aria-hidden="true" tabindex="-1"></a>po_cv <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"learner_cv"</span>, <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>))</span>
<span id="cb124-119"><a href="#cb124-119" aria-hidden="true" tabindex="-1"></a>graph <span class="ot">=</span>  po_cv <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">"tunethreshold"</span>, <span class="at">measure =</span> msr_costs)</span>
<span id="cb124-120"><a href="#cb124-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-121"><a href="#cb124-121" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">list</span>(<span class="fu">as_learner</span>(graph), <span class="fu">lrn</span>(<span class="st">"classif.log_reg"</span>))</span>
<span id="cb124-122"><a href="#cb124-122" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_german, learners,</span>
<span id="cb124-123"><a href="#cb124-123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)))</span>
<span id="cb124-124"><a href="#cb124-124" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(msr_costs)[, <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">7</span>)]</span>
<span id="cb124-125"><a href="#cb124-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-126"><a href="#cb124-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-127"><a href="#cb124-127" aria-hidden="true" tabindex="-1"></a>By using <span class="in">`po("learner_cv")`</span> for internal resampling and <span class="in">`po("tunethreshold")`</span> to find the optimal threshold we have improved our model performance considerably and can now even expect a profit.</span>
<span id="cb124-128"><a href="#cb124-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-129"><a href="#cb124-129" aria-hidden="true" tabindex="-1"></a><span class="fu">## Survival Analysis {#sec-survival}</span></span>
<span id="cb124-130"><a href="#cb124-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-131"><a href="#cb124-131" aria-hidden="true" tabindex="-1"></a><span class="in">`r index("Survival analysis")`</span> is a field of statistics concerned with trying to predict/estimate the time until an event takes place.</span>
<span id="cb124-132"><a href="#cb124-132" aria-hidden="true" tabindex="-1"></a>This predictive problem is unique as survival models are trained and tested on data that may include 'censoring', which occurs when the event of interest does *not* take place.</span>
<span id="cb124-133"><a href="#cb124-133" aria-hidden="true" tabindex="-1"></a>Survival analysis can be hard to explain in the abstract, so as a working example consider a marathon runner in a race.</span>
<span id="cb124-134"><a href="#cb124-134" aria-hidden="true" tabindex="-1"></a>Here the 'survival problem' is trying to predict the time when the marathon runner finishes the race.</span>
<span id="cb124-135"><a href="#cb124-135" aria-hidden="true" tabindex="-1"></a>However, if the event of interest does not take place (e.g., the marathon runner gives up and does not finish the race), they are said to be censored.</span>
<span id="cb124-136"><a href="#cb124-136" aria-hidden="true" tabindex="-1"></a>Instead of throwing away information about censored events, survival analysis datasets include a status variable that provides information about the 'status' of an observation.</span>
<span id="cb124-137"><a href="#cb124-137" aria-hidden="true" tabindex="-1"></a>So in our example, we might write the runner's outcome as $(4, 1)$ if they finish the race at four hours, otherwise, if they give up at two hours we would write $(2, 0)$.</span>
<span id="cb124-138"><a href="#cb124-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-139"><a href="#cb124-139" aria-hidden="true" tabindex="-1"></a>The key to modeling in survival analysis is that we assume there exists a hypothetical time the marathon runner would have finished if they had not been censored, it is then the job of a survival learner to estimate what the true survival time would have been for a similar runner, assuming they are *not* censored (see @fig-censoring).</span>
<span id="cb124-140"><a href="#cb124-140" aria-hidden="true" tabindex="-1"></a>Mathematically, this is represented by the hypothetical event time, $Y$, the hypothetical censoring time, $C$, the observed outcome time, $T = \min(Y, C)$, the event indicator $\Delta := (T = Y)$, and as usual some features, $X$.</span>
<span id="cb124-141"><a href="#cb124-141" aria-hidden="true" tabindex="-1"></a>Learners are trained on $(T, \Delta)$ but, critically, make predictions of $Y$ from previously unseen features.</span>
<span id="cb124-142"><a href="#cb124-142" aria-hidden="true" tabindex="-1"></a>This means that unlike classification and regression, learners are trained on two variables, $(T, \Delta)$, which, in R, is often captured in a <span class="in">`r ref("survival::Surv")`</span> object.</span>
<span id="cb124-143"><a href="#cb124-143" aria-hidden="true" tabindex="-1"></a>Relating to our example above, the runner's outcome would then be $(T = 4, \Delta = 1)$ or $(T = 2, \Delta = 0)$.</span>
<span id="cb124-144"><a href="#cb124-144" aria-hidden="true" tabindex="-1"></a>Another example is in the code below, where we randomly generate six survival times and six event indicators, an outcome with a <span class="in">`+`</span> indicates the outcome is censored, otherwise, the event of interest occurred.</span>
<span id="cb124-145"><a href="#cb124-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-146"><a href="#cb124-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-006}</span></span>
<span id="cb124-147"><a href="#cb124-147" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survival)</span>
<span id="cb124-148"><a href="#cb124-148" aria-hidden="true" tabindex="-1"></a><span class="fu">Surv</span>(<span class="fu">runif</span>(<span class="dv">6</span>), <span class="fu">rbinom</span>(<span class="dv">6</span>, <span class="dv">1</span>, <span class="fl">0.5</span>))</span>
<span id="cb124-149"><a href="#cb124-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-150"><a href="#cb124-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-151"><a href="#cb124-151" aria-hidden="true" tabindex="-1"></a>Readers familiar with survival analysis will recognize that the description above applies specifically to 'right censoring'.</span>
<span id="cb124-152"><a href="#cb124-152" aria-hidden="true" tabindex="-1"></a>Currently, this is the only form of censoring available in the <span class="in">`mlr3`</span> universe, hence restricting our discussion to that setting.</span>
<span id="cb124-153"><a href="#cb124-153" aria-hidden="true" tabindex="-1"></a>For a good introduction to survival analysis see @Collett2014 or for machine learning in survival analysis specifically see @MLSA.</span>
<span id="cb124-154"><a href="#cb124-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-155"><a href="#cb124-155" aria-hidden="true" tabindex="-1"></a>For the remainder of this section, we will look at how <span class="in">`r mlr3proba`</span> <span class="co">[</span><span class="ot">@mlr3proba</span><span class="co">]</span> extends the building blocks of <span class="in">`mlr3`</span> for survival analysis. We will begin by looking at objects used to construct machine learning tasks for survival analysis, then we will turn to the learners we have implemented to solve these tasks, before looking at measures for evaluating survival analysis predictions, and then finally we will consider how to transform prediction types.</span>
<span id="cb124-156"><a href="#cb124-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-157"><a href="#cb124-157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-007, echo=FALSE}</span></span>
<span id="cb124-158"><a href="#cb124-158" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Figure shows give horizontal lines at 1,2,3,4,5 on the y-axis and a vertical line at 8 on the x-axis. Top line (subject 5) has a circle at x=8 and a diamond at x=9, second line (subject 4) has a circle at x=1 and a diamond at x=9, subject 3 has a circle at x=4 and a diamond at x=6, subject 2 has a diamond at x=8, and subject 1 has a diamond at x=7.</span></span>
<span id="cb124-159"><a href="#cb124-159" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Plot illustrating different censoring types. Dead and censored subjects (y-axis) over time (x-axis). Black diamonds indicate true death times and white circles indicate censoring times. Vertical line is the study end time. Subjects 1 and 2 die in the study time. Subject 3 is censored in the study and (unknown) dies within the study time. Subject 4 is censored in the study and (unknown) dies after the study. Subject 5 dies after the end of the study. Figure and caption from @Sonabend2021b.</span></span>
<span id="cb124-160"><a href="#cb124-160" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-censoring</span></span>
<span id="cb124-161"><a href="#cb124-161" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb124-162"><a href="#cb124-162" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">10</span>), <span class="at">y =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>), <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb124-163"><a href="#cb124-163" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_blank</span>() <span class="sc">+</span></span>
<span id="cb124-164"><a href="#cb124-164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">8</span>) <span class="sc">+</span></span>
<span id="cb124-165"><a href="#cb124-165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">1</span>, <span class="at">yend =</span> <span class="dv">1</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">7</span>) <span class="sc">+</span></span>
<span id="cb124-166"><a href="#cb124-166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">2</span>, <span class="at">yend =</span> <span class="dv">2</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">8</span>) <span class="sc">+</span></span>
<span id="cb124-167"><a href="#cb124-167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">3</span>, <span class="at">yend =</span> <span class="dv">3</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-168"><a href="#cb124-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">3</span>, <span class="at">yend =</span> <span class="dv">3</span>, <span class="at">x =</span> <span class="dv">4</span>, <span class="at">xend =</span> <span class="dv">6</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb124-169"><a href="#cb124-169" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">4</span>, <span class="at">yend =</span> <span class="dv">4</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb124-170"><a href="#cb124-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">4</span>, <span class="at">yend =</span> <span class="dv">4</span>, <span class="at">x =</span> <span class="dv">1</span>, <span class="at">xend =</span> <span class="dv">9</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb124-171"><a href="#cb124-171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">5</span>, <span class="at">yend =</span> <span class="dv">5</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">xend =</span> <span class="dv">8</span>) <span class="sc">+</span></span>
<span id="cb124-172"><a href="#cb124-172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">y =</span> <span class="dv">5</span>, <span class="at">yend =</span> <span class="dv">5</span>, <span class="at">x =</span> <span class="dv">8</span>, <span class="at">xend =</span> <span class="dv">9</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb124-173"><a href="#cb124-173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">4</span>, <span class="at">y =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"white"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-174"><a href="#cb124-174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">6</span>, <span class="at">y =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">18</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-175"><a href="#cb124-175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">7</span>, <span class="at">y =</span> <span class="dv">1</span>, <span class="at">shape =</span> <span class="dv">18</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-176"><a href="#cb124-176" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">8</span>, <span class="at">y =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">18</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-177"><a href="#cb124-177" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">9</span>, <span class="at">y =</span> <span class="dv">5</span>, <span class="at">shape =</span> <span class="dv">18</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-178"><a href="#cb124-178" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">8</span>, <span class="at">y =</span> <span class="dv">5</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb124-179"><a href="#cb124-179" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="dv">4</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb124-180"><a href="#cb124-180" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">9</span>, <span class="at">y =</span> <span class="dv">4</span>, <span class="at">shape =</span> <span class="dv">18</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb124-181"><a href="#cb124-181" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"Subject"</span>, <span class="at">x =</span> <span class="st">"Time"</span>) <span class="sc">+</span></span>
<span id="cb124-182"><a href="#cb124-182" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">labels =</span> <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>), <span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb124-183"><a href="#cb124-183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb124-184"><a href="#cb124-184" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-185"><a href="#cb124-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-186"><a href="#cb124-186" aria-hidden="true" tabindex="-1"></a><span class="fu">### TaskSurv</span></span>
<span id="cb124-187"><a href="#cb124-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-188"><a href="#cb124-188" aria-hidden="true" tabindex="-1"></a>As we saw in the introduction to this section, survival algorithms require two targets for training, this means the new <span class="in">`r ref("TaskSurv")`</span> object expects two targets.</span>
<span id="cb124-189"><a href="#cb124-189" aria-hidden="true" tabindex="-1"></a>The simplest way to create a survival task is to use <span class="in">`r ref("as_task_surv()")`</span>, as in the following code chunk.</span>
<span id="cb124-190"><a href="#cb124-190" aria-hidden="true" tabindex="-1"></a>Note this has more arguments than <span class="in">`r ref("as_task_regr()")`</span> to reflect multiple target and censoring types, <span class="in">`time`</span> and <span class="in">`event`</span> arguments expect strings representing column names where the 'time' and 'event' variables are stored, <span class="in">`type`</span> refers to the censoring type (currently only right censoring supported so this is the default).</span>
<span id="cb124-191"><a href="#cb124-191" aria-hidden="true" tabindex="-1"></a><span class="in">`as_task_surv()`</span> coerces the target columns into a <span class="in">`r ref("survival::Surv")`</span> object.</span>
<span id="cb124-192"><a href="#cb124-192" aria-hidden="true" tabindex="-1"></a>In this section we will use the <span class="in">`rats`</span> dataset as a running example, this dataset looks at predicting if a drug treatment was successful in preventing 150 rats from developing tumors.</span>
<span id="cb124-193"><a href="#cb124-193" aria-hidden="true" tabindex="-1"></a>The dataset, by its own admission, is not perfect and should generally be treated as 'dummy' data, which is good for examples but not real-world analysis.</span>
<span id="cb124-194"><a href="#cb124-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-195"><a href="#cb124-195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-008, warning=FALSE, message=FALSE}</span></span>
<span id="cb124-196"><a href="#cb124-196" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb124-197"><a href="#cb124-197" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3proba)</span>
<span id="cb124-198"><a href="#cb124-198" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survival)</span>
<span id="cb124-199"><a href="#cb124-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-200"><a href="#cb124-200" aria-hidden="true" tabindex="-1"></a>tsk_rats <span class="ot">=</span> <span class="fu">as_task_surv</span>(survival<span class="sc">::</span>rats, <span class="at">time =</span> <span class="st">"time"</span>,</span>
<span id="cb124-201"><a href="#cb124-201" aria-hidden="true" tabindex="-1"></a>  <span class="at">event =</span> <span class="st">"status"</span>, <span class="at">type =</span> <span class="st">"right"</span>, <span class="at">id =</span> <span class="st">"rats"</span>)</span>
<span id="cb124-202"><a href="#cb124-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-203"><a href="#cb124-203" aria-hidden="true" tabindex="-1"></a>tsk_rats<span class="sc">$</span><span class="fu">head</span>()</span>
<span id="cb124-204"><a href="#cb124-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-205"><a href="#cb124-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-206"><a href="#cb124-206" aria-hidden="true" tabindex="-1"></a>Plotting the task with <span class="in">`autoplot`</span> results in a <span class="in">`r index('Kaplan-Meier', lower = FALSE)`</span> plot (@fig-autokm) which is a non-parametric estimator of the probability of survival for the average observation in the training set.</span>
<span id="cb124-207"><a href="#cb124-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-208"><a href="#cb124-208" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-009, warning=FALSE, message=FALSE, output = FALSE, cache = FALSE}</span></span>
<span id="cb124-209"><a href="#cb124-209" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tsk_rats)</span>
<span id="cb124-210"><a href="#cb124-210" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-211"><a href="#cb124-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-010, warning=FALSE, message=FALSE, echo = FALSE}</span></span>
<span id="cb124-212"><a href="#cb124-212" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Kaplan-Meier plot of `tsk("rats")`. x-axis is time variable and y-axis is survival function, S(T), defined by $1 -$ F(T) where F is the cumulative distribution function. Crosses indicate points where censoring takes place.</span></span>
<span id="cb124-213"><a href="#cb124-213" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Figure shows a line plot with "Time" on the x-axis from 0 to 100 and "Survival" on the y-axis from 0.80 to 1.00. The line plot is a black line from (0, 1) to (25, 1) then starts to drop slowly and then quickly down to (100, 0.80).</span></span>
<span id="cb124-214"><a href="#cb124-214" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-autokm</span></span>
<span id="cb124-215"><a href="#cb124-215" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">autoplot</span>(tsk_rats)</span>
<span id="cb124-216"><a href="#cb124-216" aria-hidden="true" tabindex="-1"></a>p<span class="sc">$</span>layers[[<span class="dv">2</span>]]<span class="sc">$</span>aes_params<span class="sc">$</span>colour <span class="ot">=</span> <span class="st">"grey30"</span></span>
<span id="cb124-217"><a href="#cb124-217" aria-hidden="true" tabindex="-1"></a>p</span>
<span id="cb124-218"><a href="#cb124-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-219"><a href="#cb124-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-220"><a href="#cb124-220" aria-hidden="true" tabindex="-1"></a>As well as creating your own tasks, you can load any of the tasks shipped with <span class="in">`mlr3proba`</span>:</span>
<span id="cb124-221"><a href="#cb124-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-222"><a href="#cb124-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-011}</span></span>
<span id="cb124-223"><a href="#cb124-223" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_tasks)[task_type <span class="sc">==</span> <span class="st">"surv"</span>]</span>
<span id="cb124-224"><a href="#cb124-224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-225"><a href="#cb124-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-226"><a href="#cb124-226" aria-hidden="true" tabindex="-1"></a><span class="fu">### LearnerSurv, PredictionSurv and Predict Types</span></span>
<span id="cb124-227"><a href="#cb124-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-228"><a href="#cb124-228" aria-hidden="true" tabindex="-1"></a>The interface for <span class="in">`r ref("LearnerSurv")`</span> and <span class="in">`r ref("PredictionSurv")`</span> objects is identical to the regression and classification settings discussed in @sec-basics.</span>
<span id="cb124-229"><a href="#cb124-229" aria-hidden="true" tabindex="-1"></a>Similarly to these settings, survival learners are constructed with <span class="in">`r ref("lrn()")`</span>.</span>
<span id="cb124-230"><a href="#cb124-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-231"><a href="#cb124-231" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3proba`</span> has a different predict interface to <span class="in">`mlr3`</span> as all possible types of prediction ('predict types') are returned when possible for all survival models -- i.e., if a model *can* compute a particular predict type then *it will be* returned in <span class="in">`PredictionSurv`</span>.</span>
<span id="cb124-232"><a href="#cb124-232" aria-hidden="true" tabindex="-1"></a>The reason for this design decision is that all these predict types can be transformed to one another and it is therefore computationally simpler to return all at once instead of rerunning models to change predict type.</span>
<span id="cb124-233"><a href="#cb124-233" aria-hidden="true" tabindex="-1"></a>In survival analysis, the following predictions can be made:</span>
<span id="cb124-234"><a href="#cb124-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-235"><a href="#cb124-235" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`response`</span> -- Predicted survival time.</span>
<span id="cb124-236"><a href="#cb124-236" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`distr`</span> -- Predicted survival distribution, either discrete or continuous.</span>
<span id="cb124-237"><a href="#cb124-237" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`lp`</span> -- Linear predictor calculated as the fitted coefficients multiplied by the test data.</span>
<span id="cb124-238"><a href="#cb124-238" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`crank`</span> -- Continuous risk ranking.</span>
<span id="cb124-239"><a href="#cb124-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-240"><a href="#cb124-240" aria-hidden="true" tabindex="-1"></a>We will go through each of these prediction types in more detail and with examples to make them less abstract.</span>
<span id="cb124-241"><a href="#cb124-241" aria-hidden="true" tabindex="-1"></a>We will use <span class="in">`lrn("surv.coxph")`</span>\index{Cox Proportional Hazards} trained on <span class="in">`tsk("rats")`</span> as a running example, since for this model, all predict types except <span class="in">`response`</span> can be computed.</span>
<span id="cb124-242"><a href="#cb124-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-243"><a href="#cb124-243" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-012}</span></span>
<span id="cb124-244"><a href="#cb124-244" aria-hidden="true" tabindex="-1"></a>tsk_rats <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"rats"</span>)</span>
<span id="cb124-245"><a href="#cb124-245" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk_rats)</span>
<span id="cb124-246"><a href="#cb124-246" aria-hidden="true" tabindex="-1"></a>prediction_cph <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"surv.coxph"</span>)<span class="sc">$</span><span class="fu">train</span>(tsk_rats, split<span class="sc">$</span>train)<span class="sc">$</span></span>
<span id="cb124-247"><a href="#cb124-247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(tsk_rats, split<span class="sc">$</span>test)</span>
<span id="cb124-248"><a href="#cb124-248" aria-hidden="true" tabindex="-1"></a>prediction_cph</span>
<span id="cb124-249"><a href="#cb124-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-250"><a href="#cb124-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-251"><a href="#cb124-251" aria-hidden="true" tabindex="-1"></a><span class="fu">#### predict_type = "response" {.unnumbered .unlisted}</span></span>
<span id="cb124-252"><a href="#cb124-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-253"><a href="#cb124-253" aria-hidden="true" tabindex="-1"></a>Counterintuitively for many, the <span class="in">`response`</span> prediction of predicted survival times is the least common predict type in survival analysis.</span>
<span id="cb124-254"><a href="#cb124-254" aria-hidden="true" tabindex="-1"></a>The likely reason for this is due to the presence of censoring.</span>
<span id="cb124-255"><a href="#cb124-255" aria-hidden="true" tabindex="-1"></a>We rarely observe the true survival time for many observations and therefore it is unlikely any survival model can confidently make predictions for survival times.</span>
<span id="cb124-256"><a href="#cb124-256" aria-hidden="true" tabindex="-1"></a>This is illustrated in the code below.</span>
<span id="cb124-257"><a href="#cb124-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-258"><a href="#cb124-258" aria-hidden="true" tabindex="-1"></a>In the example below we train and predict from a survival SVM\index{support vector machine!survival} (<span class="in">`lrn("surv.svm")`</span>), note we use <span class="in">`type = "regression"`</span> to select the algorithm that optimizes survival time predictions and <span class="in">`gamma.mu = 1e-3`</span> is selected arbitrarily as this is a required parameter (this parameter should usually be tuned).</span>
<span id="cb124-259"><a href="#cb124-259" aria-hidden="true" tabindex="-1"></a>We then compare the predictions from the model to the true data.</span>
<span id="cb124-260"><a href="#cb124-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-261"><a href="#cb124-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-013}</span></span>
<span id="cb124-262"><a href="#cb124-262" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners)</span>
<span id="cb124-263"><a href="#cb124-263" aria-hidden="true" tabindex="-1"></a>prediction_svm <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"surv.svm"</span>, <span class="at">type =</span> <span class="st">"regression"</span>, <span class="at">gamma =</span> <span class="fl">1e-3</span>)<span class="sc">$</span></span>
<span id="cb124-264"><a href="#cb124-264" aria-hidden="true" tabindex="-1"></a>  <span class="fu">train</span>(tsk_rats, split<span class="sc">$</span>train)<span class="sc">$</span><span class="fu">predict</span>(tsk_rats, split<span class="sc">$</span>test)</span>
<span id="cb124-265"><a href="#cb124-265" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">pred =</span> prediction_svm<span class="sc">$</span>response[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>],</span>
<span id="cb124-266"><a href="#cb124-266" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> prediction_svm<span class="sc">$</span>truth[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb124-267"><a href="#cb124-267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-268"><a href="#cb124-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-269"><a href="#cb124-269" aria-hidden="true" tabindex="-1"></a>As can be seen from the output, our predictions are all less than the true observed time, which means we know our model underestimated the truth.</span>
<span id="cb124-270"><a href="#cb124-270" aria-hidden="true" tabindex="-1"></a>However, because each of the true values are censored times, we have absolutely no way of knowing if these predictions are slightly bad or absolutely terrible, (i.e., the true survival times could be $105, 99, 92$ or they could be $300, 1000, 200$).</span>
<span id="cb124-271"><a href="#cb124-271" aria-hidden="true" tabindex="-1"></a>Hence, with no realistic way to evaluate these models, survival time predictions are rarely useful.</span>
<span id="cb124-272"><a href="#cb124-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-273"><a href="#cb124-273" aria-hidden="true" tabindex="-1"></a><span class="fu">#### predict_type = "distr" {.unnumbered .unlisted}</span></span>
<span id="cb124-274"><a href="#cb124-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-275"><a href="#cb124-275" aria-hidden="true" tabindex="-1"></a>Unlike regression in which deterministic/point predictions are most common, in survival analysis distribution predictions are much more common.</span>
<span id="cb124-276"><a href="#cb124-276" aria-hidden="true" tabindex="-1"></a>You will therefore find that the majority of survival models in <span class="in">`mlr3proba`</span> will make distribution predictions by default.</span>
<span id="cb124-277"><a href="#cb124-277" aria-hidden="true" tabindex="-1"></a>These predictions are implemented using the <span class="in">`r ref_pkg("alan-turing-institute/distr6")`</span> package, which allows visualization and evaluation of survival curves (defined as $1 -$ cumulative distribution function).</span>
<span id="cb124-278"><a href="#cb124-278" aria-hidden="true" tabindex="-1"></a>Below we extract the first three <span class="in">`$distr`</span> predictions from our running example and calculate the probability of survival at $t = 77$.</span>
<span id="cb124-279"><a href="#cb124-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-280"><a href="#cb124-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-014}</span></span>
<span id="cb124-281"><a href="#cb124-281" aria-hidden="true" tabindex="-1"></a>prediction_cph<span class="sc">$</span>distr[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]<span class="sc">$</span><span class="fu">survival</span>(<span class="dv">77</span>)</span>
<span id="cb124-282"><a href="#cb124-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-283"><a href="#cb124-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-284"><a href="#cb124-284" aria-hidden="true" tabindex="-1"></a>The output indicates that there is a <span class="in">`r paste0(round(prediction_cph$distr[1:3]$survival(77)*100, 1), "%")`</span>, chance of the first three predicted rats being alive at time 77 respectively.</span>
<span id="cb124-285"><a href="#cb124-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-286"><a href="#cb124-286" aria-hidden="true" tabindex="-1"></a><span class="fu">#### predict_type = "lp" {.unnumbered .unlisted}</span></span>
<span id="cb124-287"><a href="#cb124-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-288"><a href="#cb124-288" aria-hidden="true" tabindex="-1"></a><span class="in">`lp`</span>, often written as $\eta$ in academic writing, is computationally the simplest prediction and has a natural analog in regression modeling.</span>
<span id="cb124-289"><a href="#cb124-289" aria-hidden="true" tabindex="-1"></a>Readers familiar with linear regression will know that when fitting a simple linear regression model, $Y = X\beta$, we are estimating the values for $\beta$, and the estimated <span class="in">`r index("linear predictor")`</span> (lp) is then $X\hat{\beta}$, where $\hat{\beta}$ are our estimated coefficients.</span>
<span id="cb124-290"><a href="#cb124-290" aria-hidden="true" tabindex="-1"></a>In simple survival models, the linear predictor is the same quantity (but estimated in a slightly more complicated way).</span>
<span id="cb124-291"><a href="#cb124-291" aria-hidden="true" tabindex="-1"></a>The learner implementations in <span class="in">`mlr3proba`</span> are primarily machine-learning focused and few of these models have a simple linear form, which means that <span class="in">`lp`</span> cannot be computed for most of these.</span>
<span id="cb124-292"><a href="#cb124-292" aria-hidden="true" tabindex="-1"></a>In practice, when used for prediction, <span class="in">`lp`</span> is a proxy for a relative risk/continuous ranking prediction, which is discussed next.</span>
<span id="cb124-293"><a href="#cb124-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-294"><a href="#cb124-294" aria-hidden="true" tabindex="-1"></a><span class="fu">#### predict_type = "crank" {.unnumbered .unlisted}</span></span>
<span id="cb124-295"><a href="#cb124-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-296"><a href="#cb124-296" aria-hidden="true" tabindex="-1"></a>The final prediction type, <span class="in">`crank`</span>, is the most common in survival analysis and perhaps also the most confusing.</span>
<span id="cb124-297"><a href="#cb124-297" aria-hidden="true" tabindex="-1"></a>Academic texts will often refer to 'risk' predictions in survival analysis (hence why survival models are often known as 'risk prediction models'), without defining what 'risk' means.</span>
<span id="cb124-298"><a href="#cb124-298" aria-hidden="true" tabindex="-1"></a>Often, risk is defined as $\exp(\eta)$ as this is a common quantity found in simple linear survival models.</span>
<span id="cb124-299"><a href="#cb124-299" aria-hidden="true" tabindex="-1"></a>However, sometimes risk is defined as $\exp(-\eta)$, and sometimes it can be an arbitrary quantity that does not have a meaningful interpretation.</span>
<span id="cb124-300"><a href="#cb124-300" aria-hidden="true" tabindex="-1"></a>To prevent this confusion in <span class="in">`mlr3proba`</span>, we define the predict type <span class="in">`crank`</span>, which stands for **c**ontinuous **rank**ing.</span>
<span id="cb124-301"><a href="#cb124-301" aria-hidden="true" tabindex="-1"></a>This is best explained by example; continuing from the previous we output the first three <span class="in">`crank`</span> predictions.</span>
<span id="cb124-302"><a href="#cb124-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-303"><a href="#cb124-303" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-015}</span></span>
<span id="cb124-304"><a href="#cb124-304" aria-hidden="true" tabindex="-1"></a>prediction_cph<span class="sc">$</span>crank[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb124-305"><a href="#cb124-305" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-306"><a href="#cb124-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-307"><a href="#cb124-307" aria-hidden="true" tabindex="-1"></a>The output tells us that the first rat is at the lowest risk of death (smaller values represent lower risk) and the third rat is at the highest risk.</span>
<span id="cb124-308"><a href="#cb124-308" aria-hidden="true" tabindex="-1"></a>The distance between predictions also tells us that the difference in risk between the second and third rats is smaller than the difference between the first and second.</span>
<span id="cb124-309"><a href="#cb124-309" aria-hidden="true" tabindex="-1"></a>The actual values themselves are meaningless and therefore comparing <span class="in">`crank`</span> values between samples (or papers or experiments) is not meaningful.</span>
<span id="cb124-310"><a href="#cb124-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-311"><a href="#cb124-311" aria-hidden="true" tabindex="-1"></a>The <span class="in">`crank`</span> prediction type is informative and common in practice because it allows identifying observations at lower/higher risk to each other, which is useful for resource allocation, e.g., which patient should be given an expensive treatment, and clinical trials, e.g., are people in a treatment arm at lower risk of disease X than people in the control arm.</span>
<span id="cb124-312"><a href="#cb124-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-313"><a href="#cb124-313" aria-hidden="true" tabindex="-1"></a>:::{.callout-warning}</span>
<span id="cb124-314"><a href="#cb124-314" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpreting Survival Risk</span></span>
<span id="cb124-315"><a href="#cb124-315" aria-hidden="true" tabindex="-1"></a>The interpretation of 'risk' for survival predictions differs across R packages and sometimes even between models in the same package.</span>
<span id="cb124-316"><a href="#cb124-316" aria-hidden="true" tabindex="-1"></a>In <span class="in">`mlr3proba`</span> there is one consistent interpretation of <span class="in">`crank`</span>: lower values represent a lower risk of the event taking place and higher values represent higher risk.</span>
<span id="cb124-317"><a href="#cb124-317" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb124-318"><a href="#cb124-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-319"><a href="#cb124-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### MeasureSurv</span></span>
<span id="cb124-320"><a href="#cb124-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-321"><a href="#cb124-321" aria-hidden="true" tabindex="-1"></a>Survival models in <span class="in">`mlr3proba`</span> are evaluated with <span class="in">`r ref("MeasureSurv")`</span> objects, which are constructed in the usual way with <span class="in">`msr()`</span>.</span>
<span id="cb124-322"><a href="#cb124-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-323"><a href="#cb124-323" aria-hidden="true" tabindex="-1"></a>In general survival measures can be grouped into the following:</span>
<span id="cb124-324"><a href="#cb124-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-325"><a href="#cb124-325" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Discrimination measures -- Quantify if a model correctly identifies if one observation is at higher risk than another. Evaluate <span class="in">`crank`</span> and/or <span class="in">`lp`</span> predictions.</span>
<span id="cb124-326"><a href="#cb124-326" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Calibration measures -- Quantify if the average prediction is close to the truth (all definitions of calibration are unfortunately vague in a survival context). Evaluate <span class="in">`crank`</span> and/or <span class="in">`lp`</span> predictions.</span>
<span id="cb124-327"><a href="#cb124-327" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Scoring rules -- Quantify if probabilistic predictions are close to true values. Evaluate <span class="in">`distr`</span> predictions.</span>
<span id="cb124-328"><a href="#cb124-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-329"><a href="#cb124-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-016}</span></span>
<span id="cb124-330"><a href="#cb124-330" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_measures)[</span>
<span id="cb124-331"><a href="#cb124-331" aria-hidden="true" tabindex="-1"></a>  task_type <span class="sc">==</span> <span class="st">"surv"</span>, <span class="fu">c</span>(<span class="st">"key"</span>, <span class="st">"predict_type"</span>)][<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb124-332"><a href="#cb124-332" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-333"><a href="#cb124-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-334"><a href="#cb124-334" aria-hidden="true" tabindex="-1"></a>There is not a consensus in the literature around the 'best' survival measures to use to evaluate models.</span>
<span id="cb124-335"><a href="#cb124-335" aria-hidden="true" tabindex="-1"></a>We recommend ISBS (Integrated Survival Brier Score) (<span class="in">`msr("surv.graf")`</span>) to evaluate the quality of <span class="in">`distr`</span> predictions, concordance index (<span class="in">`msr("surv.cindex")`</span>) to evaluate a model's discrimination, and D-Calibration (<span class="in">`msr("surv.dcalib")`</span>) to evaluate a model's calibration.</span>
<span id="cb124-336"><a href="#cb124-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-337"><a href="#cb124-337" aria-hidden="true" tabindex="-1"></a>Using these measures, we can now evaluate our predictions from the previous example.</span>
<span id="cb124-338"><a href="#cb124-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-339"><a href="#cb124-339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-017}</span></span>
<span id="cb124-340"><a href="#cb124-340" aria-hidden="true" tabindex="-1"></a>prediction_cph<span class="sc">$</span><span class="fu">score</span>(<span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"surv.graf"</span>, <span class="st">"surv.cindex"</span>, <span class="st">"surv.dcalib"</span>)))</span>
<span id="cb124-341"><a href="#cb124-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-342"><a href="#cb124-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-343"><a href="#cb124-343" aria-hidden="true" tabindex="-1"></a>The model's performance seems okay as the ISBS and DCalib are relatively low and the C-index is greater than 0.5 however it is very hard to determine the performance of any survival model without comparing it to some baseline (usually the Kaplan-Meier).</span>
<span id="cb124-344"><a href="#cb124-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-345"><a href="#cb124-345" aria-hidden="true" tabindex="-1"></a><span class="fu">### Composition {#sec-surv-comp}</span></span>
<span id="cb124-346"><a href="#cb124-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-347"><a href="#cb124-347" aria-hidden="true" tabindex="-1"></a>Throughout <span class="in">`mlr3proba`</span> documentation we refer to "native" and "composed" predictions.</span>
<span id="cb124-348"><a href="#cb124-348" aria-hidden="true" tabindex="-1"></a>We define a 'native' prediction as the prediction made by a model without any post-processing, whereas a 'composed' prediction is returned after post-processing.</span>
<span id="cb124-349"><a href="#cb124-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-350"><a href="#cb124-350" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Internal Composition</span></span>
<span id="cb124-351"><a href="#cb124-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-352"><a href="#cb124-352" aria-hidden="true" tabindex="-1"></a><span class="in">`mlr3proba`</span> makes use of composition internally to return a <span class="in">`"crank"`</span> prediction for every learner.</span>
<span id="cb124-353"><a href="#cb124-353" aria-hidden="true" tabindex="-1"></a>This is to ensure that we can meaningfully benchmark all models according to at least one criterion (discrimination performance).</span>
<span id="cb124-354"><a href="#cb124-354" aria-hidden="true" tabindex="-1"></a>The package uses the following rules to create <span class="in">`"crank"`</span> predictions:</span>
<span id="cb124-355"><a href="#cb124-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-356"><a href="#cb124-356" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>If a model returns a 'risk' prediction then <span class="in">`crank = risk`</span> (we may multiply this by $-1$ to ensure the 'low-value low-risk' interpretation).</span>
<span id="cb124-357"><a href="#cb124-357" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Else if a model returns a <span class="in">`response`</span> prediction then we set <span class="in">`crank = -response`</span>.</span>
<span id="cb124-358"><a href="#cb124-358" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Else if a model returns a <span class="in">`lp`</span> prediction then we set <span class="in">`crank = lp`</span> (or <span class="in">`crank = -lp`</span> if needed).</span>
<span id="cb124-359"><a href="#cb124-359" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Else if a model returns a <span class="in">`distr`</span> prediction then we set <span class="in">`crank`</span> as the sum of the cumulative hazard function (see @Sonabend2022 for full discussion as to why we picked this method).</span>
<span id="cb124-360"><a href="#cb124-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-361"><a href="#cb124-361" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Explicit Composition and Pipelines</span></span>
<span id="cb124-362"><a href="#cb124-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-363"><a href="#cb124-363" aria-hidden="true" tabindex="-1"></a>At the start of this section, we mentioned that it is possible to transform prediction types between each other.</span>
<span id="cb124-364"><a href="#cb124-364" aria-hidden="true" tabindex="-1"></a>In <span class="in">`mlr3proba`</span> this is possible with 'compositor' pipelines (@sec-pipelines).</span>
<span id="cb124-365"><a href="#cb124-365" aria-hidden="true" tabindex="-1"></a>There are several pipelines implemented in the package but three in particular focus on predict type transformation:</span>
<span id="cb124-366"><a href="#cb124-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-367"><a href="#cb124-367" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`r ref("pipeline_crankcompositor()")`</span> -- Transforms a <span class="in">`"distr"`</span> prediction to <span class="in">`"crank"`</span></span>
<span id="cb124-368"><a href="#cb124-368" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span><span class="in">`r ref("pipeline_distrcompositor()")`</span> -- Transforms a <span class="in">`"lp"`</span> prediction to <span class="in">`"distr"`</span></span>
<span id="cb124-369"><a href="#cb124-369" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span><span class="in">`r ref("pipeline_responsecompositor()")`</span> -- Transforms a <span class="in">`"distr"`</span> prediction to <span class="in">`"response"`</span> (survival time)</span>
<span id="cb124-370"><a href="#cb124-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-371"><a href="#cb124-371" aria-hidden="true" tabindex="-1"></a>We internally use a version of the first pipeline whenever we return predictions from survival models so that every model has a <span class="in">`"crank"`</span> prediction type - so only use the first pipeline to overwrite these ranking predictions.</span>
<span id="cb124-372"><a href="#cb124-372" aria-hidden="true" tabindex="-1"></a>In practice, the second pipeline is more common as Cox or Accelerated Failure Time (AFT) type models always return a linear predictor (<span class="in">`"lp"`</span>), but sometimes the internal <span class="in">`predict()`</span> functions don't provide a transformation to a survival distribution prediction (<span class="in">`"distr"`</span>).</span>
<span id="cb124-373"><a href="#cb124-373" aria-hidden="true" tabindex="-1"></a>The third pipeline summarizes the predicted survival curves to a single number (expected survival time), and as previously mentioned, are rarely useful for evaluating the performance of survival machine learning models.</span>
<span id="cb124-374"><a href="#cb124-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-375"><a href="#cb124-375" aria-hidden="true" tabindex="-1"></a>In the example below we load the <span class="in">`rats`</span> dataset, remove factor columns, and then partition the data into training and testing.</span>
<span id="cb124-376"><a href="#cb124-376" aria-hidden="true" tabindex="-1"></a>We construct the <span class="in">`distrcompositor`</span> pipeline around a survival XGBoost Accelerated Failure Time (AFT) learner (<span class="in">`lrn("surv.xgboost.aft")`</span>) which by default makes predictions for <span class="in">`"lp"`</span>, <span class="in">`"crank"`</span> and <span class="in">`"response"`</span>.</span>
<span id="cb124-377"><a href="#cb124-377" aria-hidden="true" tabindex="-1"></a>In the pipeline, we specify that we will estimate the baseline distribution with a <span class="in">`r index("Kaplan-Meier", lower = FALSE)`</span> estimator (<span class="in">`estimator = "kaplan"`</span>) and that we want to assume an AFT form for our estimated distribution (<span class="in">`form = "aft"`</span>).</span>
<span id="cb124-378"><a href="#cb124-378" aria-hidden="true" tabindex="-1"></a>We then train and predict in the usual way and in our output we can now see a <span class="in">`distr`</span> prediction.</span>
<span id="cb124-379"><a href="#cb124-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-380"><a href="#cb124-380" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-018, warning=FALSE}</span></span>
<span id="cb124-381"><a href="#cb124-381" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb124-382"><a href="#cb124-382" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners)</span>
<span id="cb124-383"><a href="#cb124-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-384"><a href="#cb124-384" aria-hidden="true" tabindex="-1"></a>tsk_rats <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"rats"</span>)<span class="sc">$</span><span class="fu">select</span>(<span class="fu">c</span>(<span class="st">"litter"</span>, <span class="st">"rx"</span>))</span>
<span id="cb124-385"><a href="#cb124-385" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk_rats)</span>
<span id="cb124-386"><a href="#cb124-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-387"><a href="#cb124-387" aria-hidden="true" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"surv.xgboost.aft"</span>, <span class="at">nrounds =</span> <span class="dv">10</span>)</span>
<span id="cb124-388"><a href="#cb124-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-389"><a href="#cb124-389" aria-hidden="true" tabindex="-1"></a><span class="co"># no distr output</span></span>
<span id="cb124-390"><a href="#cb124-390" aria-hidden="true" tabindex="-1"></a>learner<span class="sc">$</span><span class="fu">train</span>(tsk_rats, split<span class="sc">$</span>train)<span class="sc">$</span><span class="fu">predict</span>(tsk_rats, split<span class="sc">$</span>test)</span>
<span id="cb124-391"><a href="#cb124-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-392"><a href="#cb124-392" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">ppl</span>(</span>
<span id="cb124-393"><a href="#cb124-393" aria-hidden="true" tabindex="-1"></a>  <span class="st">"distrcompositor"</span>,</span>
<span id="cb124-394"><a href="#cb124-394" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> learner,</span>
<span id="cb124-395"><a href="#cb124-395" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimator =</span> <span class="st">"kaplan"</span>,</span>
<span id="cb124-396"><a href="#cb124-396" aria-hidden="true" tabindex="-1"></a>  <span class="at">form =</span> <span class="st">"aft"</span>,</span>
<span id="cb124-397"><a href="#cb124-397" aria-hidden="true" tabindex="-1"></a>  <span class="at">graph_learner =</span> <span class="cn">TRUE</span></span>
<span id="cb124-398"><a href="#cb124-398" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb124-399"><a href="#cb124-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-400"><a href="#cb124-400" aria-hidden="true" tabindex="-1"></a><span class="co"># now with distr</span></span>
<span id="cb124-401"><a href="#cb124-401" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span><span class="fu">train</span>(tsk_rats, split<span class="sc">$</span>train)<span class="sc">$</span><span class="fu">predict</span>(tsk_rats, split<span class="sc">$</span>test)</span>
<span id="cb124-402"><a href="#cb124-402" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-403"><a href="#cb124-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-404"><a href="#cb124-404" aria-hidden="true" tabindex="-1"></a>Mathematically, we have done the following:</span>
<span id="cb124-405"><a href="#cb124-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-406"><a href="#cb124-406" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Assume our estimated distribution will have the form $S(t) = S_0(\frac{t}{\exp(\eta)})$ where $S$ is the survival function, $S_0$ is the baseline survival function and $\eta$ is the linear predictor.</span>
<span id="cb124-407"><a href="#cb124-407" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate $\hat{\eta}$ prediction using XGBoost</span>
<span id="cb124-408"><a href="#cb124-408" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate $\hat{S}_0(t)$ with the Kaplan-Meier estimator</span>
<span id="cb124-409"><a href="#cb124-409" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Put this all together as $S(t) = \hat{S}_0(\frac{t}{\exp(\hat{\eta})})$</span>
<span id="cb124-410"><a href="#cb124-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-411"><a href="#cb124-411" aria-hidden="true" tabindex="-1"></a>For more detail about prediction types and composition we recommend @Kalbfleisch2011.</span>
<span id="cb124-412"><a href="#cb124-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-413"><a href="#cb124-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-414"><a href="#cb124-414" aria-hidden="true" tabindex="-1"></a><span class="fu">### Putting It All Together {#sec-survival-all}</span></span>
<span id="cb124-415"><a href="#cb124-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-416"><a href="#cb124-416" aria-hidden="true" tabindex="-1"></a>Finally, we will put all the above into practice in a small benchmark experiment.</span>
<span id="cb124-417"><a href="#cb124-417" aria-hidden="true" tabindex="-1"></a>We first load <span class="in">`tsk("grace")`</span> (which only has numeric features) and sample 500 rows randomly.</span>
<span id="cb124-418"><a href="#cb124-418" aria-hidden="true" tabindex="-1"></a>We then select the ISBS, D-Calibration, and C-index to evaluate predictions, set up the same pipeline we used in the previous experiment, and load a Cox PH and Kaplan-Meier estimator.</span>
<span id="cb124-419"><a href="#cb124-419" aria-hidden="true" tabindex="-1"></a>We run our experiment with three-fold CV and aggregate the results.</span>
<span id="cb124-420"><a href="#cb124-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-421"><a href="#cb124-421" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-019, warning=FALSE}</span></span>
<span id="cb124-422"><a href="#cb124-422" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb124-423"><a href="#cb124-423" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners)</span>
<span id="cb124-424"><a href="#cb124-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-425"><a href="#cb124-425" aria-hidden="true" tabindex="-1"></a>tsk_grace <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"grace"</span>)</span>
<span id="cb124-426"><a href="#cb124-426" aria-hidden="true" tabindex="-1"></a>tsk_grace<span class="sc">$</span><span class="fu">filter</span>(<span class="fu">sample</span>(tsk_grace<span class="sc">$</span>nrow, <span class="dv">500</span>))</span>
<span id="cb124-427"><a href="#cb124-427" aria-hidden="true" tabindex="-1"></a>msr_txt <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"surv.graf"</span>, <span class="st">"surv.cindex"</span>, <span class="st">"surv.dcalib"</span>)</span>
<span id="cb124-428"><a href="#cb124-428" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(msr_txt)</span>
<span id="cb124-429"><a href="#cb124-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-430"><a href="#cb124-430" aria-hidden="true" tabindex="-1"></a>graph_learner <span class="ot">=</span> <span class="fu">ppl</span>(</span>
<span id="cb124-431"><a href="#cb124-431" aria-hidden="true" tabindex="-1"></a>  <span class="st">"distrcompositor"</span>,</span>
<span id="cb124-432"><a href="#cb124-432" aria-hidden="true" tabindex="-1"></a>  <span class="at">learner =</span> <span class="fu">lrn</span>(<span class="st">"surv.xgboost.aft"</span>, <span class="at">nrounds =</span> <span class="dv">10</span>),</span>
<span id="cb124-433"><a href="#cb124-433" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimator =</span> <span class="st">"kaplan"</span>,</span>
<span id="cb124-434"><a href="#cb124-434" aria-hidden="true" tabindex="-1"></a>  <span class="at">form =</span> <span class="st">"aft"</span>,</span>
<span id="cb124-435"><a href="#cb124-435" aria-hidden="true" tabindex="-1"></a>  <span class="at">graph_learner =</span> <span class="cn">TRUE</span>,</span>
<span id="cb124-436"><a href="#cb124-436" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale_lp =</span> <span class="cn">TRUE</span></span>
<span id="cb124-437"><a href="#cb124-437" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb124-438"><a href="#cb124-438" aria-hidden="true" tabindex="-1"></a>graph_learner<span class="sc">$</span>id <span class="ot">=</span> <span class="st">"XGBoost-AFT"</span></span>
<span id="cb124-439"><a href="#cb124-439" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">c</span>(<span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"surv.coxph"</span>, <span class="st">"surv.kaplan"</span>)), graph_learner)</span>
<span id="cb124-440"><a href="#cb124-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-441"><a href="#cb124-441" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_grace, learners,</span>
<span id="cb124-442"><a href="#cb124-442" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)))</span>
<span id="cb124-443"><a href="#cb124-443" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(measures)[, <span class="fu">c</span>(<span class="st">"learner_id"</span>, ..msr_txt)]</span>
<span id="cb124-444"><a href="#cb124-444" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-445"><a href="#cb124-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-446"><a href="#cb124-446" aria-hidden="true" tabindex="-1"></a>In this small experiment, XGBoost-AFT and Cox PH have the best discrimination, the Kaplan-Meier baseline has the best calibration, and Cox PH has the best overall predictive accuracy (with the lowest ISBS).</span>
<span id="cb124-447"><a href="#cb124-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-448"><a href="#cb124-448" aria-hidden="true" tabindex="-1"></a><span class="fu">## Density Estimation {#sec-density}</span></span>
<span id="cb124-449"><a href="#cb124-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-450"><a href="#cb124-450" aria-hidden="true" tabindex="-1"></a><span class="in">`r index('Density estimation')`</span> is a learning task to estimate the unknown distribution from which a univariate dataset is generated or put more simply to estimate the probability density (or mass) function for a single variable.</span>
<span id="cb124-451"><a href="#cb124-451" aria-hidden="true" tabindex="-1"></a>As with survival analysis, density estimation is implemented in <span class="in">`mlr3proba`</span>, as both can make probability distribution predictions (hence the name "**mlr3proba**bilistic").</span>
<span id="cb124-452"><a href="#cb124-452" aria-hidden="true" tabindex="-1"></a>Unconditional density estimation (i.e. estimation of a target without any covariates) is viewed as an unsupervised task, which means the 'truth' is never known.</span>
<span id="cb124-453"><a href="#cb124-453" aria-hidden="true" tabindex="-1"></a>For a good overview of density estimation see @Silverman1986.</span>
<span id="cb124-454"><a href="#cb124-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-455"><a href="#cb124-455" aria-hidden="true" tabindex="-1"></a>The package <span class="in">`mlr3proba`</span> extends <span class="in">`mlr3`</span> with the following objects for density estimation:</span>
<span id="cb124-456"><a href="#cb124-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-457"><a href="#cb124-457" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("TaskDens")`</span> to define density tasks.</span>
<span id="cb124-458"><a href="#cb124-458" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("LearnerDens")`</span> as the base class for density estimators.</span>
<span id="cb124-459"><a href="#cb124-459" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("PredictionDens")`</span> for density predictions.</span>
<span id="cb124-460"><a href="#cb124-460" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("MeasureDens")`</span> as a specialized class for density performance measures.</span>
<span id="cb124-461"><a href="#cb124-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-462"><a href="#cb124-462" aria-hidden="true" tabindex="-1"></a>We will consider each in turn.</span>
<span id="cb124-463"><a href="#cb124-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-464"><a href="#cb124-464" aria-hidden="true" tabindex="-1"></a><span class="fu">### TaskDens</span></span>
<span id="cb124-465"><a href="#cb124-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-466"><a href="#cb124-466" aria-hidden="true" tabindex="-1"></a>As density estimation is an unsupervised task, there is no target for prediction.</span>
<span id="cb124-467"><a href="#cb124-467" aria-hidden="true" tabindex="-1"></a>In the code below we construct a density task using <span class="in">`r ref("as_task_dens()")`</span> which takes one argument, a <span class="in">`data.frame`</span> type object with exactly one column (which we will use to estimate the underlying distribution).</span>
<span id="cb124-468"><a href="#cb124-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-469"><a href="#cb124-469" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-020}</span></span>
<span id="cb124-470"><a href="#cb124-470" aria-hidden="true" tabindex="-1"></a>tsk_dens <span class="ot">=</span> <span class="fu">as_task_dens</span>(<span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>)))</span>
<span id="cb124-471"><a href="#cb124-471" aria-hidden="true" tabindex="-1"></a>tsk_dens</span>
<span id="cb124-472"><a href="#cb124-472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-473"><a href="#cb124-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-474"><a href="#cb124-474" aria-hidden="true" tabindex="-1"></a>As with other tasks, we have included a couple of tasks that come shipped with <span class="in">`mlr3proba`</span>:</span>
<span id="cb124-475"><a href="#cb124-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-476"><a href="#cb124-476" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-021}</span></span>
<span id="cb124-477"><a href="#cb124-477" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_tasks)[task_type <span class="sc">==</span> <span class="st">"dens"</span>, <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>)]</span>
<span id="cb124-478"><a href="#cb124-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-479"><a href="#cb124-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-480"><a href="#cb124-480" aria-hidden="true" tabindex="-1"></a><span class="fu">### LearnerDens and PredictionDens</span></span>
<span id="cb124-481"><a href="#cb124-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-482"><a href="#cb124-482" aria-hidden="true" tabindex="-1"></a>Density learners may return the following prediction types:</span>
<span id="cb124-483"><a href="#cb124-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-484"><a href="#cb124-484" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`distr`</span> -- probability distribution</span>
<span id="cb124-485"><a href="#cb124-485" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`pdf`</span> -- probability density function</span>
<span id="cb124-486"><a href="#cb124-486" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`cdf`</span> -- cumulative distribution function</span>
<span id="cb124-487"><a href="#cb124-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-488"><a href="#cb124-488" aria-hidden="true" tabindex="-1"></a>All learners will return a <span class="in">`distr`</span> and <span class="in">`pdf`</span> prediction but only some can make <span class="in">`cdf`</span> predictions.</span>
<span id="cb124-489"><a href="#cb124-489" aria-hidden="true" tabindex="-1"></a>Again, the <span class="in">`distr`</span> predict type is implemented using <span class="in">`distr6`</span>.</span>
<span id="cb124-490"><a href="#cb124-490" aria-hidden="true" tabindex="-1"></a>In the code below we train and 'predict' with a histogram learner and then plot the estimated probability density function (@fig-dens-hist), which closely matches the underlying Normally-distributed data.</span>
<span id="cb124-491"><a href="#cb124-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-492"><a href="#cb124-492" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-022}</span></span>
<span id="cb124-493"><a href="#cb124-493" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dens-hist</span></span>
<span id="cb124-494"><a href="#cb124-494" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Predicted density from the histogram learner, which closely resembles the underlying N(0, 1) data.</span></span>
<span id="cb124-495"><a href="#cb124-495" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Image shows a line plot with x-axis between (-2,2) and y-axis between (0,0.4). The plot closely resembles a Normal(0, 1) distribution with a peak at 0.4.</span></span>
<span id="cb124-496"><a href="#cb124-496" aria-hidden="true" tabindex="-1"></a>lrn_hist <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"dens.hist"</span>)</span>
<span id="cb124-497"><a href="#cb124-497" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_hist<span class="sc">$</span><span class="fu">train</span>(tsk_dens, <span class="dv">1</span><span class="sc">:</span><span class="dv">900</span>)<span class="sc">$</span><span class="fu">predict</span>(tsk_dens, <span class="dv">901</span><span class="sc">:</span><span class="dv">1000</span>)</span>
<span id="cb124-498"><a href="#cb124-498" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq.int</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="fl">0.01</span>)</span>
<span id="cb124-499"><a href="#cb124-499" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> prediction<span class="sc">$</span>distr<span class="sc">$</span><span class="fu">pdf</span>(x))</span>
<span id="cb124-500"><a href="#cb124-500" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb124-501"><a href="#cb124-501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-502"><a href="#cb124-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-503"><a href="#cb124-503" aria-hidden="true" tabindex="-1"></a>The <span class="in">`pdf`</span> and <span class="in">`cdf`</span> predict types are simply wrappers around <span class="in">`distr$pdf`</span> and <span class="in">`distr$cdf`</span> respectively:</span>
<span id="cb124-504"><a href="#cb124-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-505"><a href="#cb124-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-023}</span></span>
<span id="cb124-506"><a href="#cb124-506" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_hist<span class="sc">$</span><span class="fu">train</span>(tsk_dens, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)<span class="sc">$</span><span class="fu">predict</span>(tsk_dens, <span class="dv">11</span><span class="sc">:</span><span class="dv">13</span>)</span>
<span id="cb124-507"><a href="#cb124-507" aria-hidden="true" tabindex="-1"></a><span class="co"># pdf and cdf columns in output</span></span>
<span id="cb124-508"><a href="#cb124-508" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb124-509"><a href="#cb124-509" aria-hidden="true" tabindex="-1"></a><span class="co"># comparing cdf from prediction to $cdf method from distr</span></span>
<span id="cb124-510"><a href="#cb124-510" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(prediction<span class="sc">$</span>distr<span class="sc">$</span><span class="fu">cdf</span>(tsk_dens<span class="sc">$</span><span class="fu">data</span>()<span class="sc">$</span>x[<span class="dv">11</span><span class="sc">:</span><span class="dv">13</span>]),</span>
<span id="cb124-511"><a href="#cb124-511" aria-hidden="true" tabindex="-1"></a>  prediction<span class="sc">$</span>cdf[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span>
<span id="cb124-512"><a href="#cb124-512" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-513"><a href="#cb124-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-514"><a href="#cb124-514" aria-hidden="true" tabindex="-1"></a><span class="fu">### MeasureDens and Putting It All Together</span></span>
<span id="cb124-515"><a href="#cb124-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-516"><a href="#cb124-516" aria-hidden="true" tabindex="-1"></a>At the time of publication, the only measure implemented in <span class="in">`mlr3proba`</span> for density estimation is logloss, which is defined in the same way as in classification, $L(y) = -\log(\hat{f}_Y(y))$, where $\hat{f}_Y$ is our estimated probability density function.</span>
<span id="cb124-517"><a href="#cb124-517" aria-hidden="true" tabindex="-1"></a>Putting this together with the above we are now ready to train a density learner, estimate a distribution, and evaluate our estimation:</span>
<span id="cb124-518"><a href="#cb124-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-519"><a href="#cb124-519" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-024}</span></span>
<span id="cb124-520"><a href="#cb124-520" aria-hidden="true" tabindex="-1"></a>msr_logloss <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"dens.logloss"</span>)</span>
<span id="cb124-521"><a href="#cb124-521" aria-hidden="true" tabindex="-1"></a>msr_logloss</span>
<span id="cb124-522"><a href="#cb124-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-523"><a href="#cb124-523" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(msr_logloss)</span>
<span id="cb124-524"><a href="#cb124-524" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-525"><a href="#cb124-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-526"><a href="#cb124-526" aria-hidden="true" tabindex="-1"></a>This output is most easily interpreted when compared to other learners in a benchmark experiment, so let us put everything together to conduct a small benchmark study on <span class="in">`tsk("faithful")`</span> task using some of the integrated density learners:</span>
<span id="cb124-527"><a href="#cb124-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-528"><a href="#cb124-528" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-025, message=FALSE, warning=FALSE, results='hide'}</span></span>
<span id="cb124-529"><a href="#cb124-529" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners)</span>
<span id="cb124-530"><a href="#cb124-530" aria-hidden="true" tabindex="-1"></a>tsk_faithful <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"faithful"</span>)</span>
<span id="cb124-531"><a href="#cb124-531" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"dens.hist"</span>, <span class="st">"dens.pen"</span>, <span class="st">"dens.kde"</span>))</span>
<span id="cb124-532"><a href="#cb124-532" aria-hidden="true" tabindex="-1"></a>measure <span class="ot">=</span> <span class="fu">msr</span>(<span class="st">"dens.logloss"</span>)</span>
<span id="cb124-533"><a href="#cb124-533" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_faithful, learners,</span>
<span id="cb124-534"><a href="#cb124-534" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>)))</span>
<span id="cb124-535"><a href="#cb124-535" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(measure)</span>
<span id="cb124-536"><a href="#cb124-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-537"><a href="#cb124-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-538"><a href="#cb124-538" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-026}</span></span>
<span id="cb124-539"><a href="#cb124-539" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb124-540"><a href="#cb124-540" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: false</span></span>
<span id="cb124-541"><a href="#cb124-541" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bmr, <span class="at">measure =</span> measure)</span>
<span id="cb124-542"><a href="#cb124-542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-543"><a href="#cb124-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-544"><a href="#cb124-544" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-027}</span></span>
<span id="cb124-545"><a href="#cb124-545" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb124-546"><a href="#cb124-546" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb124-547"><a href="#cb124-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb124-548"><a href="#cb124-548" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-density</span></span>
<span id="cb124-549"><a href="#cb124-549" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Three boxplots comparing performance of dens.hist, dens.pen, and dens.kde on `tsk("faithful")`.</span></span>
<span id="cb124-550"><a href="#cb124-550" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Three boxplots labeled 'dens.hist', 'dens.pen', 'dens.kde'. y-axis is 'dens.logloss' between 0.9 and 1.2. 'dens.hist' is a narrow boxplot between 1.0 and 1.1. 'dens.pen' is very wide between 0.95 and 2.1. 'dens.kde' is narrow between 0.95 and 1.0.</span></span>
<span id="cb124-551"><a href="#cb124-551" aria-hidden="true" tabindex="-1"></a>plt <span class="ot">=</span> ggplot2<span class="sc">::</span><span class="fu">last_plot</span>()</span>
<span id="cb124-552"><a href="#cb124-552" aria-hidden="true" tabindex="-1"></a>plt<span class="sc">$</span>layers[[<span class="dv">1</span>]]<span class="sc">$</span>mapping<span class="sc">$</span>fill <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb124-553"><a href="#cb124-553" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(plt)</span>
<span id="cb124-554"><a href="#cb124-554" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-555"><a href="#cb124-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-556"><a href="#cb124-556" aria-hidden="true" tabindex="-1"></a>The results (@fig-beyond-density) of this experiment indicate that the sophisticated Penalized Density Estimator does not outperform the baseline histogram, but the Kernel Density Estimator has at least consistently better (i.e. lower) logloss results.</span>
<span id="cb124-557"><a href="#cb124-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-558"><a href="#cb124-558" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cluster Analysis {#sec-cluster}</span></span>
<span id="cb124-559"><a href="#cb124-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-560"><a href="#cb124-560" aria-hidden="true" tabindex="-1"></a><span class="in">`r index("Cluster analysis")`</span> is another unsupervised task implemented in <span class="in">`mlr3`</span>.</span>
<span id="cb124-561"><a href="#cb124-561" aria-hidden="true" tabindex="-1"></a>The objective of cluster analysis is to group data into clusters, where each cluster contains similar observations.</span>
<span id="cb124-562"><a href="#cb124-562" aria-hidden="true" tabindex="-1"></a>The similarity is based on specified metrics that are task and application-dependent.</span>
<span id="cb124-563"><a href="#cb124-563" aria-hidden="true" tabindex="-1"></a>Unlike classification where we try to predict a class for each observation, in cluster analysis there is no 'true' label or class to predict.</span>
<span id="cb124-564"><a href="#cb124-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-565"><a href="#cb124-565" aria-hidden="true" tabindex="-1"></a>The package <span class="in">`r mlr3cluster`</span> extends <span class="in">`mlr3`</span> with the following objects for cluster analysis:</span>
<span id="cb124-566"><a href="#cb124-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-567"><a href="#cb124-567" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("TaskClust")`</span> to define clustering tasks</span>
<span id="cb124-568"><a href="#cb124-568" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("LearnerClust")`</span> as the base class for clustering learners</span>
<span id="cb124-569"><a href="#cb124-569" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("PredictionClust")`</span> as the specialized class for <span class="in">`r ref("Prediction")`</span> objects</span>
<span id="cb124-570"><a href="#cb124-570" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`r ref("MeasureClust")`</span> as the specialized class for performance measures</span>
<span id="cb124-571"><a href="#cb124-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-572"><a href="#cb124-572" aria-hidden="true" tabindex="-1"></a>We will consider each in turn.</span>
<span id="cb124-573"><a href="#cb124-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-574"><a href="#cb124-574" aria-hidden="true" tabindex="-1"></a><span class="fu">### TaskClust</span></span>
<span id="cb124-575"><a href="#cb124-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-576"><a href="#cb124-576" aria-hidden="true" tabindex="-1"></a>Similarly to density estimation (@sec-density), there is no target for prediction and so no <span class="in">`truth`</span> field in <span class="in">`r ref("TaskClust")`</span>.</span>
<span id="cb124-577"><a href="#cb124-577" aria-hidden="true" tabindex="-1"></a>By example, we will look at the <span class="in">`r ref("cluster::ruspini")`</span> dataset, which has 75 rows and two columns and was first introduced in @Ruspini1970 to illustrate different clustering techniques.</span>
<span id="cb124-578"><a href="#cb124-578" aria-hidden="true" tabindex="-1"></a>The observations in the dataset form four natural clusters (@fig-beyond-clust-ruspini).</span>
<span id="cb124-579"><a href="#cb124-579" aria-hidden="true" tabindex="-1"></a>In the code below we construct a cluster task using <span class="in">`r ref("as_task_clust()")`</span> which only takes one argument, a <span class="in">`data.frame`</span> type object.</span>
<span id="cb124-580"><a href="#cb124-580" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-028, warning=FALSE, message=FALSE}</span></span>
<span id="cb124-581"><a href="#cb124-581" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-ruspini</span></span>
<span id="cb124-582"><a href="#cb124-582" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Distribution of the `ruspini` dataset.</span></span>
<span id="cb124-583"><a href="#cb124-583" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Four grids. Top-left shows a curve increasing sharply between (0,0.003) and (30,0.012) then decreasing to (120, 0.003). Top-right just says 'Corr: 0.065'. Bottom-left shows four distinct clusters of points. Bottom-right increases from (0, 50) to (140, 150) then decreases to (155, 100)."</span></span>
<span id="cb124-584"><a href="#cb124-584" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb124-585"><a href="#cb124-585" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb124-586"><a href="#cb124-586" aria-hidden="true" tabindex="-1"></a>tsk_ruspini <span class="ot">=</span> <span class="fu">as_task_clust</span>(ruspini)</span>
<span id="cb124-587"><a href="#cb124-587" aria-hidden="true" tabindex="-1"></a>tsk_ruspini</span>
<span id="cb124-588"><a href="#cb124-588" aria-hidden="true" tabindex="-1"></a>tsk_ruspini<span class="sc">$</span><span class="fu">data</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>) <span class="co"># print first 3 rows</span></span>
<span id="cb124-589"><a href="#cb124-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-590"><a href="#cb124-590" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tsk_ruspini)</span>
<span id="cb124-591"><a href="#cb124-591" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-592"><a href="#cb124-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-593"><a href="#cb124-593" aria-hidden="true" tabindex="-1"></a>Technically, we did not need to create a new task for the <span class="in">`ruspini`</span> dataset since it is already included in the package, along with one other task:</span>
<span id="cb124-594"><a href="#cb124-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-595"><a href="#cb124-595" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-029}</span></span>
<span id="cb124-596"><a href="#cb124-596" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.table</span>(mlr_tasks)[task_type <span class="sc">==</span> <span class="st">"clust"</span>, <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>)]</span>
<span id="cb124-597"><a href="#cb124-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-598"><a href="#cb124-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-599"><a href="#cb124-599" aria-hidden="true" tabindex="-1"></a><span class="fu">### LearnerClust and PredictionClust</span></span>
<span id="cb124-600"><a href="#cb124-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-601"><a href="#cb124-601" aria-hidden="true" tabindex="-1"></a>As with density estimation, we refer to <span class="in">`training`</span> and <span class="in">`predicting`</span> for clustering to be consistent with the <span class="in">`mlr3`</span> interface, but strictly speaking, this should be <span class="in">`clustering`</span> and <span class="in">`assigning`</span> (the latter we will return to shortly).</span>
<span id="cb124-602"><a href="#cb124-602" aria-hidden="true" tabindex="-1"></a>Two <span class="in">`predict_types`</span> are available for clustering learners:</span>
<span id="cb124-603"><a href="#cb124-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-604"><a href="#cb124-604" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`"partition"`</span> -- Estimate of which cluster an observation falls into</span>
<span id="cb124-605"><a href="#cb124-605" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span><span class="in">`"prob"`</span> -- Probability of an observation belonging to each cluster</span>
<span id="cb124-606"><a href="#cb124-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-607"><a href="#cb124-607" aria-hidden="true" tabindex="-1"></a>Similarly to classification, prediction types of clustering learners are either deterministic (<span class="in">`"partition"`</span>) or probabilistic (<span class="in">`"prob"`</span>).</span>
<span id="cb124-608"><a href="#cb124-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-609"><a href="#cb124-609" aria-hidden="true" tabindex="-1"></a>Below we construct a C-Means clustering learner with <span class="in">`"prob"`</span> prediction type and three clusters (<span class="in">`centers = 3`</span>), train it on the <span class="in">`ruspini`</span> dataset and then return the cluster assignments (<span class="in">`$assignments`</span>) for six random observations.</span>
<span id="cb124-610"><a href="#cb124-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-611"><a href="#cb124-611" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-030}</span></span>
<span id="cb124-612"><a href="#cb124-612" aria-hidden="true" tabindex="-1"></a>lrn_cmeans <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"clust.cmeans"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>, <span class="at">centers =</span> <span class="dv">3</span>)</span>
<span id="cb124-613"><a href="#cb124-613" aria-hidden="true" tabindex="-1"></a>lrn_cmeans</span>
<span id="cb124-614"><a href="#cb124-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-615"><a href="#cb124-615" aria-hidden="true" tabindex="-1"></a>lrn_cmeans<span class="sc">$</span><span class="fu">train</span>(tsk_ruspini)</span>
<span id="cb124-616"><a href="#cb124-616" aria-hidden="true" tabindex="-1"></a>lrn_cmeans<span class="sc">$</span>assignments[<span class="fu">sample</span>(tsk_ruspini<span class="sc">$</span>nrow, <span class="dv">6</span>)]</span>
<span id="cb124-617"><a href="#cb124-617" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-618"><a href="#cb124-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-619"><a href="#cb124-619" aria-hidden="true" tabindex="-1"></a>As clustering is unsupervised, it often does not make sense to use <span class="in">`predict`</span> for new data however this is still possible using the <span class="in">`mlr3`</span> interface.</span>
<span id="cb124-620"><a href="#cb124-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-621"><a href="#cb124-621" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-031, warning = FALSE, message = FALSE}</span></span>
<span id="cb124-622"><a href="#cb124-622" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-ruspini-estimated</span></span>
<span id="cb124-623"><a href="#cb124-623" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Distribution of the estimated clusters.</span></span>
<span id="cb124-624"><a href="#cb124-624" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Four grids. Top-left shows three overlapping curves in purple (cluster 1), blue (cluster 2) and green (cluster 3). The purple and blue curves are zero in most places but then peak at (30, 120) and (60, 120) respectively. The green curve starts at (0,0) then increases slowly to (40, 120) then decreases bumpily to (120, 60). Top-right says '-0.78' in green (cluster 3), '0' in blue (cluster 2), and '-0.05' in purple (cluster 1). Bottom-left shows four distinct clusters of points, two clusters are green, one (bottom) is blue, one (bottom left) is purple. Bottom-right: line graphs that show a similar but inverted shape as top-left."</span></span>
<span id="cb124-625"><a href="#cb124-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-626"><a href="#cb124-626" aria-hidden="true" tabindex="-1"></a><span class="co"># using different data for estimation (rare use case)</span></span>
<span id="cb124-627"><a href="#cb124-627" aria-hidden="true" tabindex="-1"></a>lrn_cmeans<span class="sc">$</span><span class="fu">train</span>(tsk_ruspini, <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>)<span class="sc">$</span><span class="fu">predict</span>(tsk_ruspini, <span class="dv">31</span><span class="sc">:</span><span class="dv">32</span>)</span>
<span id="cb124-628"><a href="#cb124-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-629"><a href="#cb124-629" aria-hidden="true" tabindex="-1"></a><span class="co"># using same data as for estimation (common use case)</span></span>
<span id="cb124-630"><a href="#cb124-630" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> lrn_cmeans<span class="sc">$</span><span class="fu">train</span>(tsk_ruspini)<span class="sc">$</span><span class="fu">predict</span>(tsk_ruspini)</span>
<span id="cb124-631"><a href="#cb124-631" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, tsk_ruspini)</span>
<span id="cb124-632"><a href="#cb124-632" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-633"><a href="#cb124-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-634"><a href="#cb124-634" aria-hidden="true" tabindex="-1"></a>While two prediction types are possible, there are some learners where 'prediction' can never make sense, for example in <span class="in">`r index("hierarchical clustering", aside = TRUE)`</span>.</span>
<span id="cb124-635"><a href="#cb124-635" aria-hidden="true" tabindex="-1"></a>In hierarchical clustering, the goal is to build a hierarchy of nested clusters by either splitting large clusters into smaller ones or merging smaller clusters into bigger ones.</span>
<span id="cb124-636"><a href="#cb124-636" aria-hidden="true" tabindex="-1"></a>The final result is a tree or <span class="in">`r index('dendrogram')`</span> which can change if a new data point is added.</span>
<span id="cb124-637"><a href="#cb124-637" aria-hidden="true" tabindex="-1"></a>For consistency, <span class="in">`mlr3cluster`</span> offers a <span class="in">`predict`</span> method for hierarchical clusters but with a warning:</span>
<span id="cb124-638"><a href="#cb124-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-639"><a href="#cb124-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-032}</span></span>
<span id="cb124-640"><a href="#cb124-640" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-dend</span></span>
<span id="cb124-641"><a href="#cb124-641" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Dendrogram representing hierarchical clustering of the `ruspini` dataset. y-axis is similarity of points such that the lower observations (x-axis) are connected, the greater their similarity. The top split represents the separation of the two clusters.</span></span>
<span id="cb124-642"><a href="#cb124-642" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Plot shows a horizontal line that connects two vertical lines. Each vertical line connects to another horizontal line that splits into two more vertical lines, which continues for up to nine breaks."</span></span>
<span id="cb124-643"><a href="#cb124-643" aria-hidden="true" tabindex="-1"></a>lrn_hclust <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"clust.hclust"</span>, <span class="at">k =</span> <span class="dv">2</span>)</span>
<span id="cb124-644"><a href="#cb124-644" aria-hidden="true" tabindex="-1"></a>lrn_hclust<span class="sc">$</span><span class="fu">train</span>(tsk_ruspini)<span class="sc">$</span><span class="fu">predict</span>(tsk_ruspini)</span>
<span id="cb124-645"><a href="#cb124-645" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(lrn_hclust) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">axis.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="fl">5.5</span>))</span>
<span id="cb124-646"><a href="#cb124-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-647"><a href="#cb124-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-648"><a href="#cb124-648" aria-hidden="true" tabindex="-1"></a>In this case, the <span class="in">`predict`</span> method simply cuts the dendrogram into the number of clusters specified by <span class="in">`k`</span> parameter of the learner.</span>
<span id="cb124-649"><a href="#cb124-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-650"><a href="#cb124-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-651"><a href="#cb124-651" aria-hidden="true" tabindex="-1"></a><span class="fu">### MeasureClust</span></span>
<span id="cb124-652"><a href="#cb124-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-653"><a href="#cb124-653" aria-hidden="true" tabindex="-1"></a>As previously discussed, unsupervised tasks do not have ground truth data to compare to in model evaluation.</span>
<span id="cb124-654"><a href="#cb124-654" aria-hidden="true" tabindex="-1"></a>However, we can still measure the quality of cluster assignments by quantifying how closely objects within the same cluster are related (<span class="in">`r index("cluster cohesion")`</span>) as well as how distinct different clusters are from each other (<span class="in">`r index("cluster separation")`</span>).</span>
<span id="cb124-655"><a href="#cb124-655" aria-hidden="true" tabindex="-1"></a>There are a few built-in evaluation metrics available to assess the quality of clustering, which can be found by searching the <span class="in">`r ref("mlr_measures")`</span> dictionary.</span>
<span id="cb124-656"><a href="#cb124-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-657"><a href="#cb124-657" aria-hidden="true" tabindex="-1"></a>Two common measures are the within sum of squares (WSS) measure (<span class="in">`msr("clust.wss")`</span>) and the silhouette coefficient (<span class="in">`msr("clust.silhouette")`</span>).</span>
<span id="cb124-658"><a href="#cb124-658" aria-hidden="true" tabindex="-1"></a>WSS calculates the sum of squared differences between observations and centroids, which is a quantification of cluster cohesion (smaller values indicate the clusters are more compact).</span>
<span id="cb124-659"><a href="#cb124-659" aria-hidden="true" tabindex="-1"></a>The silhouette coefficient quantifies how well each point belongs to its assigned cluster versus neighboring clusters, where scores closer to <span class="in">`1`</span> indicate well clustered and scores closer to <span class="in">`-1`</span> indicate poorly clustered.</span>
<span id="cb124-660"><a href="#cb124-660" aria-hidden="true" tabindex="-1"></a>Note that the silhouette measure in <span class="in">`mlr3cluster`</span> returns the mean silhouette score across all observations and when there is only a single cluster, the measure simply outputs 0.</span>
<span id="cb124-661"><a href="#cb124-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-662"><a href="#cb124-662" aria-hidden="true" tabindex="-1"></a>Putting this together with the above we can now score our cluster estimation (note we must pass the <span class="in">`task`</span> to <span class="in">`$score`</span>):</span>
<span id="cb124-663"><a href="#cb124-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-664"><a href="#cb124-664" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-033}</span></span>
<span id="cb124-665"><a href="#cb124-665" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">msrs</span>(<span class="fu">c</span>(<span class="st">"clust.wss"</span>, <span class="st">"clust.silhouette"</span>))</span>
<span id="cb124-666"><a href="#cb124-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-667"><a href="#cb124-667" aria-hidden="true" tabindex="-1"></a>prediction<span class="sc">$</span><span class="fu">score</span>(measures, <span class="at">task =</span> tsk_ruspini)</span>
<span id="cb124-668"><a href="#cb124-668" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-669"><a href="#cb124-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-670"><a href="#cb124-670" aria-hidden="true" tabindex="-1"></a>The very high WSS and middling mean silhouette coefficient indicate that our clusters could do with a bit more work.</span>
<span id="cb124-671"><a href="#cb124-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-672"><a href="#cb124-672" aria-hidden="true" tabindex="-1"></a>Often reducing an unsupervised task to a quantitative measure may not be useful (given no ground truth) and instead visualization (discussed next) may be a more effective tool for assessing the quality of the clusters.</span>
<span id="cb124-673"><a href="#cb124-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-674"><a href="#cb124-674" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualization</span></span>
<span id="cb124-675"><a href="#cb124-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-676"><a href="#cb124-676" aria-hidden="true" tabindex="-1"></a>As clustering is an unsupervised task, visualization can be essential not just for 'evaluating' models but also for determining if our learners are performing as expected for our task. This section will look at visualizations for supporting clustering choices and following that we will consider plots for evaluating model performance.</span>
<span id="cb124-677"><a href="#cb124-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-678"><a href="#cb124-678" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Visualizing Clusters</span></span>
<span id="cb124-679"><a href="#cb124-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-680"><a href="#cb124-680" aria-hidden="true" tabindex="-1"></a>It is easy to rely on clustering measures to assess the quality of clustering however this should be done with care as choosing between models may come down to other decisions such as how clusters are formed.</span>
<span id="cb124-681"><a href="#cb124-681" aria-hidden="true" tabindex="-1"></a>By example, consider data generated by <span class="in">`r ref("mlbench::mlbench.spirals")`</span>, which results in two individual lines that spiral around each other (@fig-beyond-clust-spirals).</span>
<span id="cb124-682"><a href="#cb124-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-683"><a href="#cb124-683" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-034}</span></span>
<span id="cb124-684"><a href="#cb124-684" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-spirals</span></span>
<span id="cb124-685"><a href="#cb124-685" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Distribution of `spirals` data.</span></span>
<span id="cb124-686"><a href="#cb124-686" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Grid of four plots. Top-left: line increasing from (-1,0.1) to (0,0.5) then decreasing to (1,0.1). Top-right: text that says 'Corr: -0.145'. Bottom-left: two lines of dots that are in tight, non-overlapping spirals around each other. Bottom-right: same shape as top-left."</span></span>
<span id="cb124-687"><a href="#cb124-687" aria-hidden="true" tabindex="-1"></a>spirals <span class="ot">=</span> mlbench<span class="sc">::</span><span class="fu">mlbench.spirals</span>(<span class="at">n =</span> <span class="dv">300</span>, <span class="at">sd =</span> <span class="fl">0.01</span>)</span>
<span id="cb124-688"><a href="#cb124-688" aria-hidden="true" tabindex="-1"></a>tsk_spirals <span class="ot">=</span> <span class="fu">as_task_clust</span>(<span class="fu">as.data.frame</span>(spirals<span class="sc">$</span>x))</span>
<span id="cb124-689"><a href="#cb124-689" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tsk_spirals)</span>
<span id="cb124-690"><a href="#cb124-690" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-691"><a href="#cb124-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-692"><a href="#cb124-692" aria-hidden="true" tabindex="-1"></a>Now let us see what happens when fit two clustering learners on this data:</span>
<span id="cb124-693"><a href="#cb124-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-694"><a href="#cb124-694" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-035}</span></span>
<span id="cb124-695"><a href="#cb124-695" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb124-696"><a href="#cb124-696" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"clust.kmeans"</span>),</span>
<span id="cb124-697"><a href="#cb124-697" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"clust.dbscan"</span>, <span class="at">eps =</span> <span class="fl">0.1</span>)</span>
<span id="cb124-698"><a href="#cb124-698" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb124-699"><a href="#cb124-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-700"><a href="#cb124-700" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_spirals, learners, <span class="fu">rsmp</span>(<span class="st">"insample"</span>)))</span>
<span id="cb124-701"><a href="#cb124-701" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"clust.silhouette"</span>))[, <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">7</span>)]</span>
<span id="cb124-702"><a href="#cb124-702" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-703"><a href="#cb124-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-704"><a href="#cb124-704" aria-hidden="true" tabindex="-1"></a>We can see that K-means clustering gives us a higher average silhouette score and so we might conclude that a K-means learner with two centroids is a better choice than the DBSCAN method.</span>
<span id="cb124-705"><a href="#cb124-705" aria-hidden="true" tabindex="-1"></a>However, now take a look at the cluster assignment plots in @fig-beyond-clust-spirals-pred (<span class="in">`autoplot.PredictionClust`</span> is available but we do not use it here so we can highlight two particular plots).</span>
<span id="cb124-706"><a href="#cb124-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-707"><a href="#cb124-707" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-036, message=FALSE, warning=FALSE}</span></span>
<span id="cb124-708"><a href="#cb124-708" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-spirals-pred</span></span>
<span id="cb124-709"><a href="#cb124-709" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparing estimated clusters from `lrn("clust.kmeans")` and `lrn("clust.dbscan")`. Both create two distinct clusters that are separated in different ways.</span></span>
<span id="cb124-710"><a href="#cb124-710" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Two plots of the same spirals as in the previous plot. Left (K-means): points above the line x=y are purple (cluster 1) and other points are green (cluster 2). Right (DBSCAN): One of the spirals is purple and the other is green."</span></span>
<span id="cb124-711"><a href="#cb124-711" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb124-712"><a href="#cb124-712" aria-hidden="true" tabindex="-1"></a><span class="co"># get K-Means and DBSCAN partitions</span></span>
<span id="cb124-713"><a href="#cb124-713" aria-hidden="true" tabindex="-1"></a>pred_kmeans <span class="ot">=</span> <span class="fu">as.factor</span>(bmr<span class="sc">$</span><span class="fu">resample_result</span>(<span class="dv">1</span>)<span class="sc">$</span><span class="fu">prediction</span>()<span class="sc">$</span>partition)</span>
<span id="cb124-714"><a href="#cb124-714" aria-hidden="true" tabindex="-1"></a>pred_dbscan <span class="ot">=</span> <span class="fu">as.factor</span>(bmr<span class="sc">$</span><span class="fu">resample_result</span>(<span class="dv">2</span>)<span class="sc">$</span><span class="fu">prediction</span>()<span class="sc">$</span>partition)</span>
<span id="cb124-715"><a href="#cb124-715" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb124-716"><a href="#cb124-716" aria-hidden="true" tabindex="-1"></a>df_kmeans <span class="ot">=</span> <span class="fu">cbind</span>(tsk_spirals<span class="sc">$</span><span class="fu">data</span>(), <span class="at">clust =</span> pred_kmeans)</span>
<span id="cb124-717"><a href="#cb124-717" aria-hidden="true" tabindex="-1"></a>df_dbscan <span class="ot">=</span> <span class="fu">cbind</span>(tsk_spirals<span class="sc">$</span><span class="fu">data</span>(), <span class="at">clust =</span> pred_dbscan)</span>
<span id="cb124-718"><a href="#cb124-718" aria-hidden="true" tabindex="-1"></a>map <span class="ot">=</span> <span class="fu">aes</span>(<span class="at">x =</span> V1, <span class="at">y =</span> V2, <span class="at">color =</span> clust)</span>
<span id="cb124-719"><a href="#cb124-719" aria-hidden="true" tabindex="-1"></a>p_kmeans <span class="ot">=</span> <span class="fu">ggplot</span>(df_kmeans, map) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"K-means"</span>)</span>
<span id="cb124-720"><a href="#cb124-720" aria-hidden="true" tabindex="-1"></a>p_dbscan <span class="ot">=</span> <span class="fu">ggplot</span>(df_dbscan, map) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"DBSCAN"</span>)</span>
<span id="cb124-721"><a href="#cb124-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-722"><a href="#cb124-722" aria-hidden="true" tabindex="-1"></a>p_kmeans <span class="sc">+</span> p_dbscan <span class="sc">+</span> <span class="fu">plot_layout</span>(<span class="at">guides =</span> <span class="st">"collect"</span>) <span class="sc">&amp;</span> <span class="fu">geom_point</span>() <span class="sc">&amp;</span></span>
<span id="cb124-723"><a href="#cb124-723" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">&amp;</span> ggplot2<span class="sc">::</span><span class="fu">scale_colour_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>)</span>
<span id="cb124-724"><a href="#cb124-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-725"><a href="#cb124-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-726"><a href="#cb124-726" aria-hidden="true" tabindex="-1"></a>The two learners arrived at two different results to cleanly separate clusters -- the K-means algorithm assigned points that are part of the same line into two different clusters whereas DBSCAN assigned each line to its own cluster.</span>
<span id="cb124-727"><a href="#cb124-727" aria-hidden="true" tabindex="-1"></a>Which one of these approaches is correct?</span>
<span id="cb124-728"><a href="#cb124-728" aria-hidden="true" tabindex="-1"></a>The answer is it depends on your specific task and the goal of cluster analysis.</span>
<span id="cb124-729"><a href="#cb124-729" aria-hidden="true" tabindex="-1"></a>If we had only relied on the silhouette score, then the details of how the clustering was performed would have been masked and we would have been unable to decide which method was appropriate for the task.</span>
<span id="cb124-730"><a href="#cb124-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-731"><a href="#cb124-731" aria-hidden="true" tabindex="-1"></a><span class="fu">#### PCA and Silhouette Plots</span></span>
<span id="cb124-732"><a href="#cb124-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-733"><a href="#cb124-733" aria-hidden="true" tabindex="-1"></a>The two most important plots implemented in <span class="in">`r mlr3viz`</span> to support the evaluation of cluster learners are PCA and silhouette plots.</span>
<span id="cb124-734"><a href="#cb124-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-735"><a href="#cb124-735" aria-hidden="true" tabindex="-1"></a><span class="in">`r index('Principal components analysis')`</span> (PCA) is a commonly used dimension reduction method in ML to reduce the number of variables in a dataset or to visualize the most important 'components', which are linear transformations of the dataset features.</span>
<span id="cb124-736"><a href="#cb124-736" aria-hidden="true" tabindex="-1"></a>Components are considered more important if they have higher variance (and therefore more predictive power).</span>
<span id="cb124-737"><a href="#cb124-737" aria-hidden="true" tabindex="-1"></a>In the context of clustering, by plotting observations against the first two components, and then coloring them by cluster, we could visualize our high-dimensional dataset and we would expect to see observations in distinct groups.</span>
<span id="cb124-738"><a href="#cb124-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-739"><a href="#cb124-739" aria-hidden="true" tabindex="-1"></a>Since our running example only has two features, PCA does not make sense to visualize the data.</span>
<span id="cb124-740"><a href="#cb124-740" aria-hidden="true" tabindex="-1"></a>So we will use a task based on the <span class="in">`USArrests`</span> dataset instead.</span>
<span id="cb124-741"><a href="#cb124-741" aria-hidden="true" tabindex="-1"></a>By plotting the result of PCA (@fig-beyond-clust-usarrests), we see that our model has done a good job of separating observations into two clusters along the first two principal components.</span>
<span id="cb124-742"><a href="#cb124-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-743"><a href="#cb124-743" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-037, message=FALSE, warning=FALSE}</span></span>
<span id="cb124-744"><a href="#cb124-744" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-usarrests</span></span>
<span id="cb124-745"><a href="#cb124-745" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: First two principal components using PCA on `tsk("usarrests")`.</span></span>
<span id="cb124-746"><a href="#cb124-746" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Scatter plot of green (cluster 2) and purple (cluster 1) points. x-axis: PC1 (96.55%) between -0.3 and 0.2. y-axis: PC2 (2.78%) between -0.3 and 0.2. Points are cleanly separated into two clusters by color."</span></span>
<span id="cb124-747"><a href="#cb124-747" aria-hidden="true" tabindex="-1"></a>tsk_usarrests <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"usarrests"</span>)</span>
<span id="cb124-748"><a href="#cb124-748" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"clust.kmeans"</span>)<span class="sc">$</span><span class="fu">train</span>(tsk_usarrests)<span class="sc">$</span></span>
<span id="cb124-749"><a href="#cb124-749" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(tsk_usarrests)</span>
<span id="cb124-750"><a href="#cb124-750" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, tsk_usarrests, <span class="at">type =</span> <span class="st">"pca"</span>)</span>
<span id="cb124-751"><a href="#cb124-751" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-752"><a href="#cb124-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-753"><a href="#cb124-753" aria-hidden="true" tabindex="-1"></a>Silhouette plots visually assess the quality of the estimated clusters by visualizing if observations in a cluster are well-placed both individually and as a group.</span>
<span id="cb124-754"><a href="#cb124-754" aria-hidden="true" tabindex="-1"></a>The plots include a dotted line which visualizes the average silhouette coefficient across all data points and each data point's silhouette value is represented by a bar colored by their assigned cluster.</span>
<span id="cb124-755"><a href="#cb124-755" aria-hidden="true" tabindex="-1"></a>In our particular case, the average silhouette index is <span class="in">`r round(msr("clust.silhouette")$score(prediction, tsk_usarrests), 2)`</span>.</span>
<span id="cb124-756"><a href="#cb124-756" aria-hidden="true" tabindex="-1"></a>If the average silhouette value for a given cluster is below the average silhouette coefficient line then this implies that the cluster is not well defined.</span>
<span id="cb124-757"><a href="#cb124-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-758"><a href="#cb124-758" aria-hidden="true" tabindex="-1"></a>Continuing with our new example, we find (@fig-beyond-clust-sil) that a lot of observations are actually below the average line and close to zero, and therefore the quality of our cluster assignments is not very good, meaning that many observations are likely assigned to the wrong cluster.</span>
<span id="cb124-759"><a href="#cb124-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-760"><a href="#cb124-760" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-038, message=FALSE, warning=FALSE}</span></span>
<span id="cb124-761"><a href="#cb124-761" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-clust-sil</span></span>
<span id="cb124-762"><a href="#cb124-762" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Silhouette plot from predictions made by `lrn("clust.kmeans")` on `tsk("usarrests")`.'</span></span>
<span id="cb124-763"><a href="#cb124-763" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: "Horizontal barplot with 'Silhouette Values' on x-axis between 0 and 1; y-axis is 'Observations' between 0 and 50. Observations between 0-20 are all colored purple (cluster 1) and observations between 21-50 are colored green (cluster 2). A dashed vertical line passes through x=0.59. The majority of bars finish before this line."</span></span>
<span id="cb124-764"><a href="#cb124-764" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(prediction, tsk_usarrests, <span class="at">type =</span> <span class="st">"sil"</span>)</span>
<span id="cb124-765"><a href="#cb124-765" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-766"><a href="#cb124-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-767"><a href="#cb124-767" aria-hidden="true" tabindex="-1"></a><span class="fu">### Putting It All Together {#sec-cluster-all}</span></span>
<span id="cb124-768"><a href="#cb124-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-769"><a href="#cb124-769" aria-hidden="true" tabindex="-1"></a>Finally, we conduct a small benchmark study using <span class="in">`tsk("usarrests")`</span> and a few integrated cluster learners:</span>
<span id="cb124-770"><a href="#cb124-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-771"><a href="#cb124-771" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-039, message=FALSE, warning=FALSE}</span></span>
<span id="cb124-772"><a href="#cb124-772" aria-hidden="true" tabindex="-1"></a>tsk_usarrests <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">"usarrests"</span>)</span>
<span id="cb124-773"><a href="#cb124-773" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb124-774"><a href="#cb124-774" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"clust.featureless"</span>),</span>
<span id="cb124-775"><a href="#cb124-775" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"clust.kmeans"</span>, <span class="at">centers =</span> <span class="dv">4</span>L),</span>
<span id="cb124-776"><a href="#cb124-776" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">"clust.cmeans"</span>, <span class="at">centers =</span> <span class="dv">3</span>L)</span>
<span id="cb124-777"><a href="#cb124-777" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb124-778"><a href="#cb124-778" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">list</span>(<span class="fu">msr</span>(<span class="st">"clust.wss"</span>), <span class="fu">msr</span>(<span class="st">"clust.silhouette"</span>))</span>
<span id="cb124-779"><a href="#cb124-779" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(<span class="fu">benchmark_grid</span>(tsk_usarrests, learners,</span>
<span id="cb124-780"><a href="#cb124-780" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rsmp</span>(<span class="st">"insample"</span>)))</span>
<span id="cb124-781"><a href="#cb124-781" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(measures)[, <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">8</span>)]</span>
<span id="cb124-782"><a href="#cb124-782" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-783"><a href="#cb124-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-784"><a href="#cb124-784" aria-hidden="true" tabindex="-1"></a>The C-means and K-means algorithms are both considerably better than the featureless baseline but further analysis (and visualizations) would be required to decide which of those two is suitable for our needs.</span>
<span id="cb124-785"><a href="#cb124-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-786"><a href="#cb124-786" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spatial Analysis {#sec-spatiotemporal}</span></span>
<span id="cb124-787"><a href="#cb124-787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-788"><a href="#cb124-788" aria-hidden="true" tabindex="-1"></a>The final task we will discuss in this book is <span class="in">`r index("spatial analysis")`</span>.</span>
<span id="cb124-789"><a href="#cb124-789" aria-hidden="true" tabindex="-1"></a>Spatial analysis can be a subset of any other machine learning task (e.g., regression or classification) and is defined by the presence of spatial information in a dataset, usually stored as coordinates that are often named "x" and "y" or "lat" and "lon" (for 'latitude' and 'longitude' respectively.)</span>
<span id="cb124-790"><a href="#cb124-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-791"><a href="#cb124-791" aria-hidden="true" tabindex="-1"></a>Spatial analysis is its own task as spatial data must be handled carefully due to the complexity of 'autocorrelation'.</span>
<span id="cb124-792"><a href="#cb124-792" aria-hidden="true" tabindex="-1"></a>Where <span class="in">`r index("correlation")`</span> is defined as a statistical association *between two* variables, `r index("autocorrelation", aside = TRUE)` is a statistical association *within one* variable.</span>
<span id="cb124-793"><a href="#cb124-793" aria-hidden="true" tabindex="-1"></a>In ML terms, in a dataset with features and observations, correlation occurs when two or more features are statistically associated in some way, whereas autocorrelation occurs when two or more observations are statistically associated across one feature.</span>
<span id="cb124-794"><a href="#cb124-794" aria-hidden="true" tabindex="-1"></a>Autocorrelation, therefore, violates one of the fundamental assumptions of ML that all observations in a dataset are independent, which results in lower confidence about the quality of a trained machine learning model and the resulting performance estimates <span class="co">[</span><span class="ot">@hastie2001</span><span class="co">]</span>.</span>
<span id="cb124-795"><a href="#cb124-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-796"><a href="#cb124-796" aria-hidden="true" tabindex="-1"></a>Autocorrelation is present in spatial data as there is implicit information encoded in coordinates, such as whether two observations (e.g., cities, countries, continents) are close together or far apart.</span>
<span id="cb124-797"><a href="#cb124-797" aria-hidden="true" tabindex="-1"></a>By example, let us imagine we are predicting the number of cases of a disease two months after an outbreak in Germany (@fig-autocorrelation).</span>
<span id="cb124-798"><a href="#cb124-798" aria-hidden="true" tabindex="-1"></a>Outbreaks radiate outwards from an epicenter and therefore countries closer to Germany will have higher numbers of cases and countries further away will have lower numbers (@fig-autocorrelation, bottom).</span>
<span id="cb124-799"><a href="#cb124-799" aria-hidden="true" tabindex="-1"></a>Thus, looking at the data spatially shows clear signs of autocorrelation across nearby observations.</span>
<span id="cb124-800"><a href="#cb124-800" aria-hidden="true" tabindex="-1"></a>Note in this example the autocorrelation is radial but in practice, this will not always be the case.</span>
<span id="cb124-801"><a href="#cb124-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-802"><a href="#cb124-802" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-040, warning=FALSE, echo=FALSE, message=FALSE, out.width = "60%", out.height = "60%", fig.height = 5}</span></span>
<span id="cb124-803"><a href="#cb124-803" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-autocorrelation</span></span>
<span id="cb124-804"><a href="#cb124-804" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Heatmaps where darker countries indicate higher number of cases and lighter countries indicate lower number of cases of imaginary Disease X with epicenter in Germany. The top map imagines a world in which there is no spatial autocorrelation and the number of cases of a disease is randomly distributed. The bottom map shows a more accurate world in which the number of cases radiate outwards from the epicenter (Germany).</span></span>
<span id="cb124-805"><a href="#cb124-805" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Image shows two separate maps of Europe. Top map has a random distribution of colors from white to dark gray. Bottom map shows darkest color (dark gray) at Germany with increasing lightness as the countries are increasingly further away.</span></span>
<span id="cb124-806"><a href="#cb124-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-807"><a href="#cb124-807" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb124-808"><a href="#cb124-808" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb124-809"><a href="#cb124-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-810"><a href="#cb124-810" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">map_data</span>(<span class="st">"world"</span>)</span>
<span id="cb124-811"><a href="#cb124-811" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> m[m<span class="sc">$</span>region <span class="sc">==</span> <span class="st">"Germany"</span>, ]</span>
<span id="cb124-812"><a href="#cb124-812" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">mean</span>(m<span class="sc">$</span>lon)</span>
<span id="cb124-813"><a href="#cb124-813" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">mean</span>(m<span class="sc">$</span>lat)</span>
<span id="cb124-814"><a href="#cb124-814" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> <span class="fu">map_data</span>(<span class="st">"world"</span>)</span>
<span id="cb124-815"><a href="#cb124-815" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> m <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(long <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">15</span>, long <span class="sc">&lt;</span> <span class="dv">40</span>, lat <span class="sc">&gt;</span> <span class="dv">36</span>, lat <span class="sc">&lt;</span>  <span class="dv">60</span>)</span>
<span id="cb124-816"><a href="#cb124-816" aria-hidden="true" tabindex="-1"></a>m<span class="sc">$</span>dist <span class="ot">=</span> (<span class="sc">-</span><span class="fu">sqrt</span>((m<span class="sc">$</span>lon <span class="sc">-</span> x1)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> (m<span class="sc">$</span>lat <span class="sc">-</span> x2)<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">*</span> <span class="fl">10e5</span></span>
<span id="cb124-817"><a href="#cb124-817" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">min</span>(m<span class="sc">$</span>dist) <span class="sc">&lt;</span> <span class="dv">0</span>) {</span>
<span id="cb124-818"><a href="#cb124-818" aria-hidden="true" tabindex="-1"></a>  m<span class="sc">$</span>dist <span class="ot">=</span> m<span class="sc">$</span>dist <span class="sc">-</span> <span class="fu">min</span>(m<span class="sc">$</span>dist)</span>
<span id="cb124-819"><a href="#cb124-819" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb124-820"><a href="#cb124-820" aria-hidden="true" tabindex="-1"></a>m<span class="sc">$</span>rand <span class="ot">=</span> <span class="fu">runif</span>(<span class="fu">nrow</span>(m), <span class="fu">min</span>(m<span class="sc">$</span>dist), <span class="fu">max</span>(m<span class="sc">$</span>dist))</span>
<span id="cb124-821"><a href="#cb124-821" aria-hidden="true" tabindex="-1"></a>cou <span class="ot">=</span> m <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(region) <span class="sc">%&gt;%</span> <span class="fu">summarize</span>(<span class="at">long =</span> <span class="fu">mean</span>(long), <span class="at">lat =</span> <span class="fu">mean</span>(lat)) <span class="sc">%&gt;%</span> <span class="fu">filter</span>(region <span class="sc">==</span> <span class="st">"Germany"</span>)</span>
<span id="cb124-822"><a href="#cb124-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-823"><a href="#cb124-823" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> <span class="fu">ggplot</span>(<span class="at">data =</span> m) <span class="sc">+</span></span>
<span id="cb124-824"><a href="#cb124-824" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient2</span>(<span class="at">low =</span> <span class="st">"white"</span>, <span class="at">mid =</span> <span class="st">"gray"</span>, <span class="at">high =</span> <span class="st">"black"</span>, <span class="at">midpoint =</span> <span class="fu">mean</span>(m<span class="sc">$</span>dist)) <span class="sc">+</span></span>
<span id="cb124-825"><a href="#cb124-825" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb124-826"><a href="#cb124-826" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">25</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">37</span>, <span class="dv">58</span>)</span>
<span id="cb124-827"><a href="#cb124-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-828"><a href="#cb124-828" aria-hidden="true" tabindex="-1"></a>t <span class="ot">=</span> <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> region, <span class="at">x =</span> long, <span class="at">y =</span> lat), <span class="at">data =</span> cou, <span class="at">size =</span> <span class="fl">2.5</span>)</span>
<span id="cb124-829"><a href="#cb124-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-830"><a href="#cb124-830" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">=</span> p <span class="sc">+</span> <span class="fu">geom_map</span>(<span class="at">map =</span> m, <span class="fu">aes</span>(long, lat, <span class="at">map_id =</span> region, <span class="at">fill =</span> rand), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">lwd =</span> <span class="fl">0.6</span>) <span class="sc">+</span> t <span class="sc">+</span></span>
<span id="cb124-831"><a href="#cb124-831" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"n"</span>)</span>
<span id="cb124-832"><a href="#cb124-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-833"><a href="#cb124-833" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">=</span> p <span class="sc">+</span> <span class="fu">geom_map</span>(<span class="at">map =</span> m, <span class="fu">aes</span>(long, lat, <span class="at">map_id =</span> region, <span class="at">fill =</span> dist), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">lwd =</span> <span class="fl">0.6</span>) <span class="sc">+</span> t <span class="sc">+</span></span>
<span id="cb124-834"><a href="#cb124-834" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">fill =</span> <span class="st">"Cases"</span>)</span>
<span id="cb124-835"><a href="#cb124-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-836"><a href="#cb124-836" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">/</span> p2 <span class="sc">&amp;</span> patchwork<span class="sc">::</span><span class="fu">plot_layout</span>(<span class="at">guides =</span> <span class="st">"collect"</span>)</span>
<span id="cb124-837"><a href="#cb124-837" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-838"><a href="#cb124-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-839"><a href="#cb124-839" aria-hidden="true" tabindex="-1"></a>Unlike other tasks we have looked at in this chapter, there is no underlying difference between the implemented learners or measures.</span>
<span id="cb124-840"><a href="#cb124-840" aria-hidden="true" tabindex="-1"></a>Instead, we provide additional resampling methods in <span class="in">`r mlr3spatiotempcv`</span> to account for the similarity in the train and test sets during resampling that originates from spatiotemporal autocorrelation.</span>
<span id="cb124-841"><a href="#cb124-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-842"><a href="#cb124-842" aria-hidden="true" tabindex="-1"></a>Throughout this section we will use the <span class="in">`r ref("mlr3spatiotempcv::ecuador")`</span> dataset and task as a working example.</span>
<span id="cb124-843"><a href="#cb124-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-844"><a href="#cb124-844" aria-hidden="true" tabindex="-1"></a><span class="fu">### TaskClassifST and TaskRegrST</span></span>
<span id="cb124-845"><a href="#cb124-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-846"><a href="#cb124-846" aria-hidden="true" tabindex="-1"></a>To make use of spatial resampling methods, we have implemented two extensions of <span class="in">`r ref("TaskClassif")`</span> and <span class="in">`r ref("TaskRegr")`</span> to accommodate spatial data, <span class="in">`r ref("TaskClassifST")`</span> and <span class="in">`r ref("TaskRegrST")`</span> respectively.</span>
<span id="cb124-847"><a href="#cb124-847" aria-hidden="true" tabindex="-1"></a>Below we only show classification examples but regression follows trivially.</span>
<span id="cb124-848"><a href="#cb124-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-849"><a href="#cb124-849" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-041, message=FALSE, warning=FALSE}</span></span>
<span id="cb124-850"><a href="#cb124-850" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3spatial)</span>
<span id="cb124-851"><a href="#cb124-851" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3spatiotempcv)</span>
<span id="cb124-852"><a href="#cb124-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-853"><a href="#cb124-853" aria-hidden="true" tabindex="-1"></a><span class="co"># create task from `data.frame`</span></span>
<span id="cb124-854"><a href="#cb124-854" aria-hidden="true" tabindex="-1"></a>tsk_ecuador <span class="ot">=</span> <span class="fu">as_task_classif_st</span>(ecuador, <span class="at">id =</span> <span class="st">"ecuador_task"</span>,</span>
<span id="cb124-855"><a href="#cb124-855" aria-hidden="true" tabindex="-1"></a>  <span class="at">target =</span> <span class="st">"slides"</span>, <span class="at">positive =</span> <span class="st">"TRUE"</span>,</span>
<span id="cb124-856"><a href="#cb124-856" aria-hidden="true" tabindex="-1"></a>  <span class="at">coordinate_names =</span> <span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"y"</span>), <span class="at">crs =</span> <span class="st">"32717"</span>)</span>
<span id="cb124-857"><a href="#cb124-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-858"><a href="#cb124-858" aria-hidden="true" tabindex="-1"></a><span class="co"># or create task from 'sf' object</span></span>
<span id="cb124-859"><a href="#cb124-859" aria-hidden="true" tabindex="-1"></a>data_sf <span class="ot">=</span> sf<span class="sc">::</span><span class="fu">st_as_sf</span>(ecuador, <span class="at">coords =</span> <span class="fu">c</span>(<span class="st">"x"</span>, <span class="st">"y"</span>), <span class="at">crs =</span> <span class="st">"32717"</span>)</span>
<span id="cb124-860"><a href="#cb124-860" aria-hidden="true" tabindex="-1"></a>tsk_ecuador <span class="ot">=</span> <span class="fu">as_task_classif_st</span>(data_sf, <span class="at">target =</span> <span class="st">"slides"</span>,</span>
<span id="cb124-861"><a href="#cb124-861" aria-hidden="true" tabindex="-1"></a>  <span class="at">positive =</span> <span class="st">"TRUE"</span>)</span>
<span id="cb124-862"><a href="#cb124-862" aria-hidden="true" tabindex="-1"></a>tsk_ecuador</span>
<span id="cb124-863"><a href="#cb124-863" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-864"><a href="#cb124-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-865"><a href="#cb124-865" aria-hidden="true" tabindex="-1"></a>Once a task is created, you can train and predict as normal.</span>
<span id="cb124-866"><a href="#cb124-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-867"><a href="#cb124-867" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-042}</span></span>
<span id="cb124-868"><a href="#cb124-868" aria-hidden="true" tabindex="-1"></a><span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>)<span class="sc">$</span><span class="fu">train</span>(tsk_ecuador)<span class="sc">$</span><span class="fu">predict</span>(tsk_ecuador)</span>
<span id="cb124-869"><a href="#cb124-869" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-870"><a href="#cb124-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-871"><a href="#cb124-871" aria-hidden="true" tabindex="-1"></a>However as discussed above, it is best to use the specialized resampling methods to achieve bias-reduced estimates of model performance.</span>
<span id="cb124-872"><a href="#cb124-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-873"><a href="#cb124-873" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spatiotemporal Cross-Validation {#spatiotemp-cv}</span></span>
<span id="cb124-874"><a href="#cb124-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-875"><a href="#cb124-875" aria-hidden="true" tabindex="-1"></a>Before we look at the spatial resampling methods implemented in <span class="in">`mlr3spatiotempcv`</span> we will first show what can go wrong if non-spatial resampling methods are used for spatial data.</span>
<span id="cb124-876"><a href="#cb124-876" aria-hidden="true" tabindex="-1"></a>Below we benchmark a decision tree on <span class="in">`tsk("ecuador")`</span> using two different repeated cross-validation resampling methods, the first ("NSpCV" (non-spatial cross-validation)) is a non-spatial resampling method from <span class="in">`mlr3`</span>, the second ("SpCV" (spatial cross-validation)) is from <span class="in">`mlr3spatiotempcv`</span> and is optimized for spatial data.</span>
<span id="cb124-877"><a href="#cb124-877" aria-hidden="true" tabindex="-1"></a>The example highlights how "NSpCV" makes it appear as if the decision tree is performing better than it is with considerably higher estimated performance, however, this is an overconfident prediction due to the autocorrelation in the data.</span>
<span id="cb124-878"><a href="#cb124-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-879"><a href="#cb124-879" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-043, warning=FALSE,message=FALSE}</span></span>
<span id="cb124-880"><a href="#cb124-880" aria-hidden="true" tabindex="-1"></a>lrn_rpart <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.rpart"</span>, <span class="at">predict_type =</span> <span class="st">"prob"</span>)</span>
<span id="cb124-881"><a href="#cb124-881" aria-hidden="true" tabindex="-1"></a>rsmp_nsp <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"repeated_cv"</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">repeats =</span> <span class="dv">2</span>, <span class="at">id =</span> <span class="st">"NSpCV"</span>)</span>
<span id="cb124-882"><a href="#cb124-882" aria-hidden="true" tabindex="-1"></a>rsmp_sp <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"repeated_spcv_coords"</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">repeats =</span> <span class="dv">2</span>,</span>
<span id="cb124-883"><a href="#cb124-883" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="st">"SpCV"</span>)</span>
<span id="cb124-884"><a href="#cb124-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-885"><a href="#cb124-885" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(tsk_ecuador, lrn_rpart, <span class="fu">c</span>(rsmp_nsp, rsmp_sp))</span>
<span id="cb124-886"><a href="#cb124-886" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb124-887"><a href="#cb124-887" aria-hidden="true" tabindex="-1"></a>bmr<span class="sc">$</span><span class="fu">aggregate</span>(<span class="fu">msr</span>(<span class="st">"classif.acc"</span>))[, <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">7</span>)]</span>
<span id="cb124-888"><a href="#cb124-888" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-889"><a href="#cb124-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-890"><a href="#cb124-890" aria-hidden="true" tabindex="-1"></a>In the above example, applying non-spatial resampling results in train and test sets that are very similar due to the underlying spatial autocorrelation.</span>
<span id="cb124-891"><a href="#cb124-891" aria-hidden="true" tabindex="-1"></a>Hence there is little difference from testing a model on the same data it was trained on, which should be avoided for an honest performance result (see @sec-basics).</span>
<span id="cb124-892"><a href="#cb124-892" aria-hidden="true" tabindex="-1"></a>In contrast, the spatial method has accommodated autocorrelation and the test data is less correlated (though some association will remain) with the training data.</span>
<span id="cb124-893"><a href="#cb124-893" aria-hidden="true" tabindex="-1"></a>Visually this can be seen using <span class="in">`r ref("mlr3spatiotempcv::autoplot()")`</span> methods.</span>
<span id="cb124-894"><a href="#cb124-894" aria-hidden="true" tabindex="-1"></a>In @fig-sprsmp we visualize how the task is partitioned according to the spatial resampling method (@fig-sprsmp, left) and non-spatial resampling method (@fig-sprsmp, right).</span>
<span id="cb124-895"><a href="#cb124-895" aria-hidden="true" tabindex="-1"></a>There is a clear separation in space for the respective partitions when using the spatial resampling whereas the train and test splits overlap a lot (and are therefore more correlated) using the non-spatial method.</span>
<span id="cb124-896"><a href="#cb124-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-897"><a href="#cb124-897" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-044}</span></span>
<span id="cb124-898"><a href="#cb124-898" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Scatterplots show separation of train (blue) and test (orange) data for the first fold of the first repetition of the cross-validation. Left is spatial resampling where train and test data are clearly separated. Right is non-spatial resampling where there is overlap in train and test data.</span></span>
<span id="cb124-899"><a href="#cb124-899" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Two scatter plots with points in blue (training data) and orange (test data). Left plot (Spatial Resampling) shows a clean separation between orange and blue points. Right plot (Non-spatial Resampling) shows blue and orange dots randomly scattered among each other.</span></span>
<span id="cb124-900"><a href="#cb124-900" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-sprsmp</span></span>
<span id="cb124-901"><a href="#cb124-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-902"><a href="#cb124-902" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb124-903"><a href="#cb124-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-904"><a href="#cb124-904" aria-hidden="true" tabindex="-1"></a>(<span class="fu">autoplot</span>(rsmp_sp, tsk_ecuador, <span class="at">fold_id =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb124-905"><a href="#cb124-905" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Spatial Resampling"</span>) <span class="sc">+</span></span>
<span id="cb124-906"><a href="#cb124-906" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(rsmp_nsp, tsk_ecuador, <span class="at">fold_id =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb124-907"><a href="#cb124-907" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Non-spatial Resampling"</span>)) <span class="sc">+</span></span>
<span id="cb124-908"><a href="#cb124-908" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_layout</span>(<span class="at">guides =</span> <span class="st">"collect"</span>) <span class="sc">&amp;</span></span>
<span id="cb124-909"><a href="#cb124-909" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">&amp;</span></span>
<span id="cb124-910"><a href="#cb124-910" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">4</span>), <span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb124-911"><a href="#cb124-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-912"><a href="#cb124-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-913"><a href="#cb124-913" aria-hidden="true" tabindex="-1"></a>Now we have seen why spatial resampling matters we can take a look at what methods are available in <span class="in">`mlr3spatiotempcv`</span>.</span>
<span id="cb124-914"><a href="#cb124-914" aria-hidden="true" tabindex="-1"></a>The resampling methods we have added can be categorized into:</span>
<span id="cb124-915"><a href="#cb124-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-916"><a href="#cb124-916" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Blocking -- Create rectangular blocks in 2D or 3D space</span>
<span id="cb124-917"><a href="#cb124-917" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Buffering -- Create buffering zones to remove observations between train and test sets</span>
<span id="cb124-918"><a href="#cb124-918" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Spatiotemporal clustering -- Clusters based on coordinates (and/or time points)</span>
<span id="cb124-919"><a href="#cb124-919" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Feature space clustering -- Clusters based on feature space and not necessarily spatiotemporal</span>
<span id="cb124-920"><a href="#cb124-920" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Custom (partitioning) -- Grouped by factor variables</span>
<span id="cb124-921"><a href="#cb124-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-922"><a href="#cb124-922" aria-hidden="true" tabindex="-1"></a>The choice of method may depend on specific characteristics of the dataset and there is no easy rule to pick one method over another, full details of different methods can be found in @Schratz2021 -- the paper deliberately avoids recommending one method over another as the 'optimal' choice is highly dependent on the predictive task, autocorrelation in the data, and the spatial structure of the sampling design.</span>
<span id="cb124-923"><a href="#cb124-923" aria-hidden="true" tabindex="-1"></a>The documentation for each of the implemented methods includes details of each method as well as references to original publications.</span>
<span id="cb124-924"><a href="#cb124-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-925"><a href="#cb124-925" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb124-926"><a href="#cb124-926" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spatio*temporal* Resampling</span></span>
<span id="cb124-927"><a href="#cb124-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-928"><a href="#cb124-928" aria-hidden="true" tabindex="-1"></a>We have focused on spatial analysis but referred to "spatiotemporal" and "spatiotemp".</span>
<span id="cb124-929"><a href="#cb124-929" aria-hidden="true" tabindex="-1"></a>The spatial-only resampling methods discussed in this section can be extended to temporal analysis (or spatial and temporal analysis combined) by setting the <span class="in">`"time"`</span> <span class="in">`col_role`</span> in the task (@sec-row-col-roles) -- this is an advanced topic that may be added in future editions of this book.</span>
<span id="cb124-930"><a href="#cb124-930" aria-hidden="true" tabindex="-1"></a>See the <span class="in">`mlr3spatiotempcv`</span> visualization vignette at <span class="in">`r link("https://mlr3spatiotempcv.mlr-org.com/articles/spatiotemp-viz.html")`</span> for specific details about 3D spatiotemporal visualization.</span>
<span id="cb124-931"><a href="#cb124-931" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb124-932"><a href="#cb124-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-933"><a href="#cb124-933" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spatial Prediction {#sec-spatial-prediction}</span></span>
<span id="cb124-934"><a href="#cb124-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-935"><a href="#cb124-935" aria-hidden="true" tabindex="-1"></a>Until now we have looked at resampling to accommodate spatiotemporal *features*, but what if you want to make spatiotemporal *predictions*?</span>
<span id="cb124-936"><a href="#cb124-936" aria-hidden="true" tabindex="-1"></a>In this case, the goal is to make classification or regression predictions at the pixel level, i.e., for an area, defined by the geometric resolution, of a raster image.</span>
<span id="cb124-937"><a href="#cb124-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-938"><a href="#cb124-938" aria-hidden="true" tabindex="-1"></a>To enable these predictions we have created a new function, <span class="in">`r ref("mlr3spatial::predict_spatial()")`</span>, to allow spatial predictions using any of the following spatial data classes:</span>
<span id="cb124-939"><a href="#cb124-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-940"><a href="#cb124-940" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`stars`</span> (from package <span class="in">`r ref_pkg("stars")`</span>)</span>
<span id="cb124-941"><a href="#cb124-941" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`SpatRaster`</span> (from package <span class="in">`r ref_pkg("terra")`</span>)</span>
<span id="cb124-942"><a href="#cb124-942" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`RasterLayer`</span> (from package <span class="in">`r ref_pkg("raster")`</span>)</span>
<span id="cb124-943"><a href="#cb124-943" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`RasterStack`</span> (from package <span class="in">`r ref_pkg("raster")`</span>)</span>
<span id="cb124-944"><a href="#cb124-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-945"><a href="#cb124-945" aria-hidden="true" tabindex="-1"></a>In the example below we load the <span class="in">`leipzig_points`</span> dataset for training and coerce this to a spatiotemporal task with <span class="in">`r ref("as_task_classif_st")`</span>, and we load the <span class="in">`leipzig_raster`</span> raster.</span>
<span id="cb124-946"><a href="#cb124-946" aria-hidden="true" tabindex="-1"></a>Both files are included as example data in <span class="in">`r mlr3spatial`</span>.</span>
<span id="cb124-947"><a href="#cb124-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-948"><a href="#cb124-948" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-045, warning=FALSE, message=FALSE}</span></span>
<span id="cb124-949"><a href="#cb124-949" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: false</span></span>
<span id="cb124-950"><a href="#cb124-950" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3spatial)</span>
<span id="cb124-951"><a href="#cb124-951" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb124-952"><a href="#cb124-952" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(terra, <span class="at">exclude =</span> <span class="st">"resample"</span>)</span>
<span id="cb124-953"><a href="#cb124-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-954"><a href="#cb124-954" aria-hidden="true" tabindex="-1"></a><span class="co"># load sample points</span></span>
<span id="cb124-955"><a href="#cb124-955" aria-hidden="true" tabindex="-1"></a>leipzig_vector <span class="ot">=</span> sf<span class="sc">::</span><span class="fu">read_sf</span>(<span class="fu">system.file</span>(<span class="st">"extdata"</span>,</span>
<span id="cb124-956"><a href="#cb124-956" aria-hidden="true" tabindex="-1"></a>  <span class="st">"leipzig_points.gpkg"</span>, <span class="at">package =</span> <span class="st">"mlr3spatial"</span>),</span>
<span id="cb124-957"><a href="#cb124-957" aria-hidden="true" tabindex="-1"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span>)</span>
<span id="cb124-958"><a href="#cb124-958" aria-hidden="true" tabindex="-1"></a><span class="co"># create training data</span></span>
<span id="cb124-959"><a href="#cb124-959" aria-hidden="true" tabindex="-1"></a>tsk_leipzig <span class="ot">=</span> <span class="fu">as_task_classif_st</span>(leipzig_vector, <span class="at">target =</span> <span class="st">"land_cover"</span>)</span>
<span id="cb124-960"><a href="#cb124-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-961"><a href="#cb124-961" aria-hidden="true" tabindex="-1"></a><span class="co"># load raster image</span></span>
<span id="cb124-962"><a href="#cb124-962" aria-hidden="true" tabindex="-1"></a>leipzig_raster <span class="ot">=</span> terra<span class="sc">::</span><span class="fu">rast</span>(<span class="fu">system.file</span>(<span class="st">"extdata"</span>, <span class="st">"leipzig_raster.tif"</span>,</span>
<span id="cb124-963"><a href="#cb124-963" aria-hidden="true" tabindex="-1"></a>  <span class="at">package =</span> <span class="st">"mlr3spatial"</span>))</span>
<span id="cb124-964"><a href="#cb124-964" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-965"><a href="#cb124-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-966"><a href="#cb124-966" aria-hidden="true" tabindex="-1"></a>Now we can continue as normal to train and predict with a classification learner, in this case, a random forest.</span>
<span id="cb124-967"><a href="#cb124-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-968"><a href="#cb124-968" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-046, cache.lazy=FALSE, cache=FALSE}</span></span>
<span id="cb124-969"><a href="#cb124-969" aria-hidden="true" tabindex="-1"></a>lrn_ranger <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"classif.ranger"</span>)<span class="sc">$</span><span class="fu">train</span>(tsk_leipzig)</span>
<span id="cb124-970"><a href="#cb124-970" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">=</span> <span class="fu">predict_spatial</span>(leipzig_raster, lrn_ranger,</span>
<span id="cb124-971"><a href="#cb124-971" aria-hidden="true" tabindex="-1"></a>  <span class="at">format =</span> <span class="st">"terra"</span>)</span>
<span id="cb124-972"><a href="#cb124-972" aria-hidden="true" tabindex="-1"></a>prediction</span>
<span id="cb124-973"><a href="#cb124-973" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-974"><a href="#cb124-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-975"><a href="#cb124-975" aria-hidden="true" tabindex="-1"></a>In this example, we specified the creation of a <span class="in">`terra`</span> object, which can be visualized with in-built plotting methods.</span>
<span id="cb124-976"><a href="#cb124-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-977"><a href="#cb124-977" aria-hidden="true" tabindex="-1"></a><span class="in">```{r beyond_regression_and_classification-047, message = FALSE, cache.lazy=FALSE, cache=FALSE, out.width = "50%", out.height = "50%"}</span></span>
<span id="cb124-978"><a href="#cb124-978" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Spatial predictions for forest (purple), pasture (blue), urban (green), and water (yellow) categories.</span></span>
<span id="cb124-979"><a href="#cb124-979" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-alt: Very zoomed-in map with x-axis from 732000 to 733000 and 5692500 to 5693500 on y-axis. Different clusters are colored in green, blue, purple and yellow.</span></span>
<span id="cb124-980"><a href="#cb124-980" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-beyond-raster</span></span>
<span id="cb124-981"><a href="#cb124-981" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prediction, <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"#440154FF"</span>, <span class="st">"#443A83FF"</span>, <span class="st">"#31688EFF"</span>,</span>
<span id="cb124-982"><a href="#cb124-982" aria-hidden="true" tabindex="-1"></a>  <span class="st">"#21908CFF"</span>, <span class="st">"#35B779FF"</span>, <span class="st">"#8FD744FF"</span>, <span class="st">"#FDE725FF"</span>))</span>
<span id="cb124-983"><a href="#cb124-983" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-984"><a href="#cb124-984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-985"><a href="#cb124-985" aria-hidden="true" tabindex="-1"></a><span class="fu">## Quantile Regression (+) {#sec-quantile-regression}</span></span>
<span id="cb124-986"><a href="#cb124-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-987"><a href="#cb124-987" aria-hidden="true" tabindex="-1"></a>Regression models typically predict the conditional mean of the target given the input features.</span>
<span id="cb124-988"><a href="#cb124-988" aria-hidden="true" tabindex="-1"></a>Quantile regression allows for the prediction of conditional quantiles, enabling more uncertainty-aware and informative predictions or an approximation of the conditional distribution.</span>
<span id="cb124-989"><a href="#cb124-989" aria-hidden="true" tabindex="-1"></a>Instead of answering "What is the expected outcome given these features?", quantile regression asks, "What is the outcome at a given probability level (e.g., 10th percentile, median, 90th percentile)?".</span>
<span id="cb124-990"><a href="#cb124-990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-991"><a href="#cb124-991" aria-hidden="true" tabindex="-1"></a>This is particularly useful in scenarios where we want to model uncertainty and extremes in data:</span>
<span id="cb124-992"><a href="#cb124-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-993"><a href="#cb124-993" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Constructing prediction intervals, by asking for a lower bound, a central prediction, and an upper bound  (e.g. 0.05, 0.5, or 0.95)</span>
<span id="cb124-994"><a href="#cb124-994" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Identifying extreme values: In applications such as risk analysis, financial modeling, or weather forecasting, we may be particularly interested in predicting the worst-case or best-case outcomes (e.g., the 5th quantile for a stock price drop).</span>
<span id="cb124-995"><a href="#cb124-995" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Handling heteroscedastic data: When the variance of the response variable changes with the input features, quantile regression is usually a more robust solution.</span>
<span id="cb124-996"><a href="#cb124-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-997"><a href="#cb124-997" aria-hidden="true" tabindex="-1"></a>A key concept in estimating quantile regression models is the pinball loss, which generalizes the L1 loss, or mean absolute error (MAE), to optimize for arbitrary quantiles $\tau$.</span>
<span id="cb124-998"><a href="#cb124-998" aria-hidden="true" tabindex="-1"></a>To understand this, we need to recall that the median (i.e. the 0.5-quantile) minimizes the MAE.</span>
<span id="cb124-999"><a href="#cb124-999" aria-hidden="true" tabindex="-1"></a>The pinball loss modifies the L1 loss by introducing an asymmetry that encourages the model to penalize under- or over-prediction more heavily, based on the chosen quantile level.</span>
<span id="cb124-1000"><a href="#cb124-1000" aria-hidden="true" tabindex="-1"></a>For instance, setting $\tau = 0.1$ means overpredictions are nine times more expensive than underpredictions, leading the model to systematically underestimate the target.</span>
<span id="cb124-1001"><a href="#cb124-1001" aria-hidden="true" tabindex="-1"></a>This pushes the model to estimate not the center of the (conditional) distribution, but the selected quantile.</span>
<span id="cb124-1002"><a href="#cb124-1002" aria-hidden="true" tabindex="-1"></a>We can connect this directly to quantiles: If the model is trained to minimize pinball loss for a given quantile $\tau$, then $\tau \%$ of the observed values should be below the predicted value, and $(1 - \tau) \%$ should be above it.</span>
<span id="cb124-1003"><a href="#cb124-1003" aria-hidden="true" tabindex="-1"></a>For example, a model trained with $\tau = 0.1$ will produce predictions such that 10\% of observed values fall below its predictions, making it an estimator of the 10th percentile.</span>
<span id="cb124-1004"><a href="#cb124-1004" aria-hidden="true" tabindex="-1"></a>The pinball loss will reappear as an evaluation metric at the end of this chapter.</span>
<span id="cb124-1005"><a href="#cb124-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1006"><a href="#cb124-1006" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb124-1007"><a href="#cb124-1007" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Values of the pinball loss function for different quantiles.</span></span>
<span id="cb124-1008"><a href="#cb124-1008" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-pinball</span></span>
<span id="cb124-1009"><a href="#cb124-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1010"><a href="#cb124-1010" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb124-1011"><a href="#cb124-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1012"><a href="#cb124-1012" aria-hidden="true" tabindex="-1"></a>pinball_loss <span class="ot">=</span> <span class="cf">function</span>(err, tau) <span class="fu">ifelse</span>(err <span class="sc">&gt;=</span> <span class="dv">0</span>, tau <span class="sc">*</span> err, (tau <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> err)</span>
<span id="cb124-1013"><a href="#cb124-1013" aria-hidden="true" tabindex="-1"></a>res <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb124-1014"><a href="#cb124-1014" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">=</span> <span class="fu">data.table</span>(</span>
<span id="cb124-1015"><a href="#cb124-1015" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">rep</span>(res, <span class="dv">3</span>),</span>
<span id="cb124-1016"><a href="#cb124-1016" aria-hidden="true" tabindex="-1"></a>  <span class="at">tau =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"0.5"</span>, <span class="st">"0.9"</span>, <span class="st">"0.1"</span>), <span class="at">each =</span> <span class="fu">length</span>(res)),</span>
<span id="cb124-1017"><a href="#cb124-1017" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="fu">c</span>(<span class="fu">pinball_loss</span>(res, <span class="fl">0.5</span>), <span class="fu">pinball_loss</span>(res, <span class="fl">0.9</span>), <span class="fu">pinball_loss</span>(res, <span class="fl">0.1</span>))</span>
<span id="cb124-1018"><a href="#cb124-1018" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb124-1019"><a href="#cb124-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1020"><a href="#cb124-1020" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> loss, <span class="at">color =</span> tau)) <span class="sc">+</span></span>
<span id="cb124-1021"><a href="#cb124-1021" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb124-1022"><a href="#cb124-1022" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb124-1023"><a href="#cb124-1023" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="at">by =</span> <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb124-1024"><a href="#cb124-1024" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">6</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">6</span>)) <span class="sc">+</span></span>
<span id="cb124-1025"><a href="#cb124-1025" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>, <span class="at">alpha =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb124-1026"><a href="#cb124-1026" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"pinball loss"</span>, <span class="at">x =</span> <span class="st">"truth - response"</span>, <span class="at">color =</span> <span class="fu">expression</span>(tau)) <span class="sc">+</span></span>
<span id="cb124-1027"><a href="#cb124-1027" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb124-1028"><a href="#cb124-1028" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">6</span>), <span class="at">legend.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">6</span>))</span>
<span id="cb124-1029"><a href="#cb124-1029" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1030"><a href="#cb124-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1031"><a href="#cb124-1031" aria-hidden="true" tabindex="-1"></a>But note: While many ML models based on empirical risk minimization use the pinball loss for estimating quantiles, some model classes might work differently.</span>
<span id="cb124-1032"><a href="#cb124-1032" aria-hidden="true" tabindex="-1"></a>However, since the underlying training procedure of a model is external to <span class="in">`mlr3`</span>, we are more concerned with resampling and evaluating quantile regression models.</span>
<span id="cb124-1033"><a href="#cb124-1033" aria-hidden="true" tabindex="-1"></a>This works in exactly the same manner as for other tasks.</span>
<span id="cb124-1034"><a href="#cb124-1034" aria-hidden="true" tabindex="-1"></a>Because we provide only a brief overview of quantile regression, we recommend @yu_quantile_2003 if you are interested in a methodological introduction to the topic and @koenker_quantile_2005 for a more expansive treatment of quantile regression.</span>
<span id="cb124-1035"><a href="#cb124-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1036"><a href="#cb124-1036" aria-hidden="true" tabindex="-1"></a><span class="fu">### Synthetic data set generation {#sec-data-generation}</span></span>
<span id="cb124-1037"><a href="#cb124-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1038"><a href="#cb124-1038" aria-hidden="true" tabindex="-1"></a>Let us construct a simple synthetic data set to demonstrate how quantile regression works.</span>
<span id="cb124-1039"><a href="#cb124-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1040"><a href="#cb124-1040" aria-hidden="true" tabindex="-1"></a>We generate 10,000 data points where the univariate feature <span class="in">`x`</span> is drawn from a uniform distribution between 1 and 15 and the target <span class="in">`y`</span> follows a non-linear function of <span class="in">`x`</span>.</span>
<span id="cb124-1041"><a href="#cb124-1041" aria-hidden="true" tabindex="-1"></a>To make the problem more interesting, we use heteroscedastic Gaussian noise on the target, i.e. the variance increases as <span class="in">`x`</span> increases.</span>
<span id="cb124-1042"><a href="#cb124-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1045"><a href="#cb124-1045" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb124-1046"><a href="#cb124-1046" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">10000</span></span>
<span id="cb124-1047"><a href="#cb124-1047" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">1</span>, <span class="at">max =</span> <span class="dv">15</span>)</span>
<span id="cb124-1048"><a href="#cb124-1048" aria-hidden="true" tabindex="-1"></a>f <span class="ot">=</span> <span class="cf">function</span>(x) <span class="dv">2</span> <span class="sc">+</span> ((<span class="dv">10</span> <span class="sc">*</span> x <span class="sc">*</span> <span class="fu">cos</span>(x)) <span class="sc">/</span> (x<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb124-1049"><a href="#cb124-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1050"><a href="#cb124-1050" aria-hidden="true" tabindex="-1"></a>variance <span class="ot">=</span> <span class="cf">function</span>(x) <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">sqrt</span>(x)</span>
<span id="cb124-1051"><a href="#cb124-1051" aria-hidden="true" tabindex="-1"></a>noise <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="fu">variance</span>(x)))</span>
<span id="cb124-1052"><a href="#cb124-1052" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">data.table</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">f</span>(x) <span class="sc">+</span> noise)</span>
<span id="cb124-1053"><a href="#cb124-1053" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1054"><a href="#cb124-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1055"><a href="#cb124-1055" aria-hidden="true" tabindex="-1"></a>Let us plot the data to get a better feel for it.</span>
<span id="cb124-1056"><a href="#cb124-1056" aria-hidden="true" tabindex="-1"></a>The points are a random subset of the data (10%).</span>
<span id="cb124-1057"><a href="#cb124-1057" aria-hidden="true" tabindex="-1"></a>The line is the true underlying function $f(x)$, from which we sampled and which we would ideally recover as our estimated posterior median.</span>
<span id="cb124-1058"><a href="#cb124-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1059"><a href="#cb124-1059" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb124-1060"><a href="#cb124-1060" aria-hidden="true" tabindex="-1"></a>true_data <span class="ot">=</span> <span class="fu">data.table</span>(<span class="at">x =</span> x, <span class="at">y =</span> <span class="fu">f</span>(x))</span>
<span id="cb124-1061"><a href="#cb124-1061" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb124-1062"><a href="#cb124-1062" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> data[<span class="fu">sample</span>(.N, <span class="at">size =</span> <span class="fl">0.1</span> <span class="sc">*</span> .N)], <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1063"><a href="#cb124-1063" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb124-1064"><a href="#cb124-1064" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb124-1065"><a href="#cb124-1065" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1066"><a href="#cb124-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1067"><a href="#cb124-1067" aria-hidden="true" tabindex="-1"></a>This plot reveals two essential properties of our data.</span>
<span id="cb124-1068"><a href="#cb124-1068" aria-hidden="true" tabindex="-1"></a>Firstly, $f(x)$ oscillates more for small <span class="in">`x`</span> but becomes smoother for larger values.</span>
<span id="cb124-1069"><a href="#cb124-1069" aria-hidden="true" tabindex="-1"></a>Secondly, we clearly see heteroscedasticity as the variance of <span class="in">`y`</span> increases as <span class="in">`x`</span> grows.</span>
<span id="cb124-1070"><a href="#cb124-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1071"><a href="#cb124-1071" aria-hidden="true" tabindex="-1"></a>Because of the latter, mean-based models will struggle to provide robust predictions, especially for larger values of <span class="in">`x`</span>, as they will be heavily influenced by extreme deviations.</span>
<span id="cb124-1072"><a href="#cb124-1072" aria-hidden="true" tabindex="-1"></a>In contrast, the median (0.5-quantile) provides a more stable estimate, while other quantiles (e.g., 0.05 and 0.95) allow us to estimate uncertainty and extreme outcomes.</span>
<span id="cb124-1073"><a href="#cb124-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1074"><a href="#cb124-1074" aria-hidden="true" tabindex="-1"></a>Now that we have generated our data set, we transform it into a regular regression task and split it into a train and test set.</span>
<span id="cb124-1075"><a href="#cb124-1075" aria-hidden="true" tabindex="-1"></a>We also specify five quantiles to estimate.</span>
<span id="cb124-1076"><a href="#cb124-1076" aria-hidden="true" tabindex="-1"></a>The median, which we will soon set as the intended <span class="in">`response`</span> and four other quantiles to to capture lower and upper dispersion.</span>
<span id="cb124-1077"><a href="#cb124-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1078"><a href="#cb124-1078" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb124-1079"><a href="#cb124-1079" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3verse)</span>
<span id="cb124-1080"><a href="#cb124-1080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1081"><a href="#cb124-1081" aria-hidden="true" tabindex="-1"></a>task <span class="ot">=</span> <span class="fu">as_task_regr</span>(data, <span class="at">target =</span> <span class="st">"y"</span>)</span>
<span id="cb124-1082"><a href="#cb124-1082" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">=</span> <span class="fu">partition</span>(task)</span>
<span id="cb124-1083"><a href="#cb124-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1084"><a href="#cb124-1084" aria-hidden="true" tabindex="-1"></a>qs <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.95</span>)</span>
<span id="cb124-1085"><a href="#cb124-1085" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1086"><a href="#cb124-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1087"><a href="#cb124-1087" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quantile Regression with Multiple Learners {#sec-quantile-regression-models}</span></span>
<span id="cb124-1088"><a href="#cb124-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1089"><a href="#cb124-1089" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Random Regression Forest {#sec-quantile-ranger}</span></span>
<span id="cb124-1090"><a href="#cb124-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1091"><a href="#cb124-1091" aria-hidden="true" tabindex="-1"></a>The first learner we apply is a random regression forest (<span class="in">`lrn("regr.ranger")`</span>), implemented in <span class="in">`r ref_pkg("mlr3learners")`</span>, a tree-based ensemble which can nicely handle complex interactions and non-linear relationships.</span>
<span id="cb124-1092"><a href="#cb124-1092" aria-hidden="true" tabindex="-1"></a>We configure the learner to predict the specified quantiles and mark the median quantile as the dedicated response.</span>
<span id="cb124-1093"><a href="#cb124-1093" aria-hidden="true" tabindex="-1"></a>We then train and predict as usual.</span>
<span id="cb124-1094"><a href="#cb124-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1095"><a href="#cb124-1095" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb124-1096"><a href="#cb124-1096" aria-hidden="true" tabindex="-1"></a>lrn_ranger <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.ranger"</span>, <span class="at">predict_type =</span> <span class="st">"quantiles"</span>,</span>
<span id="cb124-1097"><a href="#cb124-1097" aria-hidden="true" tabindex="-1"></a>                     <span class="at">quantiles =</span> qs, <span class="at">quantile_response =</span> <span class="fl">0.5</span>)</span>
<span id="cb124-1098"><a href="#cb124-1098" aria-hidden="true" tabindex="-1"></a>lrn_ranger<span class="sc">$</span>param_set<span class="sc">$</span><span class="fu">set_values</span>(<span class="at">min.node.size =</span> <span class="dv">10</span>, <span class="at">num.trees =</span> <span class="dv">100</span>, <span class="at">mtry =</span> <span class="dv">1</span>)</span>
<span id="cb124-1099"><a href="#cb124-1099" aria-hidden="true" tabindex="-1"></a>lrn_ranger<span class="sc">$</span><span class="fu">train</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>train)</span>
<span id="cb124-1100"><a href="#cb124-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1101"><a href="#cb124-1101" aria-hidden="true" tabindex="-1"></a>prds_ranger <span class="ot">=</span> lrn_ranger<span class="sc">$</span><span class="fu">predict</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>test)</span>
<span id="cb124-1102"><a href="#cb124-1102" aria-hidden="true" tabindex="-1"></a>prds_ranger</span>
<span id="cb124-1103"><a href="#cb124-1103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1104"><a href="#cb124-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1105"><a href="#cb124-1105" aria-hidden="true" tabindex="-1"></a>The predict object has additional columns for all quantiles.</span>
<span id="cb124-1106"><a href="#cb124-1106" aria-hidden="true" tabindex="-1"></a>We set <span class="in">`$quantile_response = 0.5`</span> which means that <span class="in">`response`</span> is equal to the 0.5-quantile.</span>
<span id="cb124-1107"><a href="#cb124-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1108"><a href="#cb124-1108" aria-hidden="true" tabindex="-1"></a>We now plot the predicted quantiles against the true test data.</span>
<span id="cb124-1109"><a href="#cb124-1109" aria-hidden="true" tabindex="-1"></a>Each colored line represents a different quantile estimate, and the black curve represents the true function.</span>
<span id="cb124-1110"><a href="#cb124-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1111"><a href="#cb124-1111" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb124-1112"><a href="#cb124-1112" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Results of quantile regression with GAM. 90%-prediction interval in green and 50%-prediction interval in blue. The black line is the underlying function.</span></span>
<span id="cb124-1113"><a href="#cb124-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1114"><a href="#cb124-1114" aria-hidden="true" tabindex="-1"></a>data_ranger <span class="ot">=</span> <span class="fu">as.data.table</span>(prds_ranger)</span>
<span id="cb124-1115"><a href="#cb124-1115" aria-hidden="true" tabindex="-1"></a>data_ranger[, x <span class="sc">:</span><span class="er">=</span> task<span class="sc">$</span><span class="fu">data</span>(<span class="at">rows =</span> splits<span class="sc">$</span>test)<span class="sc">$</span>x]</span>
<span id="cb124-1116"><a href="#cb124-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1117"><a href="#cb124-1117" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">=</span> viridis<span class="sc">::</span><span class="fu">viridis</span>(<span class="dv">2</span>, <span class="at">begin =</span> <span class="fl">0.5</span>, <span class="at">end =</span> <span class="fl">0.8</span>)</span>
<span id="cb124-1118"><a href="#cb124-1118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1119"><a href="#cb124-1119" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data_ranger, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb124-1120"><a href="#cb124-1120" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.05</span>), <span class="at">color =</span> colors[[<span class="dv">2</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb124-1121"><a href="#cb124-1121" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.95</span>), <span class="at">color =</span> colors[[<span class="dv">2</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb124-1122"><a href="#cb124-1122" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> q0<span class="fl">.05</span>, <span class="at">ymax =</span> q0<span class="fl">.95</span>), <span class="at">fill =</span> colors[[<span class="dv">2</span>]], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb124-1123"><a href="#cb124-1123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.25</span>), <span class="at">color =</span> colors[[<span class="dv">1</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb124-1124"><a href="#cb124-1124" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.75</span>), <span class="at">color =</span> colors[[<span class="dv">1</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb124-1125"><a href="#cb124-1125" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> q0<span class="fl">.25</span>, <span class="at">ymax =</span> q0<span class="fl">.75</span>), <span class="at">fill =</span> colors[[<span class="dv">1</span>]], <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1126"><a href="#cb124-1126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> truth), <span class="at">alpha =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb124-1127"><a href="#cb124-1127" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span>y), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb124-1128"><a href="#cb124-1128" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">15</span>)) <span class="sc">+</span></span>
<span id="cb124-1129"><a href="#cb124-1129" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">""</span>, <span class="at">x =</span> <span class="st">"x"</span>, <span class="at">y =</span> <span class="st">"y"</span>) <span class="sc">+</span></span>
<span id="cb124-1130"><a href="#cb124-1130" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb124-1131"><a href="#cb124-1131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1132"><a href="#cb124-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1133"><a href="#cb124-1133" aria-hidden="true" tabindex="-1"></a>We can see that the random forest captures the overall trend of the function.</span>
<span id="cb124-1134"><a href="#cb124-1134" aria-hidden="true" tabindex="-1"></a>It provides quantile estimates that increase as <span class="in">`x`</span> increases and handles the non-linearity of our data well due to its ensemble nature.</span>
<span id="cb124-1135"><a href="#cb124-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1136"><a href="#cb124-1136" aria-hidden="true" tabindex="-1"></a>But the predicted quantiles appear overly jagged and spiky, which suggests that the model might be overfitting to the noise in the training data rather than capturing smooth trends.</span>
<span id="cb124-1137"><a href="#cb124-1137" aria-hidden="true" tabindex="-1"></a>The median estimate oscillates around the true function but does not consistently align with it.</span>
<span id="cb124-1138"><a href="#cb124-1138" aria-hidden="true" tabindex="-1"></a>The reason for these limitations lies in how random forests construct quantiles.</span>
<span id="cb124-1139"><a href="#cb124-1139" aria-hidden="true" tabindex="-1"></a>In quantile regression forests, predictions are derived from the empirical distribution of the response values within the terminal nodes of individual trees.</span>
<span id="cb124-1140"><a href="#cb124-1140" aria-hidden="true" tabindex="-1"></a>Each tree partitions the feature space into regions, and all observations that fall into the same region (terminal node) share the same conditional distribution estimate.</span>
<span id="cb124-1141"><a href="#cb124-1141" aria-hidden="true" tabindex="-1"></a>Quantiles are computed based on the sorted values of these observations.</span>
<span id="cb124-1142"><a href="#cb124-1142" aria-hidden="true" tabindex="-1"></a>Because the number of samples in each terminal node is finite, the estimated quantiles are discrete rather than continuous, leading to the characteristic "stair-step" appearance in the predictions.</span>
<span id="cb124-1143"><a href="#cb124-1143" aria-hidden="true" tabindex="-1"></a>If a particular terminal node contains only a small number of observations, the estimated quantiles may shift abruptly between adjacent nodes, creating jagged or spiky predictions.</span>
<span id="cb124-1144"><a href="#cb124-1144" aria-hidden="true" tabindex="-1"></a>Additionally, the aggregation across trees averages over multiple step functions, which can result in piecewise-constant and noisy quantile estimates.</span>
<span id="cb124-1145"><a href="#cb124-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1146"><a href="#cb124-1146" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Smooth Additive Model with PipeOpLearnerQuantiles {#sec-quantile-qgam}</span></span>
<span id="cb124-1147"><a href="#cb124-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1148"><a href="#cb124-1148" aria-hidden="true" tabindex="-1"></a>To address the limitations that we observed with the random regression forest, we will now consider quantile regression with smooth generalized additive models (GAM) as an alternative method.</span>
<span id="cb124-1149"><a href="#cb124-1149" aria-hidden="true" tabindex="-1"></a>This approach allows for smoother estimates and may improve the robustness of quantile predictions.</span>
<span id="cb124-1150"><a href="#cb124-1150" aria-hidden="true" tabindex="-1"></a>Unlike tree-based methods, GAMs construct their prediction function using smooth splines rather than discrete splits.</span>
<span id="cb124-1151"><a href="#cb124-1151" aria-hidden="true" tabindex="-1"></a>This makes them well-suited for handling continuous and structured data -- which here aligns well with our simulation setup, although, in a more realistic scencario, we would not know this.</span>
<span id="cb124-1152"><a href="#cb124-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1153"><a href="#cb124-1153" aria-hidden="true" tabindex="-1"></a>The predictive intervals we obtain from the quantile GAM differ from conventional confidence intervals in GAMs: rather than quantifying uncertainty around the estimated function itself, our quantile estimates enable direct predictive inference.</span>
<span id="cb124-1154"><a href="#cb124-1154" aria-hidden="true" tabindex="-1"></a>This allows us to construct observation-wise prediction intervals.</span>
<span id="cb124-1155"><a href="#cb124-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1156"><a href="#cb124-1156" aria-hidden="true" tabindex="-1"></a>We will begin to demonstrate this using <span class="co">[</span><span class="ot">`lrn("regr.mqgam")`</span><span class="co">](https://mlr3extralearners.mlr-org.com/reference/mlr_learners_regr.mqgam.html)</span> from <span class="in">`r ref_pkg("mlr3extralearners")`</span>.</span>
<span id="cb124-1157"><a href="#cb124-1157" aria-hidden="true" tabindex="-1"></a>As we have done above for the random regression forest, we fit a model using the previously specified quantiles.</span>
<span id="cb124-1158"><a href="#cb124-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1159"><a href="#cb124-1159" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE, warning=FALSE, results='hide'}</span></span>
<span id="cb124-1160"><a href="#cb124-1160" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3extralearners)</span>
<span id="cb124-1161"><a href="#cb124-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1162"><a href="#cb124-1162" aria-hidden="true" tabindex="-1"></a>lrn_mqgam <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.mqgam"</span>, <span class="at">predict_type =</span> <span class="st">"quantiles"</span>,</span>
<span id="cb124-1163"><a href="#cb124-1163" aria-hidden="true" tabindex="-1"></a>                <span class="at">quantiles =</span> qs, <span class="at">quantile_response =</span> <span class="fl">0.5</span>)</span>
<span id="cb124-1164"><a href="#cb124-1164" aria-hidden="true" tabindex="-1"></a>lrn_mqgam<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>form <span class="ot">=</span> y <span class="sc">~</span> <span class="fu">s</span>(x)</span>
<span id="cb124-1165"><a href="#cb124-1165" aria-hidden="true" tabindex="-1"></a>lrn_mqgam<span class="sc">$</span><span class="fu">train</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>train)</span>
<span id="cb124-1166"><a href="#cb124-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1167"><a href="#cb124-1167" aria-hidden="true" tabindex="-1"></a>prds_mqgam <span class="ot">=</span> lrn_mqgam<span class="sc">$</span><span class="fu">predict</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>test)</span>
<span id="cb124-1168"><a href="#cb124-1168" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1169"><a href="#cb124-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1170"><a href="#cb124-1170" aria-hidden="true" tabindex="-1"></a>After training, we generate predictions for the test set and visualize the results.</span>
<span id="cb124-1171"><a href="#cb124-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1172"><a href="#cb124-1172" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE}</span></span>
<span id="cb124-1173"><a href="#cb124-1173" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Results of quantile regression with GAM. 90%-prediction interval in green and 50%-prediction interval in blue. The black line is the underlying function.</span></span>
<span id="cb124-1174"><a href="#cb124-1174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1175"><a href="#cb124-1175" aria-hidden="true" tabindex="-1"></a>data_mqgam <span class="ot">=</span> <span class="fu">as.data.table</span>(prds_mqgam)</span>
<span id="cb124-1176"><a href="#cb124-1176" aria-hidden="true" tabindex="-1"></a>data_mqgam[, x <span class="sc">:</span><span class="er">=</span> task<span class="sc">$</span><span class="fu">data</span>(<span class="at">rows =</span> splits<span class="sc">$</span>test)<span class="sc">$</span>x]</span>
<span id="cb124-1177"><a href="#cb124-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1178"><a href="#cb124-1178" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">=</span> viridis<span class="sc">::</span><span class="fu">viridis</span>(<span class="dv">2</span>, <span class="at">begin =</span> <span class="fl">0.5</span>, <span class="at">end =</span> <span class="fl">0.7</span>)</span>
<span id="cb124-1179"><a href="#cb124-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1180"><a href="#cb124-1180" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data_mqgam, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb124-1181"><a href="#cb124-1181" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.05</span>), <span class="at">color =</span> colors[[<span class="dv">2</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1182"><a href="#cb124-1182" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.95</span>), <span class="at">color =</span> colors[[<span class="dv">2</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1183"><a href="#cb124-1183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> q0<span class="fl">.05</span>, <span class="at">ymax =</span> q0<span class="fl">.95</span>), <span class="at">fill =</span> colors[[<span class="dv">2</span>]], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb124-1184"><a href="#cb124-1184" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.25</span>), <span class="at">color =</span> colors[[<span class="dv">1</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1185"><a href="#cb124-1185" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> q0<span class="fl">.75</span>), <span class="at">color =</span> colors[[<span class="dv">1</span>]], <span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1186"><a href="#cb124-1186" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> q0<span class="fl">.25</span>, <span class="at">ymax =</span> q0<span class="fl">.75</span>), <span class="at">fill =</span> colors[[<span class="dv">1</span>]], <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb124-1187"><a href="#cb124-1187" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> truth), <span class="at">alpha =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb124-1188"><a href="#cb124-1188" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span>y), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb124-1189"><a href="#cb124-1189" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">15</span>)) <span class="sc">+</span></span>
<span id="cb124-1190"><a href="#cb124-1190" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">""</span>, <span class="at">x =</span> <span class="st">"x"</span>, <span class="at">y =</span> <span class="st">"y"</span>) <span class="sc">+</span></span>
<span id="cb124-1191"><a href="#cb124-1191" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb124-1192"><a href="#cb124-1192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1193"><a href="#cb124-1193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1194"><a href="#cb124-1194" aria-hidden="true" tabindex="-1"></a>Compared to the random regression forest, the quantile GAM produces smoother estimates, as expected from an additive model.</span>
<span id="cb124-1195"><a href="#cb124-1195" aria-hidden="true" tabindex="-1"></a>The predicted median closely follows the true function, and the estimated prediction intervals capture the heteroscedastic variance of the target well.</span>
<span id="cb124-1196"><a href="#cb124-1196" aria-hidden="true" tabindex="-1"></a>Notably, the coverage of the quantiles is more stable, without the fluctuations seen in the random forest approach.</span>
<span id="cb124-1197"><a href="#cb124-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1198"><a href="#cb124-1198" aria-hidden="true" tabindex="-1"></a>There are multiple learners in the <span class="in">`mlr3verse`</span> which cannot predict multiple quantiles simultaneously.</span>
<span id="cb124-1199"><a href="#cb124-1199" aria-hidden="true" tabindex="-1"></a>Because of this, we are also going to show how to use the <span class="in">`po("learner_quantiles")`</span> from <span class="in">`r ref_pkg("mlr3pipelines")`</span>, which wraps a learner and extends its functionality to handle multiple quantiles in one step.</span>
<span id="cb124-1200"><a href="#cb124-1200" aria-hidden="true" tabindex="-1"></a>@sec-pipelines and @sec-pipelines-nonseq have already given an introduction to <span class="in">`r ref_pkg("mlr3pipelines")`</span>.</span>
<span id="cb124-1201"><a href="#cb124-1201" aria-hidden="true" tabindex="-1"></a>We use this pipeop with <span class="co">[</span><span class="ot">`lrn("regr.qgam")`</span><span class="co">](https://mlr3extralearners.mlr-org.com/reference/mlr_learners_regr.qgam.html)</span>, a quantile regression GAM learner that can only be trained on one quantile.</span>
<span id="cb124-1202"><a href="#cb124-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1203"><a href="#cb124-1203" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, message=FALSE}</span></span>
<span id="cb124-1204"><a href="#cb124-1204" aria-hidden="true" tabindex="-1"></a>lrn_qgam <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">"regr.qgam"</span>)</span>
<span id="cb124-1205"><a href="#cb124-1205" aria-hidden="true" tabindex="-1"></a>lrn_qgam<span class="sc">$</span>param_set<span class="sc">$</span>values<span class="sc">$</span>form <span class="ot">=</span> y <span class="sc">~</span> <span class="fu">s</span>(x)</span>
<span id="cb124-1206"><a href="#cb124-1206" aria-hidden="true" tabindex="-1"></a>po_qgam <span class="ot">=</span> <span class="fu">po</span>(<span class="st">"learner_quantiles"</span>, <span class="at">learner =</span> lrn_qgam,</span>
<span id="cb124-1207"><a href="#cb124-1207" aria-hidden="true" tabindex="-1"></a>                  <span class="at">quantiles.q_response =</span> <span class="fl">0.5</span>,</span>
<span id="cb124-1208"><a href="#cb124-1208" aria-hidden="true" tabindex="-1"></a>                  <span class="at">quantiles.q_vals =</span> qs)</span>
<span id="cb124-1209"><a href="#cb124-1209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1210"><a href="#cb124-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1211"><a href="#cb124-1211" aria-hidden="true" tabindex="-1"></a>We can then use <span class="in">`r ref("mlr3pipelines::GraphLearner")`</span> to predict for the test set.</span>
<span id="cb124-1212"><a href="#cb124-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1213"><a href="#cb124-1213" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, warning=FALSE, message=FALSE, results='hide'}</span></span>
<span id="cb124-1214"><a href="#cb124-1214" aria-hidden="true" tabindex="-1"></a>graph_lrn_qgam <span class="ot">=</span> <span class="fu">as_learner</span>(po_qgam)</span>
<span id="cb124-1215"><a href="#cb124-1215" aria-hidden="true" tabindex="-1"></a>graph_lrn_qgam<span class="sc">$</span><span class="fu">train</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>train)</span>
<span id="cb124-1216"><a href="#cb124-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1217"><a href="#cb124-1217" aria-hidden="true" tabindex="-1"></a>prds_qgam <span class="ot">=</span> graph_lrn_qgam<span class="sc">$</span><span class="fu">predict</span>(task, <span class="at">row_ids =</span> splits<span class="sc">$</span>test)</span>
<span id="cb124-1218"><a href="#cb124-1218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1219"><a href="#cb124-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1220"><a href="#cb124-1220" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Comparison of methods {#sec-comparison}</span></span>
<span id="cb124-1221"><a href="#cb124-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1222"><a href="#cb124-1222" aria-hidden="true" tabindex="-1"></a>So far, we have only looked at a visualization of the predictions on the test data.</span>
<span id="cb124-1223"><a href="#cb124-1223" aria-hidden="true" tabindex="-1"></a>We will now evaluate and benchmark the two models.</span>
<span id="cb124-1224"><a href="#cb124-1224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1225"><a href="#cb124-1225" aria-hidden="true" tabindex="-1"></a>To evaluate how well each model predicts quantiles on our test data, we compute the pinball loss.</span>
<span id="cb124-1226"><a href="#cb124-1226" aria-hidden="true" tabindex="-1"></a>In general, a lower absolute pinball loss indicates better accuracy for a given quantile <span class="in">`alpha`</span>.</span>
<span id="cb124-1227"><a href="#cb124-1227" aria-hidden="true" tabindex="-1"></a>Since extreme quantiles (e.g. 0.05 or 0.95) represent rare events and rely on less data for estimation, we would typically expect them to have higher loss than the median.</span>
<span id="cb124-1228"><a href="#cb124-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1231"><a href="#cb124-1231" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb124-1232"><a href="#cb124-1232" aria-hidden="true" tabindex="-1"></a>measures <span class="ot">=</span> <span class="fu">list</span>(<span class="fu">msr</span>(<span class="st">"regr.pinball"</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>, <span class="at">id =</span> <span class="st">"q0.05"</span>),</span>
<span id="cb124-1233"><a href="#cb124-1233" aria-hidden="true" tabindex="-1"></a>          <span class="fu">msr</span>(<span class="st">"regr.pinball"</span>, <span class="at">alpha =</span> <span class="fl">0.25</span>, <span class="at">id =</span> <span class="st">"q0.25"</span>),</span>
<span id="cb124-1234"><a href="#cb124-1234" aria-hidden="true" tabindex="-1"></a>          <span class="fu">msr</span>(<span class="st">"regr.pinball"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">id =</span> <span class="st">"q0.5"</span>),</span>
<span id="cb124-1235"><a href="#cb124-1235" aria-hidden="true" tabindex="-1"></a>          <span class="fu">msr</span>(<span class="st">"regr.pinball"</span>, <span class="at">alpha =</span> <span class="fl">0.75</span>, <span class="at">id =</span> <span class="st">"q0.75"</span>),</span>
<span id="cb124-1236"><a href="#cb124-1236" aria-hidden="true" tabindex="-1"></a>          <span class="fu">msr</span>(<span class="st">"regr.pinball"</span>, <span class="at">alpha =</span> <span class="fl">0.95</span>, <span class="at">id =</span> <span class="st">"q0.95"</span>))</span>
<span id="cb124-1237"><a href="#cb124-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1238"><a href="#cb124-1238" aria-hidden="true" tabindex="-1"></a>prds_ranger<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb124-1239"><a href="#cb124-1239" aria-hidden="true" tabindex="-1"></a>prds_mqgam<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb124-1240"><a href="#cb124-1240" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1241"><a href="#cb124-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1242"><a href="#cb124-1242" aria-hidden="true" tabindex="-1"></a>In this case, the loss for more extreme quantiles is lower than that of the median.</span>
<span id="cb124-1243"><a href="#cb124-1243" aria-hidden="true" tabindex="-1"></a>The quantiles modeled with the GAM provide a better fit than the random forest.</span>
<span id="cb124-1244"><a href="#cb124-1244" aria-hidden="true" tabindex="-1"></a>This aligns with our previous results, where the GAM produced smoother quantile estimates than the random forest.</span>
<span id="cb124-1245"><a href="#cb124-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1246"><a href="#cb124-1246" aria-hidden="true" tabindex="-1"></a>To further assess the quality of our models, we resample and benchmark the models with 10-fold cross validation.</span>
<span id="cb124-1247"><a href="#cb124-1247" aria-hidden="true" tabindex="-1"></a>After resampling, the results can then be aggregated and scored.</span>
<span id="cb124-1248"><a href="#cb124-1248" aria-hidden="true" tabindex="-1"></a>This works as established in @sec-performance.</span>
<span id="cb124-1249"><a href="#cb124-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1250"><a href="#cb124-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, warning=FALSE, message=FALSE, results='hide'}</span></span>
<span id="cb124-1251"><a href="#cb124-1251" aria-hidden="true" tabindex="-1"></a>cv10 <span class="ot">=</span> <span class="fu">rsmp</span>(<span class="st">"cv"</span>, <span class="at">folds =</span> <span class="dv">10</span>)</span>
<span id="cb124-1252"><a href="#cb124-1252" aria-hidden="true" tabindex="-1"></a>cv10<span class="sc">$</span><span class="fu">instantiate</span>(task)</span>
<span id="cb124-1253"><a href="#cb124-1253" aria-hidden="true" tabindex="-1"></a>rr_ranger <span class="ot">=</span> <span class="fu">resample</span>(task, lrn_ranger, cv10)</span>
<span id="cb124-1254"><a href="#cb124-1254" aria-hidden="true" tabindex="-1"></a>rr_mqgam <span class="ot">=</span> <span class="fu">resample</span>(task, lrn_mqgam, cv10)</span>
<span id="cb124-1255"><a href="#cb124-1255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1256"><a href="#cb124-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1259"><a href="#cb124-1259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb124-1260"><a href="#cb124-1260" aria-hidden="true" tabindex="-1"></a><span class="co"># Score and aggregate resampling results</span></span>
<span id="cb124-1261"><a href="#cb124-1261" aria-hidden="true" tabindex="-1"></a>acc_ranger <span class="ot">=</span> rr_ranger<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb124-1262"><a href="#cb124-1262" aria-hidden="true" tabindex="-1"></a>rr_ranger<span class="sc">$</span><span class="fu">aggregate</span>(measures)</span>
<span id="cb124-1263"><a href="#cb124-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1264"><a href="#cb124-1264" aria-hidden="true" tabindex="-1"></a>acc_mqgam <span class="ot">=</span> rr_mqgam<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb124-1265"><a href="#cb124-1265" aria-hidden="true" tabindex="-1"></a>rr_mqgam<span class="sc">$</span><span class="fu">aggregate</span>(measures)</span>
<span id="cb124-1266"><a href="#cb124-1266" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1267"><a href="#cb124-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1268"><a href="#cb124-1268" aria-hidden="true" tabindex="-1"></a>Finally, we compare both learners in a benchmark:</span>
<span id="cb124-1269"><a href="#cb124-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1270"><a href="#cb124-1270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, results='hide'}</span></span>
<span id="cb124-1271"><a href="#cb124-1271" aria-hidden="true" tabindex="-1"></a>learners <span class="ot">=</span> <span class="fu">lrns</span>(<span class="fu">c</span>(<span class="st">"regr.ranger"</span>, <span class="st">"regr.mqgam"</span>), <span class="at">predict_type =</span> <span class="st">"quantiles"</span>,</span>
<span id="cb124-1272"><a href="#cb124-1272" aria-hidden="true" tabindex="-1"></a>     <span class="at">quantiles =</span> qs, <span class="at">quantile_response =</span> <span class="fl">0.5</span>)</span>
<span id="cb124-1273"><a href="#cb124-1273" aria-hidden="true" tabindex="-1"></a>design <span class="ot">=</span> <span class="fu">benchmark_grid</span>(task, learners, cv10)</span>
<span id="cb124-1274"><a href="#cb124-1274" aria-hidden="true" tabindex="-1"></a>bmr <span class="ot">=</span> <span class="fu">benchmark</span>(design)</span>
<span id="cb124-1275"><a href="#cb124-1275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1276"><a href="#cb124-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1279"><a href="#cb124-1279" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb124-1280"><a href="#cb124-1280" aria-hidden="true" tabindex="-1"></a>bmr_scores <span class="ot">=</span> bmr<span class="sc">$</span><span class="fu">score</span>(measures)</span>
<span id="cb124-1281"><a href="#cb124-1281" aria-hidden="true" tabindex="-1"></a>bmr_agg <span class="ot">=</span> bmr<span class="sc">$</span><span class="fu">aggregate</span>(measures)</span>
<span id="cb124-1282"><a href="#cb124-1282" aria-hidden="true" tabindex="-1"></a>bmr_agg[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</span>
<span id="cb124-1283"><a href="#cb124-1283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb124-1284"><a href="#cb124-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1285"><a href="#cb124-1285" aria-hidden="true" tabindex="-1"></a>In general, all standard <span class="in">`mlr3`</span>-workflows, i.e. resampling, benchmarking, tuning, and the use of pipelines, can be applied to quantile regression learners just as they are applied to regression learners with other predict types.</span>
<span id="cb124-1286"><a href="#cb124-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1287"><a href="#cb124-1287" aria-hidden="true" tabindex="-1"></a>In this section, we learned how we can use quantile regression in <span class="in">`mlr3`</span>.</span>
<span id="cb124-1288"><a href="#cb124-1288" aria-hidden="true" tabindex="-1"></a>Although both models capture the general trend of the data, the GAM-based approach provides smoother quantile estimates and better coverage of predictive intervals.</span>
<span id="cb124-1289"><a href="#cb124-1289" aria-hidden="true" tabindex="-1"></a>The random forest model exhibits more variability and struggles with overfitting, particularly at extreme quantiles.</span>
<span id="cb124-1290"><a href="#cb124-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1291"><a href="#cb124-1291" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb124-1292"><a href="#cb124-1292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1293"><a href="#cb124-1293" aria-hidden="true" tabindex="-1"></a>In this chapter, we explored going beyond regression and classification to see how classes in <span class="in">`mlr3`</span> can be used to implement other ML tasks.</span>
<span id="cb124-1294"><a href="#cb124-1294" aria-hidden="true" tabindex="-1"></a>Cost-sensitive classification extends the 'normal' classification setting by assuming that costs associated with <span class="in">`r index('false negatives', 'false negative')`</span> and <span class="in">`r index('false positives', 'false positive')`</span> are unequal.</span>
<span id="cb124-1295"><a href="#cb124-1295" aria-hidden="true" tabindex="-1"></a>Running cost-sensitive classification experiments is possible using only features in <span class="in">`mlr3`</span>.</span>
<span id="cb124-1296"><a href="#cb124-1296" aria-hidden="true" tabindex="-1"></a>Survival analysis, available in <span class="in">`r mlr3proba`</span>, can be thought of as a regression problem when the outcome may be censored, which means it may never be observed within a given time frame.</span>
<span id="cb124-1297"><a href="#cb124-1297" aria-hidden="true" tabindex="-1"></a>The final task in <span class="in">`mlr3proba`</span> is density estimation, the unsupervised task concerned with estimating univariate probability distributions.</span>
<span id="cb124-1298"><a href="#cb124-1298" aria-hidden="true" tabindex="-1"></a>Using <span class="in">`r mlr3cluster`</span>, you can perform cluster analysis on observations, which involves grouping observations according to similarities in their variables.</span>
<span id="cb124-1299"><a href="#cb124-1299" aria-hidden="true" tabindex="-1"></a>It is possible to perform spatial analysis with <span class="in">`r mlr3spatial`</span> and <span class="in">`r mlr3spatiotempcv`</span> to make predictions using coordinates as features and to make spatial predictions.</span>
<span id="cb124-1300"><a href="#cb124-1300" aria-hidden="true" tabindex="-1"></a>Finally, we saw how we can use the predict type <span class="in">`"quantiles"`</span> to predict conditional quantiles and construct prediction intervals.</span>
<span id="cb124-1301"><a href="#cb124-1301" aria-hidden="true" tabindex="-1"></a>The <span class="in">`mlr3`</span> interface is highly extensible, which means future ML tasks can (and will) be added to our universe and we will add these to this chapter of the book in future editions.</span>
<span id="cb124-1302"><a href="#cb124-1302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1303"><a href="#cb124-1303" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Class <span class="pp">|</span> Constructor/Function <span class="pp">|</span> Fields/Methods <span class="pp">|</span></span>
<span id="cb124-1304"><a href="#cb124-1304" aria-hidden="true" tabindex="-1"></a><span class="pp">| -----</span> <span class="pp">| ---</span> <span class="pp">|</span> -- <span class="pp">|</span></span>
<span id="cb124-1305"><a href="#cb124-1305" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3::MeasureClassifCosts")`</span> <span class="pp">|</span> <span class="in">`msr("classif.costs")`</span> <span class="pp">|</span> - <span class="pp">|</span></span>
<span id="cb124-1306"><a href="#cb124-1306" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3pipelines::PipeOpTuneThreshold")`</span> <span class="pp">|</span> <span class="in">`po("tunethreshold")`</span> <span class="pp">|</span> - <span class="pp">|</span></span>
<span id="cb124-1307"><a href="#cb124-1307" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3proba::TaskSurv")`</span> <span class="pp">|</span> <span class="in">`r ref("as_task_surv()")`</span> <span class="pp">|</span> <span class="in">`$data()`</span> <span class="pp">|</span></span>
<span id="cb124-1308"><a href="#cb124-1308" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3proba::PipeOpDistrCompositor")`</span> <span class="pp">|</span> <span class="in">`po("distrcompose")`</span> <span class="pp">|</span> - <span class="pp">|</span></span>
<span id="cb124-1309"><a href="#cb124-1309" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3proba::TaskDens")`</span> <span class="pp">|</span> <span class="in">`r ref("as_task_dens()")`</span> <span class="pp">|</span> <span class="in">`$data()`</span> <span class="pp">|</span></span>
<span id="cb124-1310"><a href="#cb124-1310" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3cluster::TaskClust")`</span> <span class="pp">|</span> <span class="in">`r ref("as_task_clust()")`</span> <span class="pp">|</span> <span class="in">`$data()`</span> <span class="pp">|</span></span>
<span id="cb124-1311"><a href="#cb124-1311" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> <span class="in">`r ref("mlr3spatiotempcv::TaskClassifST")`</span> <span class="pp">|</span> <span class="in">`r ref("as_task_classif_st()")`</span> <span class="pp">|</span> <span class="in">`$data()`</span> <span class="pp">|</span></span>
<span id="cb124-1312"><a href="#cb124-1312" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> - <span class="pp">|</span> <span class="in">`r ref("mlr3spatiotempcv::predict_spatial()")`</span> <span class="pp">|</span>  <span class="pp">|</span></span>
<span id="cb124-1313"><a href="#cb124-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1314"><a href="#cb124-1314" aria-hidden="true" tabindex="-1"></a>: Important classes and functions covered in this chapter with underlying class (if applicable), class constructor or function, and important class fields and methods (if applicable). {#tbl-beyond-api}</span>
<span id="cb124-1315"><a href="#cb124-1315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1316"><a href="#cb124-1316" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises</span></span>
<span id="cb124-1317"><a href="#cb124-1317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1318"><a href="#cb124-1318" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Run a benchmark experiment on <span class="in">`tsk("german_credit")`</span> with <span class="in">`lrn("classif.featureless")`</span>, <span class="in">`lrn("classif.log_reg")`</span>, and <span class="in">`lrn("classif.ranger")`</span>.</span>
<span id="cb124-1319"><a href="#cb124-1319" aria-hidden="true" tabindex="-1"></a>  Tune the prediction thresholds of all learners by encapsulating them in a <span class="in">`po("learner_cv")`</span> (with two-fold CV), followed by a <span class="in">`po("tunethreshold")`</span>.</span>
<span id="cb124-1320"><a href="#cb124-1320" aria-hidden="true" tabindex="-1"></a>  Use <span class="in">`msr("classif.costs", costs = costs)`</span>, where the <span class="in">`costs`</span> matrix is as follows: true positive is <span class="in">`-10`</span>, true negative is <span class="in">`-1`</span>, false positive is <span class="in">`2`</span>, and false negative is <span class="in">`3`</span>.</span>
<span id="cb124-1321"><a href="#cb124-1321" aria-hidden="true" tabindex="-1"></a>  Use this measure in <span class="in">`po("tunethreshold")`</span> and when evaluating your benchmark experiment.</span>
<span id="cb124-1322"><a href="#cb124-1322" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Train and test a survival forest using <span class="in">`lrn("surv.rfsrc")`</span> (from <span class="in">`mlr3extralearners`</span>).</span>
<span id="cb124-1323"><a href="#cb124-1323" aria-hidden="true" tabindex="-1"></a>  Run this experiment using <span class="in">`tsk("rats")`</span> and <span class="in">`partition()`</span>.</span>
<span id="cb124-1324"><a href="#cb124-1324" aria-hidden="true" tabindex="-1"></a>  Evaluate your model with the RCLL measure.</span>
<span id="cb124-1325"><a href="#cb124-1325" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Estimate the density of the "precip" task from the <span class="in">`mlr3proba`</span> package using <span class="in">`lrn("dens.hist")`</span>, evaluate your estimation with the logloss measure.</span>
<span id="cb124-1326"><a href="#cb124-1326" aria-hidden="true" tabindex="-1"></a>  As a stretch goal, look into the documentation of <span class="in">`distr6`</span> to learn how to analyse your estimated distribution further.</span>
<span id="cb124-1327"><a href="#cb124-1327" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Run a benchmark clustering experiment on the "wine" dataset without a label column.</span>
<span id="cb124-1328"><a href="#cb124-1328" aria-hidden="true" tabindex="-1"></a>  Compare the performance of k-means learner with <span class="in">`k`</span> equal to <span class="in">`2`</span>, <span class="in">`3`</span> and <span class="in">`4`</span> using the silhouette measure and the insample resampling technique.</span>
<span id="cb124-1329"><a href="#cb124-1329" aria-hidden="true" tabindex="-1"></a>  What value of <span class="in">`k`</span> would you choose based on the silhouette scores?</span>
<span id="cb124-1330"><a href="#cb124-1330" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Manually <span class="in">`$train()`</span> a GBM regression model from <span class="in">`r ref_pkg("mlr3extralearners")`</span> on <span class="in">`tsk("mtcars")`</span> to predict the 95th percentile of the target variable.</span>
<span id="cb124-1331"><a href="#cb124-1331" aria-hidden="true" tabindex="-1"></a>  Make sure that you split the data and only use the test data for fitting the learner.</span>
<span id="cb124-1332"><a href="#cb124-1332" aria-hidden="true" tabindex="-1"></a>  Use the test data to evaluate your learner with the pinball loss.</span>
<span id="cb124-1333"><a href="#cb124-1333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-1334"><a href="#cb124-1334" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb124-1335"><a href="#cb124-1335" aria-hidden="true" tabindex="-1"></a><span class="in">`r citeas(chapter)`</span></span>
<span id="cb124-1336"><a href="#cb124-1336" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>All content licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> <br> © Bernd Bischl, Raphael Sonabend, Lars Kotthoff, Michel Lang.</p>
</div>   
    <div class="nav-footer-center">
<p><a href="https://mlr-org.com">Website</a> | <a href="https://github.com/mlr-org/mlr3book">GitHub</a> | <a href="https://mlr-org.com/gallery">Gallery</a> | <a href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/">Mattermost</a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/mlr-org/mlr3book/edit/main/book/chapters/chapter13/beyond_regression_and_classification.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/mlr-org/mlr3book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/mlr-org/mlr3book/blob/main/book/chapters/chapter13/beyond_regression_and_classification.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>