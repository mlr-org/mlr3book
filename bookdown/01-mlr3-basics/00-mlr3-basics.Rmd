# mlr3 Basics {#basics}

This chapter will teach you the essential building blocks, R6 classes, and operations of `r mlr_pkg("mlr3")`.
This includes creating supervised machine learning tasks like classification and regression, training models and getting prediction on new data, and evaluating and comparing different models through cross-validation and benchmarking.

A typical machine learning workflow looks like this:

```{r 00-mlr3-basics-001, echo = FALSE}
knitr::include_graphics("images/ml_abstraction.png")
```

The data, which `r mlr_pkg("mlr3")` encapsulates in tasks, is split into non-overlapping train and test sets to be able to evaluate models objectively &mdash; we are interested in models that generalize to new data rather than just memorizing the training data.
The training data is given to a machine learning algorithm, called a learner in `r mlr_pkg("mlr3")`, that uses it to build a model of how the features of the data relate to the target values.
This model is then used to produce predictions on the test data, which are compared to the ground truth values to assess the quality of the model.
`r mlr_pkg("mlr3")` offers a number of different measures to quantify this quality; usually a numeric score.
This process may be repeated several times, each time resampling different train and test sets from the original data set.
Multiple resampling iterations allow one to get a better generalization performance estimate for a particular type of model by quantifying its performance on different data.

The `r mlr_pkg("mlr3")` package provides R6 classes for the essential building blocks of this machine learning workflow:

* A [task](#tasks) encapsulates the data along with additional information, such as what the prediction target is.
* A [learners](#learners) encapsulates one of R's many machine learning algorithms and allows to train models and make predictions.
  Most learners have hyperparameters that affect their operation.
* A [measure](#measures) computes a numeric score based on predicted and ground-truth values and their difference.
* A [resampling](#resampling) specifies a series of train and test sets.

In many cases, this simple workflow is not sufficient to deal with real-world data, which may require normalization, imputation of missing values, or feature selection.
We will cover more complex workflows that allow to do this and even more later in the book.
For now, we restrict ourselves to simple workflows like the one above for the sake of clarity.
