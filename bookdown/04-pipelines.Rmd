# Pipelines {#pipelines}

`r mlr_pkg("mlr3pipelines")` is a dataflow programming toolkit.
This chapter focuses on the applicant's side of the package.
A more in-depth and technically oriented vignette can be found in the [mlr3pipeline vignette](https://mlr3pipelines.mlr-org.com/articles/introduction.html).

Machine learning workflows can be written as directed “Graphs”/"Pipelines" that represent data flows between preprocessing, model fitting, and ensemble learning units in an expressive and intuitive language.
We will most often use the term "Graph" in this manual but it can interchangeably be used with "pipeline" or "workflow".

An example for such a graph can be found below:

```{r 04-pipelines-001, echo=FALSE, fig.align='center', out.width="98%"}
knitr::include_graphics("images/simple_pipeline.png")
```

Single computational steps can be represented as so-called PipeOps, which can then be connected with directed edges in a Graph.
The scope of `r mlr_pkg("mlr3pipelines")` is still growing.
Currently supported features are:

* Data manipulation and preprocessing operations, e.g. PCA, feature filtering, imputation
* Task subsampling for speed and outcome class imbalance handling
* `r mlr_pkg("mlr3")` Learner operations for prediction and stacking
* Ensemble methods and aggregation of predictions

Additionally, we implement several meta operators that can be used to construct powerful pipelines:

* Simultaneous path branching (data going both ways)
* Alternative path branching (data going one specific way, controlled by hyperparameters)

An extensive introduction to creating custom **PipeOps** (PO's) can be found in the [technical introduction](#extending-mlr3pipelines).

Using methods from `r mlr_pkg("mlr3tuning")`, it is even possible to simultaneously optimize parameters of multiple processing units.

A predecessor to this package is the [mlrCPO](https://github.com/mlr-org/mlrCPO) package, which works with mlr 2.x.
Other packages that provide, to varying degree, some preprocessing functionality or machine learning domain specific language, are:

* the `r cran_pkg("caret")` package and the related `r cran_pkg("recipes")`  project
* the `r cran_pkg("dplyr")` package

An example for a Pipeline that can be constructed using `r mlr_pkg("mlr3pipelines")` is depicted below:

```{r 04-pipelines-002, echo = FALSE, width = 10, height = 10, eval=TRUE, message=FALSE}
# This just produces a plot, not visible to the user.
library(visNetwork)
library(mlr3misc)
library(mlr3pipelines)
graph = mlr_pipeops$get("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
      mlr_pipeops$get("nop", id = "null1"),
      mlr_pipeops$get("pca"),
      mlr_pipeops$get("scale")
  ))
gr = graph %>>%
  mlr_pipeops$get("unbranch", c("nop", "pca", "scale")) %>>%
  mlr_pipeops$get("learner", mlr_learners$get("classif.rpart"))

 gr$plot(html = TRUE) %>% visInteraction(zoomView = FALSE)
```

## The Building Blocks: PipeOps

The building blocks of `r mlr_pkg("mlr3pipelines")` are **PipeOp**-objects (PO).
They can be constructed directly using `PipeOp<NAME>$new()`, but the recommended way is to retrieve them from the `mlr_pipeops` dictionary:

```{r 04-pipelines-003}
library("mlr3pipelines")
as.data.table(mlr_pipeops)
```

Single POs can be created using `mlr_pipeops$get(<name>)`:

```{r 04-pipelines-004}
pca = mlr_pipeops$get("pca")
```

or using **syntactic sugar**:
```{r 04-pipelines-005}
pca = po("pca")
```

Some POs require additional arguments for construction:

```{r 04-pipelines-006, eval = FALSE}
learner = mlr_pipeops$get("learner")

# Error in as_learner(learner) : argument "learner" is missing, with no default argument "learner" is missing, with no default
```

```{r 04-pipelines-007}
learner = mlr_pipeops$get("learner", mlr_learners$get("classif.rpart"))
```

or in short `po("learner", lrn("classif.rpart"))`.

Hyperparameters of POs can be set through the `param_vals` argument.
Here we set the fraction of features for a filter:

```{r 04-pipelines-008}
filter = mlr_pipeops$get("filter",
  filter = mlr3filters::FilterVariance$new(),
  param_vals = list(filter.frac = 0.5))
```

or in short notation:

```{r 04-pipelines-009, eval = FALSE}
po("filter", mlr3filters::FilterVariance$new(), filter.frac = 0.5)
```

The figure below shows an exemplary `PipeOp`.
It takes an input, transforms it during `.$train` and `.$predict` and returns data:

```{r 04-pipelines-010}
knitr::include_graphics("images/po_viz.png")
```

## The Pipeline Operator: `%>>%` {#pipe-operator}

Although it is possible to create intricate `Graphs` with edges going all over the place (as long as no loops are introduced), there is usually a clear direction of flow between "layers" in the `Graph`.
It is therefore convenient to build up a `Graph` from layers.
This can be done using the **`%>>%`** ("double-arrow") operator.
It takes either a `PipeOp` or a `Graph` on each of its sides and connects all of the outputs of its left-hand side to one of the inputs each of its right-hand side.
The number of inputs therefore must match the number of outputs.

```{r 04-pipelines-011}
gr = mlr_pipeops$get("scale") %>>% mlr_pipeops$get("pca")
gr$plot(html = TRUE) %>% visInteraction(zoomView = FALSE) # disable zoom
```

## Nodes, Edges and Graphs {#pipe-nodes-edges-graphs}

POs are combined into `r ref("Graph")`s.
The manual way (= hard way) to construct a `r ref("Graph")`  is to create an empty graph first.
Then one fills the empty graph with POs, and connects edges between the POs.
POs are identified by their `$id`.
Note that the operations all modify the object in-place and return the object itself.
Therefore, multiple modifications can be chained.

For this example we use the `pca` PO defined above and a new PO named "mutate".
The latter creates a new feature from existing variables.

```{r 04-pipelines-012}
mutate = mlr_pipeops$get("mutate")
```

```{r 04-pipelines-013}
graph = Graph$new()$
  add_pipeop(mutate)$
  add_pipeop(filter)$
  add_edge("mutate", "variance")  # add connection mutate -> filter
```

The much quicker way is to use the `%>>%` operator to chain POs or `r ref("Graph")` s.
The same result as above can be achieved by doing the following:

```{r 04-pipelines-014}
graph = mutate %>>% filter
```

Now the `r ref("Graph")`  can be inspected using its `$plot()` function:

```{r 04-pipelines-015}
graph$plot(html = TRUE) %>% visInteraction(zoomView = FALSE) # disable zoom
```

**Chaining multiple POs of the same kind**

If multiple POs of the same kind should be chained, it is necessary to change the `id` to avoid name clashes.
This can be done by either accessing the `$id` slot or during construction:

```{r 04-pipelines-016, error = TRUE}
graph$add_pipeop(mlr_pipeops$get("pca"))
```

```{r 04-pipelines-017}
graph$add_pipeop(mlr_pipeops$get("pca", id = "pca2"))
```

## Modeling {#pipe-modeling}

The main purpose of a `r ref("Graph")` is to build combined preprocessing and model fitting pipelines that can be used as `r mlr_pkg("mlr3")` `r ref("Learner")`.
In the following we chain two preprocessing tasks:

* mutate (creation of a new feature)
* filter (filtering the dataset)

and then chain a PO learner to train and predict on the modified dataset.

```{r 04-pipelines-018}
graph = mutate %>>%
  filter %>>%
  mlr_pipeops$get("learner",
    learner = mlr_learners$get("classif.rpart"))
```

Until here we defined the main pipeline stored in `r ref("Graph")`.
Now we can train and predict the pipeline:

```{r 04-pipelines-019, message=FALSE}
task = mlr_tasks$get("iris")
graph$train(task)
graph$predict(task)
```

Rather than calling `$train()` and `$predict()` manually, we can put the pipeline `r ref("Graph")` into a `r ref("GraphLearner")` object.
A `r ref("GraphLearner")` encapsulates the whole pipeline (including the preprocessing steps) and can be put into `r ref("resample()")`  or `r ref("benchmark()")` .
If you are familiar with the old _mlr_ package, this is the equivalent of all the `make*Wrapper()` functions.
The pipeline being encapsulated (here `r ref("Graph")` ) must always produce a `r ref("Prediction")`  with its `$predict()` call, so it will probably contain at least one `r ref("PipeOpLearner")` .

```{r 04-pipelines-020}
glrn = GraphLearner$new(graph)
```

This learner can be used for model fitting, resampling, benchmarking, and tuning:

```{r 04-pipelines-021}
cv3 = rsmp("cv", folds = 3)
resample(task, glrn, cv3)
```

### Setting Hyperparameters {#pipe-hyperpars}

Individual POs offer hyperparameters because they contain `$param_set` slots that can be read and written from `$param_set$values` (via the paradox package).
The parameters get passed down to the `r ref("Graph")`, and finally to the `r ref("GraphLearner")` .
This makes it not only possible to easily change the behavior of a `r ref("Graph")`  / `r ref("GraphLearner")` and try different settings manually, but also to perform tuning using the `r mlr_pkg("mlr3tuning")` package.

```{r 04-pipelines-022}
glrn$param_set$values$variance.filter.frac = 0.25
cv3 = rsmp("cv", folds = 3)
resample(task, glrn, cv3)
```

### Tuning {#pipe-tuning}

If you are unfamiliar with tuning in `r mlr_pkg("mlr3")`, we recommend to take a look at the section about [tuning](#tuning) first.
Here we define a `r ref("ParamSet")` for the "rpart" learner and the "variance" filter which should be optimized during tuning.

```{r 04-pipelines-023}
library("paradox")
ps = ParamSet$new(list(
  ParamDbl$new("classif.rpart.cp", lower = 0, upper = 0.05),
  ParamDbl$new("variance.filter.frac", lower = 0.25, upper = 1)
))
```

After having defined the `PerformanceEvaluator`, a random search with 10 iterations is created.
For the inner resampling, we are simply doing holdout (single split into train/test) to keep the runtimes reasonable.

```{r 04-pipelines-024}
library("mlr3tuning")
instance = TuningInstance$new(
  task = task,
  learner = glrn,
  resampling = rsmp("holdout"),
  measures = msr("classif.ce"),
  param_set = ps,
  terminator = term("evals", n_evals = 20)
)
```

```{r 04-pipelines-025, eval = FALSE}
tuner = TunerRandomSearch$new()
tuner$tune(instance)
```

The tuning result can be found in the `result` slot.

```{r 04-pipelines-026, eval = FALSE}
instance$result
```

## Non-Linear Graphs {#pipe-nonlinear}

The Graphs seen so far all have a linear structure.
Some POs may have multiple input or output channels.
These make it possible to create non-linear Graphs with alternative paths taken by the data.

Possible types are:

- [Branching](#pipe-model-ensembles-branching):
  Splitting of a node into several paths, e.g. useful when comparing multiple feature-selection methods (pca, filters).
  Only one path will be executed.
- [Copying](#pipe-model-ensembles-copying):
  Splitting of a node into several paths, all paths will be executed (sequentially).
  Parallel execution is not yet supported.
- [Stacking](#pipe-model-ensembles-stacking):
  Single graphs are stacked onto each other, i.e. the output of one `r ref("Graph")` is the input for another.
  In machine learning this means that the prediction of one `r ref("Graph")` is used as input for another `r ref("Graph")`

### Branching & Copying {#pipe-model-ensembles-branching-copying}

The `r ref("PipeOpBranch")`  and `r ref("PipeOpUnbranch")`  POs make it possible to specify multiple alternative paths.
Only one is actually executed, the others are ignored.
The active path is determined by a hyperparameter.
This concept makes it possible to tune alternative preprocessing paths (or learner models).

`PipeOp(Un)Branch` is initialized either with the number of branches, or with a `character`-vector indicating the names of the branches.
If names are given, the "branch-choosing" hyperparameter becomes more readable.
In the following, we set three options:

1. Doing nothing ("nop")
2. Applying a PCA
3. Scaling the data

It is important to "unbranch" again after "branching", so that the outputs are merged into one result objects.

In the following we first create the branched graph and then show what happens if the "unbranching" is not applied:

```{r 04-pipelines-027, eval = TRUE}
branch_graph = mlr_pipeops$get("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
      mlr_pipeops$get("nop", id = "null1"),
      mlr_pipeops$get("pca"),
      mlr_pipeops$get("scale")
  ))
```

Without "unbranching" one creates the following graph:

```{r 04-pipelines-028, eval=FALSE}
branch_graph$plot(html=TRUE)
```

```{r 04-pipelines-029, echo=FALSE, fig.align="right"}
branch_graph$plot(html=TRUE) %>% visInteraction(zoomView = FALSE) # disable zoom
```

Now when "unbranching", we obtain the following results:

```{r 04-pipelines-030, fig.align="center"}
(branch_graph %>>% mlr_pipeops$get("unbranch", c("nop", "pca", "scale")))$plot(html = TRUE) %>%
  visInteraction(zoomView = FALSE) # disable zoom
```

The same can be achieved using a shorter notation:

```{r 04-pipelines-031}
# List of pipeops
opts = list(po("nop", "no_op"), po("pca"), po("scale"))
# List of po ids
opt_ids = mlr3misc::map_chr(opts, `[[`, "id")
po("branch", options = opt_ids) %>>%
  gunion(opts) %>>%
  po("unbranch", options = opt_ids)
```

### Model Ensembles {#pipe-model-ensembles}

We can leverage the different operations presented to connect POs.
This allows us to form powerful graphs.

Before we go into details, we split the task into train and test indices.

```{r 04-pipelines-032}
task = mlr_tasks$get("iris")
train.idx = sample(seq_len(task$nrow), 120)
test.idx = setdiff(seq_len(task$nrow), train.idx)
```

#### Bagging {#pipe-model-ensembles-bagging}

We first examine Bagging introduced by [@Breiman1996].
The basic idea is to create multiple predictors and then aggregate those to a single, more powerful predictor.

> "... multiple versions are formed
> by making bootstrap replicates of the learning set
> and using these as new learning sets" [@Breiman1996]

Bagging then aggregates a set of predictors by averaging (regression) or majority vote (classification).
The idea behind bagging is, that a set of weak, but different predictors can be combined in order to arrive at a single, better predictor.

We can achieve this by downsampling our data before training a learner, repeating this e.g. 10 times and then performing a majority vote on the predictions.

First, we create a simple pipeline, that uses `r ref("PipeOpSubsample")`  before a `r ref("PipeOpLearner")`  is trained:

```{r 04-pipelines-033}
single_pred = PipeOpSubsample$new(param_vals = list(frac = 0.7)) %>>%
  PipeOpLearner$new(mlr_learners$get("classif.rpart"))
```

We can now copy this operation 10 times using `r ref("greplicate")` .

```{r 04-pipelines-034}
pred_set = greplicate(single_pred, 10L)
```

Afterwards we need to aggregate the 10 pipelines to form a single model:

```{r 04-pipelines-035}
bagging = pred_set %>>%
  PipeOpClassifAvg$new(innum = 10L)
```

Now we can plot again to see what happens:

```{r 04-pipelines-036, fig.width=7.5, fig.align="center"}
bagging$plot(html = TRUE)
```

This pipeline can again be used in conjunction with `r ref("GraphLearner")`  in order for Bagging to be used like a `r ref("Learner")`:

```{r 04-pipelines-037}
baglrn = GraphLearner$new(bagging)
baglrn$train(task, train.idx)
baglrn$predict(task, test.idx)
```

In conjunction with different `Backends`, this can be a very powerful tool.
In cases when the data does not fully fit in memory, one can obtain a fraction of the data for each learner from a `r ref("DataBackend")`  and then aggregate predictions over all learners.

#### Stacking {#pipe-model-ensembles-stacking}

Stacking [@Wolpert1992] is another technique that can improve model performance.
The basic idea behind stacking is the use of predictions from one model as features for a subsequent model to possibly improve performance.

As an example we can train a decision tree and use the predictions from this model in conjunction with the original features in order to train an additional model on top.

To limit overfitting, we additionally do not predict on the original predictions of the learner.
Instead, we predict on out-of-bag predictions.
To do all this, we can use `r ref("PipeOpLearnerCV")` .

`r ref("PipeOpLearnerCV")`  performs nested cross-validation on the training data, fitting a model in each fold.
Each of the models is then used to predict on the out-of-fold data.
As a result, we obtain predictions for every data point in our input data.

We first create a "level 0" learner, which is used to extract a lower level prediction.
Additionally, we `clone()` the learner object to obtain a copy of the learner.
Subsequently, one sets a custom id for the `r ref("PipeOp")` .

```{r 04-pipelines-038}
lrn = mlr_learners$get("classif.rpart")
lrn_0 = PipeOpLearnerCV$new(lrn$clone())
lrn_0$id = "rpart_cv"
```

We use `r ref("PipeOpNOP")`  in combination with `r ref("gunion")`, in order to send the unchanged Task to the next level.
There it is combined with the predictions from our decision tree learner.

```{r 04-pipelines-039}
level_0 = gunion(list(lrn_0, PipeOpNOP$new()))
```

Afterwards, we want to concatenate the predictions from `r ref("PipeOpLearnerCV")`  and the original Task using `r ref("PipeOpFeatureUnion")` :

```{r 04-pipelines-040}
combined = level_0 %>>% PipeOpFeatureUnion$new(2)
```

Now we can train another learner on top of the combined features:

```{r 04-pipelines-041, fig.width=7.5}
stack = combined %>>% PipeOpLearner$new(lrn$clone())
vn = stack$plot(html = TRUE)
visNetwork::visInteraction(vn, zoomView = FALSE) # disable zoom
```

```{r 04-pipelines-042, eval = FALSE}
stacklrn = GraphLearner$new(stack)
stacklrn$train(task, train.idx)
stacklrn$predict(task, test.idx)
```

In this vignette, we showed a very simple use-case for stacking.
In many real-world applications, stacking is done for multiple levels and on multiple representations of the dataset.
On a lower level, different preprocessing methods can be defined in conjunction with several learners.
On a higher level, we can then combine those predictions in order to form a very powerful model.

#### Multilevel Stacking

In order to showcase the power of `r mlr_pkg("mlr3pipelines")`, we will show a more complicated stacking example.

In this case, we train a `glmnet` and 2 different `rpart` models (some transform its inputs using `r ref("PipeOpPCA")`) on our task in the "level 0" and concatenate them with the original features (via `r ref("gunion")`.
The result is then passed on to "level 1", where we copy the concatenated features 3 times and put this task into an `rpart` and a `glmnet` model.
Additionally, we keep a version of the "level 0" output (via `r ref("PipeOpNOP")`) and pass this on to "level 2".
In "level 2" we simply concatenate all "level 1" outputs and train a final decision tree.

In the following examples, use `<lrn>$param_set$values$<param_name> = <param_value>` to set hyperparameters
for the different learner.

```{r 04-pipelines-043}
library(mlr3learners) # for classif.glmnet
rprt = lrn("classif.rpart", predict_type = "prob")
glmn = lrn("classif.glmnet", predict_type = "prob")

#  Create Learner CV Operators
lrn_0 = PipeOpLearnerCV$new(rprt, id = "rpart_cv_1")
lrn_0$param_set$values$maxdepth = 5L
lrn_1 = PipeOpPCA$new(id = "pca1") %>>% PipeOpLearnerCV$new(rprt, id = "rpart_cv_2")
lrn_1$param_set$values$rpart_cv_2.maxdepth = 1L
lrn_2 = PipeOpPCA$new(id = "pca2") %>>% PipeOpLearnerCV$new(glmn)

# Union them with a PipeOpNULL to keep original features
level_0 = gunion(list(lrn_0, lrn_1,lrn_2, PipeOpNOP$new(id = "NOP1")))

# Cbind the output 3 times, train 2 learners but also keep level
# 0 predictions
level_1 = level_0 %>>%
  PipeOpFeatureUnion$new(4) %>>%
  PipeOpCopy$new(3) %>>%
  gunion(list(
    PipeOpLearnerCV$new(rprt, id = "rpart_cv_l1"),
    PipeOpLearnerCV$new(glmn, id = "glmnt_cv_l1"),
    PipeOpNOP$new(id = "NOP_l1")
  ))

# Cbind predictions, train a final learner
level_2 = level_1 %>>%
  PipeOpFeatureUnion$new(3, id = "u2") %>>%
  PipeOpLearner$new(rprt,
    id = "rpart_l2")

# Plot the resulting graph
vn = level_2$plot(html = TRUE)
visNetwork::visInteraction(vn, zoomView = FALSE) # disable zoom

task = tsk("iris")
lrn = GraphLearner$new(level_2)
```

And we can again call `.$train` and `.$predict`

```{r 04-pipelines-044, eval=FALSE}
lrn$
  train(task, train.idx)$
  predict(task, test.idx)$
  score()
```

## Special Operators {#pipe-special-ops}

This section introduces some special operators, that might be useful in many applications.

### Imputation: `PipeOpImpute`

An often occurring setting is the imputation of missing data.
Imputation methods range from relatively simple imputation using either *mean*, *median* or histograms to way more involved methods including using machine learning algorithms in order to predict missing values.

The following `PipeOp`, `r ref("PipeOpImpute")`, imputes numeric values from a histogram, adds a new level for factors and additionally adds a column marking whether a value for a given feature was missing or not.

```{r 04-pipelines-045}
pom = PipeOpMissInd$new()
pon = PipeOpImputeHist$new(id = "imputer_num", param_vals = list(affect_columns = is.numeric))
pof = PipeOpImputeNewlvl$new(id = "imputer_fct", param_vals = list(affect_columns = is.factor))
imputer = pom %>>% pon %>>% pof
```

A learner can thus be equipped with automatic imputation of missing values by adding an imputation Pipeop.

```{r 04-pipelines-046}
polrn = PipeOpLearner$new(mlr_learners$get("classif.rpart"))
lrn = GraphLearner$new(graph = imputer %>>% polrn)
```

### Feature Engineering: `PipeOpMutate`

New features can be added or computed from a task using `r ref("PipeOpMutate")` .
The operator evaluates one or multiple expressions provided in an `alist`.
In this example, we compute some new features on top of the `iris` task.
Then we add them to the data as illustrated below:

```{r 04-pipelines-047}
pom = PipeOpMutate$new()

# Define a set of mutations
mutations = list(
  Sepal.Sum = ~ Sepal.Length + Sepal.Width,
  Petal.Sum = ~ Petal.Length + Petal.Width,
  Sepal.Petal.Ratio = ~ (Sepal.Length / Petal.Length)
)
pom$param_set$values$mutation = mutations
```

If outside data is required, we can make use of the `env` parameter.
Moreover, we provide an environment, where expressions are evaluated (`env` defaults to `.GlobalEnv`).

### Training on data subsets: `PipeOpChunk`

In cases, where data is too big to fit into the machine's memory, an often-used technique is to split the data into several parts.
Subsequently, the parts are trained on each part of the data.
After undertaking these steps, we aggregate the models.
In this example, we split our data into 4 parts using `r ref("PipeOpChunk")` .
Additionally, we create 4 `r ref("PipeOpLearner")`  POS, which are then trained on each split of the data.

```{r 04-pipelines-048}
chks = PipeOpChunk$new(4)
lrns = greplicate(PipeOpLearner$new(mlr_learners$get("classif.rpart")), 4)
```

Afterwards we can use `r ref("PipeOpClassifAvg")`  to aggregate the predictions from the 4 different models into a new one.

```{r 04-pipelines-049}
mjv = PipeOpClassifAvg$new(4)
```

We can now connect the different operators and visualize the full graph:

```{r 04-pipelines-050, fig.width=7.5, fig.height = 9}
pipeline = chks %>>% lrns %>>% mjv
pipeline$plot(html = TRUE) %>% visInteraction(zoomView = FALSE) # disable zoom
```

```{r 04-pipelines-051}
pipelrn = GraphLearner$new(pipeline)
pipelrn$train(task, train.idx)$
  predict(task, train.idx)$
  score()
```

### Feature Selection: `PipeOpFilter` and `PipeOpSelect`

The package `r mlr_pkg("mlr3filters")` contains many different `r ref("mlr3filters::Filter")`s that can be used to select features for subsequent learners.
This is often required when the data has a large amount of features.

A `PipeOp` for filters is `r ref("PipeOpFilter")`:

```{r 04-pipelines-052}
PipeOpFilter$new(mlr3filters::FilterInformationGain$new())
```

How many features to keep can be set using `filter_nfeat`, `filter_frac` and `filter_cutoff`.

Filters can be selected / de-selected by name using `r ref("PipeOpSelect")` .


## Advanced: An in-depth look into mlr3pipelines

This vignette is an in-depth introduction to `r cran_pkg("mlr3pipelines")`, the dataflow programming toolkit for machine learning in `R` using [`mlr3`](https://github.com/mlr-org/mlr3).
It will go through basic concepts and then give a few examples that both show the simplicity as well as the power and versatility of using `r cran_pkg("mlr3pipelines")`.

### What's the Point

Machine learning toolkits often try to abstract away the processes happening inside machine learning algorithms.
This makes it easy for the user to switch out one algorithm for another without having to worry about what is happening inside it, what kind of data it is able to operate on etc.
The benefit of using `mlr3`, for example, is that one can create a `Learner`, a `Task`, a `Resampling` etc. and use them for typical machine learning operations.
It is trivial to exchange individual components and therefore use, for example, a different `Learner` in the same experiment for comparison.

```{r 04-pipelines-053}
task = TaskClassif$new("iris", as_data_backend(iris), "Species")
lrn = mlr_learners$get("classif.rpart")
rsmp = mlr_resamplings$get("holdout")
resample(task, lrn, rsmp)
```

However, this modularity breaks down as soon as the learning algorithm encompasses more than just model fitting, like data preprocessing, ensembles or other meta models.
`r cran_pkg("mlr3pipelines")` takes modularity one step further than `mlr3`: it makes it possible to build individual steps within a `Learner` out of building blocks called **`PipeOp`s**.

### `PipeOp`: Pipeline Operators

The most basic unit of functionality within `r cran_pkg("mlr3pipelines")` is the **`PipeOp`**, short for "pipeline operator", which represents a trans-formative operation on input (for example a training dataset) leading to output.
It can therefore be seen as a generalized notion of a function, with a certain twist: `PipeOp`s behave differently during a "training phase" and a "prediction phase".
The training phase will typically generate a certain model of the data that is saved as internal state.
The prediction phase will then operate on the input data depending on the trained model.

An example of this behavior is the *principal component analysis* operation ("`PipeOpPCA`"):
During training, it will transform incoming data by rotating it in a way that leads to uncorrelated features ordered by their contribution to total variance.
It will *also* save the rotation matrix to be used during for new data.
This makes it possible to perform "prediction" with single rows of new data, where a row's scores on each of the principal components (the components of the training data!) is computed.

```{r 04-pipelines-054}
po = mlr_pipeops$get("pca")
po$train(list(task))[[1]]$data()
```

```{r 04-pipelines-055}
single_line_task = task$clone()$filter(1)
po$predict(list(single_line_task))[[1]]$data()
```

```{r 04-pipelines-056}
po$state
```

This shows the most important primitives incorporated in a `PipeOp`:
* **`$train()`**, taking a list of input arguments, turning them into a list of outputs, meanwhile saving a state in `$state`
* **`$predict()`**, taking a list of input arguments, turning them into a list of outputs, making use of the saved `$state`
* **`$state`**, the "model" trained with `$train()` and utilized during `$predict()`.

Schematically we can represent the `PipeOp` like so:

```{r 04-pipelines-057, echo = FALSE}
knitr::include_graphics("images/po_viz.png")
```

#### Why the `$state`

It is important to take a moment and notice the importance of a `$state` variable and the `$train()` / `$predict()` dichotomy in a `PipeOp`.
There are many preprocessing methods, for example scaling of parameters or imputation, that could in theory just be applied to training data and prediction / validation data separately, or they could be applied to a task before resampling is performed.
This would, however, be fallacious:

* The preprocessing of each instance of prediction data should not depend on the remaining prediction dataset.
A prediction on a single instance of new data should give the same result as prediction performed on a whole dataset.
* If preprocessing is performed on a task *before* resampling is done, information about the test set can leak into the training set.
Resampling should evaluate the generalization performance of the *entire* machine learning method, therefore the behavior of this entire method must only depend only on the content of the *training* split during resampling.

#### Where to Get `PipeOp`s

Each `PipeOp` is an instance of an "`R6`" class, many of which are provided by the `r cran_pkg("mlr3pipelines")` package itself.
They can be constructed explicitly ("`PipeOpPCA$new()`") or retrieved from the `mlr_pipelines` collection: `mlr_pipeops$get("pca")`.
The entire list of available `PipeOp`s, and some meta-information, can be retrieved using `as.data.table()`:

```{r 04-pipelines-058}
as.data.table(mlr_pipeops)[, c("key", "input.num", "output.num")]
```

When retrieving `PipeOp`s from the `mlr_pipeops` dictionary, it is also possible to give additional constructor arguments, such as an [id](#pipeop-ids-and-id-name-clashes) or [parameter values](#hyperparameters).

```{r 04-pipelines-059}
mlr_pipeops$get("pca", param_vals = list(rank. = 3))
```

### PipeOp Channels

#### Input Channels

Just like functions, `PipeOp`s can take multiple inputs.
These multiple inputs are always given as elements in the input list.
For example, there is a `PipeOpFeatureUnion` that combines multiple tasks with different features and "`cbind()`s" them together, creating one combined task.
When two halves of the `iris` task are given, for example, it recreates the original task:
```{r 04-pipelines-060}
iris_first_half = task$clone()$select(c("Petal.Length", "Petal.Width"))
iris_second_half = task$clone()$select(c("Sepal.Length", "Sepal.Width"))

pofu = mlr_pipeops$get("featureunion", innum = 2)

pofu$train(list(iris_first_half, iris_second_half))[[1]]$data()
```

Because `PipeOpFeatureUnion` effectively takes two input arguments here, we can say it has two **input channels**.
An input channel also carries information about the *type* of input that is acceptable.
The input channels of the `pofu` object constructed above, for example, each accept a `Task` during training and prediction.
This information can be queried from the `$input` slot:
```{r 04-pipelines-061}
pofu$input
```

Other `PipeOp`s may have channels that take different types during different phases.
The `backuplearner` `PipeOp`, for example, takes a `NULL` and a `Task` during training, and a `Prediction` and a `Task` during prediction:

```{r 04-pipelines-062}
## TODO this is an important case to handle here, do not delete unless there is a better example.
## mlr_pipeops$get("backuplearner")$input
```

#### Output Channels

Unlike the typical notion of a function, `PipeOp`s can also have multiple **output channels**.
`$train()` and `$predict()` always return a list, so certain `PipeOp`s may return lists with more than one element.
Similar to input channels, the information about the number and type of outputs given by a `PipeOp` is available in the `$output` slot.
The `chunk` PipeOp, for example, chunks a given `Task` into subsets and consequently returns multiple `Task` objects, both during training and prediction.
The number of output channels must be given during construction through the `outnum` argument.

```{r 04-pipelines-063}
mlr_pipeops$get("chunk", outnum = 3)$output
```

Note that the number of output channels during training and prediction is the same.
A schema of a `PipeOp` with two output channels:

```{r 04-pipelines-064, echo = FALSE}
knitr::include_graphics("images/po_multi_alone.png")
```

#### Channel Configuration

Most `PipeOp`s have only one input channel (so they take a list with a single element), but there are a few with more than one;
In many cases, the number of input or output channels is determined during construction, e.g. through the `innum` / `outnum` arguments.
The `input.num` and `output.num` columns of the `mlr_pipeops`-table [above](#where-to-get-pipeops) show the default number of channels, and `NA` if the number depends on a construction argument.

The default printer of a `PipeOp` gives information about channel names and types:

```{r 04-pipelines-065}
## mlr_pipeops$get("backuplearner")
```

### `Graph`: Networks of `PipeOp`s

#### Basics

What is the advantage of this tedious way of declaring input and output channels and handling in/output through lists?
Because each `PipeOp` has a known number of input and output channels that always produce or accept data of a known type, it is possible to network them together in **`Graph`**s.
A `Graph` is a collection of `PipeOp`s with "edges" that mandate that data should be flowing along them.
Edges always pass between `PipeOp` *channels*, so it is not only possible to explicitly prescribe which position of an input or output list an edge refers to, it makes it possible to make different components of a `PipeOp`'s output flow to multiple different other `PipeOp`s, as well as to have a `PipeOp` gather its input from multiple other `PipeOp`s.

A schema of a simple graph of `PipeOp`s:
```{r 04-pipelines-066, echo = FALSE}
knitr::include_graphics("images/po_multi_viz.png")
```

A `Graph` is empty when first created, and `PipeOp`s can be added using the **`$add_pipeop()`** method.
The **`$add_edge()`** method is used to create connections between them.
While the printer of a `Graph` gives some information about its layout, the most intuitive way of visualizing it is using the `$plot()` function.

```{r 04-pipelines-067}
gr = Graph$new()
gr$add_pipeop(mlr_pipeops$get("scale"))
gr$add_pipeop(mlr_pipeops$get("subsample", param_vals = list(frac = 0.1)))
gr$add_edge("scale", "subsample")
```

```{r 04-pipelines-068}
print(gr)
```

```{r 04-pipelines-069, fig.width = 8, fig.height = 8}
gr$plot(html = TRUE)
```

A `Graph` itself has a **`$train()`** and a **`$predict()`** method that accept some data and propagate this data through the network of `PipeOp`s.
The return value corresponds to the output of the `PipeOp` output channels that are not connected to other `PipeOp`s.

```{r 04-pipelines-070}
gr$train(task)[[1]]$data()
```

```{r 04-pipelines-071}
gr$predict(single_line_task)[[1]]$data()
```

The collection of `PipeOp`s inside a `Graph` can be accessed through the **`$pipeops`** slot.
The set of edges in the Graph can be inspected through the **`$edges`** slot.
It is possible to modify individual `PipeOps` and edges in a Graph through these slots, but this is not recommended because no error checking is performed and it may put the `Graph` in an unsupported state.

#### Networks

The example above showed a linear preprocessing pipeline, but it is in fact possible to build true "graphs" of operations, as long as no loops are introduced^[It is tempting to denote this as a "directed acyclic graph", but this would not be entirely correct because edges run between channels of `PipeOp`s, not `PipeOp`s themselves.].
`PipeOp`s with multiple output channels can feed their data to multiple different subsequent `PipeOp`s, and `PipeOp`s with multiple input channels can take results from different `PipeOp`s.
When a `PipeOp` has more than one input / output channel, then the `Graph`'s `$add_edge()` method needs an additional argument that indicates which channel to connect to.
This argument can be given in the form of an integer, or as the name of the channel.

The following constructs a `Graph` that copies the input and gives one copy each to a "scale" and a "pca" `PipeOp`.
The resulting columns of each operation are put next to each other by "featureunion".

```{r 04-pipelines-072}
gr = Graph$new()$
  add_pipeop(mlr_pipeops$get("copy", outnum = 2))$
  add_pipeop(mlr_pipeops$get("scale"))$
  add_pipeop(mlr_pipeops$get("pca"))$
  add_pipeop(mlr_pipeops$get("featureunion", innum = 2))

gr$
  add_edge("copy", "scale", src_channel = 1)$        ## designating channel by index
  add_edge("copy", "pca", src_channel = "output2")$  ## designating channel by name
  add_edge("scale", "featureunion", dst_channel = 1)$
  add_edge("pca", "featureunion", dst_channel = 2)

gr$plot(html = TRUE)
```
```{r 04-pipelines-073}
gr$train(iris_first_half)[[1]]$data()
```

#### Syntactic Sugar

Although it is possible to create intricate `Graphs` with edges going all over the place (as long as no loops are introduced), there is usually a clear direction of flow between "layers" in the `Graph`.
It is therefore convenient to build up a `Graph` from layers, which can be done using the **`%>>%`** ("double-arrow") operator.
It takes either a `PipeOp` or a `Graph` on each of its sides and connects all of the outputs of its left-hand side to one of the inputs each of its right-hand side--the number of inputs therefore must match the number of outputs.
Together with the **`gunion()`** operation, which takes `PipeOp`s or `Graph`s and arranges them next to each other akin to a (disjoint) graph union, the above network can more easily be constructed as follows:

```{r 04-pipelines-074}
gr = mlr_pipeops$get("copy", outnum = 2) %>>%
  gunion(list(mlr_pipeops$get("scale"), mlr_pipeops$get("pca"))) %>>%
  mlr_pipeops$get("featureunion", innum = 2)

gr$plot(html = TRUE)
```

#### `PipeOp` IDs and ID Name Clashes

`PipeOp`s within a graph are addressed by their **`$id`**-slot.
It is therefore necessary for all `PipeOp`s within a `Graph` to have a unique `$id`.
The `$id` can be set during or after construction, but it should not directly be changed after a `PipeOp` was inserted in a `Graph`.
At that point, the **`$set_names()`**-method can be used to change `PipeOp` ids.

```{r 04-pipelines-075, error = TRUE}
po1 = mlr_pipeops$get("scale")
po2 = mlr_pipeops$get("scale")
po1 %>>% po2  ## name clash
```

```{r 04-pipelines-076}
po2$id = "scale2"
gr = po1 %>>% po2
gr
```

```{r 04-pipelines-077}
## Alternative ways of getting new ids:
mlr_pipeops$get("scale", id = "scale2")
PipeOpScale$new(id = "scale2")
```

```{r 04-pipelines-078, error = TRUE}
## sometimes names of PipeOps within a Graph need to be changed
gr2 = mlr_pipeops$get("scale") %>>% mlr_pipeops$get("pca")
gr %>>% gr2
```

```{r 04-pipelines-079}
gr2$set_names("scale", "scale3")
gr %>>% gr2
```

### Learners in Graphs, Graphs in Learners

The true power of `r cran_pkg("mlr3pipelines")` derives from the fact that it can be integrated seamlessly with `mlr3`.
Two components are mainly responsible for this:

* **`PipeOpLearner`**, a `PipeOp` that encapsulates a `mlr3` `Learner` and creates a `PredictionData` object in its `$predict()` phase
* **`GraphLearner`**, a `mlr3` `Learner` that can be used in place of any other `mlr3` `Learner`, but which does prediction using a `Graph` given to it

Note that these are dual to each other: One takes a `Learner` and produces a `PipeOp` (and by extension a `Graph`); the other takes a `Graph` and produces a `Learner`.

#### `PipeOpLearner`

The `PipeOpLearner` is constructed using a `mlr3` `Learner` and will use it to create `PredictionData` in the `$predict()` phase.
The output during `$train()` is `NULL`.
It can be used after a preprocessing pipeline, and it is even possible to perform operations on the `PredictionData`, for example by averaging multiple predictions or by using the "`PipeOpBackupLearner`" operator to impute predictions that a given model failed to create.

The following is a very simple `Graph` that performs training and prediction on data after performing principal component analysis.

```{r 04-pipelines-080}
gr = mlr_pipeops$get("pca") %>>% mlr_pipeops$get("learner",
  mlr_learners$get("classif.rpart"))
```
```{r 04-pipelines-081}
gr$train(task)
gr$predict(task)
```

#### `GraphLearner`

Although a `Graph` has `$train()` and `$predict()` functions, it can not be used directly in places where `mlr3` `Learners` can be used like resampling or benchmarks.
For this, it needs to be wrapped in a `GraphLearner` object, which is a thin wrapper that enables this functionality.
The resulting `Learner` is extremely versatile, because every part of it can be modified, replaced, parameterized and optimized over.
Resampling the graph above can be done the same way that resampling of the `Learner` was performed in the [introductory example](#whats-the-point).

```{r 04-pipelines-082}
lrngrph = GraphLearner$new(gr)
resample(task, lrngrph, rsmp)
```

### Hyperparameters

`r cran_pkg("mlr3pipelines")` relies on the [`paradox`](https://paradox.mlr-org.com) package to provide parameters that can modify each `PipeOp`'s behavior.
`paradox` parameters provide information about the parameters that can be changed, as well as their types and ranges.
They provide a unified interface for benchmarks and parameter optimization ("tuning").
For a deep dive into `paradox`, see the [mlr3book](https://mlr3book.mlr-org.com).

The `ParamSet`, representing the space of possible parameter configurations of a `PipeOp`, can be inspected by accessing the **`$param_set`** slot of a `PipeOp` or a `Graph`.

```{r 04-pipelines-083}
op_pca = mlr_pipeops$get("pca")
op_pca$param_set
```

To set or retrieve a parameter, the **`$param_set$values`** slot can be accessed.
Alternatively, the `param_vals` value can be given during construction.

```{r 04-pipelines-084}
op_pca$param_set$values$center = FALSE
op_pca$param_set$values
```

```{r 04-pipelines-085}
op_pca = mlr_pipeops$get("pca", param_vals = list(center = TRUE))
op_pca$param_set$values
```

Each `PipeOp` can bring its own individual parameters which are collected together in the `Graph`'s `$param_set`.
A `PipeOp`'s parameter names are prefixed with its `$id` to prevent parameter name clashes.

```{r 04-pipelines-086}
gr = op_pca %>>% mlr_pipeops$get("scale")
gr$param_set
```

```{r 04-pipelines-087}
gr$param_set$values
```

Both `PipeOpLearner` and `GraphLearner` preserve parameters of the objects they encapsulate.

```{r 04-pipelines-088}
op_rpart = mlr_pipeops$get("learner", mlr_learners$get("classif.rpart"))
op_rpart$param_set
```

```{r 04-pipelines-089}
glrn = GraphLearner$new(gr %>>% op_rpart)
glrn$param_set
```
