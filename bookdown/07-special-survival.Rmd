## Survival Analysis {#survival}

Survival analysis is a sub-field of supervised machine learning in which the aim is to predict the survival distribution of a given individual.
Arguably the main feature of survival analysis is that unlike classification and regression, learners are trained on two features:

1. the time until the event takes place
2. the event type: either censoring or death.

At a particular time-point, an individual is either: alive, dead, or censored.
Censoring occurs if it is unknown if an individual is alive or dead.
For example, say we are interested in patients in hospital and every day it is recorded if they are alive or dead, then after a patient leaves it is unknown if they are alive or dead, hence they are censored.
If there was no censoring, then ordinary regression analysis could be used instead.
Furthermore, survival data contains solely positive values and therefore needs to be transformed to avoid biases.

Note that survival analysis accounts for both censored and uncensored observations while adjusting respective model parameters.

The package `r mlr_pkg("mlr3proba")` extends `r mlr_pkg("mlr3")` with the following objects for survival analysis:

* `r ref("mlr3proba::TaskSurv", text = "TaskSurv")` to define (censored) survival tasks
* `r ref("mlr3proba::LearnerSurv", text = "LearnerSurv")` as base class for survival learners
* `r ref("mlr3proba::PredictionSurv", text = "PredictionSurv")` as specialized class for `r ref("Prediction")` objects
* `r ref("mlr3proba::MeasureSurv", text = "MeasureSurv")` as specialized class for performance measures

For a good introduction to survival analysis see *Modelling Survival Data in Medical Research* [@Collett2014].

### TaskSurv

Unlike `TaskClassif` and `TaskRegr` which have a single 'target' argument, `TaskSurv` mimics the
`survival::Surv` object and has three-four target arguments (dependent on censoring type)

```{r 07-special-survival-001}
library("mlr3")
library("mlr3proba")
library("survival")

TaskSurv$new(id = "interval_censored", backend = survival::bladder2[,-c(1, 7)],
                    time = "start", time2 = "stop", type = "interval2")

# type = "right" is default
task = TaskSurv$new(id = "right_censored", backend = survival::rats,
             time = "time", event = "status", type = "right")

print(task)

# the target column is a survival object:
head(task$truth())

# kaplan-meier plot
library("mlr3viz")
autoplot(task)
```

### Predict Types - crank, lp, and distr

Every `PredictionSurv` object can predict one or more of:

* `lp` - Linear predictor calculated as the fitted coefficients multiplied by the test data.
* `distr` - Predicted survival distribution, either discrete or continuous. Implemented in `r cran_pkg("distr6")`.
* `crank` - Continuous risk ranking.

`lp` and `crank` can be used with measures of discrimination such as the concordance index.
Whilst `lp` is a specific mathematical prediction, `crank` is any continuous ranking that identifies who is more or less likely to experience the event.
So far the only implemented learner that only returns a continuous ranking is `surv.svm`.
If a `PredictionSurv` returns an `lp` then the `crank` is identical to this.
Otherwise `crank` is calculated as the expectation of the predicted survival distribution.
Note that for linear proportional hazards models, the ranking (but not necessarily the `crank` score itself) given by `lp` and the expectation of `distr`, is identical.

The example below uses the `r ref("mlr_tasks_rats", text = "rats")` task shipped with `r mlr_pkg("mlr3proba")`.

```{r 07-special-survival-002}
task = mlr_tasks$get("rats")
learn = lrn("surv.coxph")

train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)

learn$train(task, row_ids = train_set)
prediction = learn$predict(task, row_ids = test_set)

print(prediction)
```

### Composition

Finally we take a look at the `PipeOp`s implemented in `r mlr_pkg("mlr3proba")`, which are used for composition of predict types.
For example, a predict linear predictor does not have a lot of meaning by itself, but it can be composed into a survival distribution.
See `r mlr_pkg("mlr3pipelines")` for full tutorials and details on `PipeOp`s.


```{r 07-special-survival-003}
library(mlr3pipelines)
library(mlr3learners.gbm)
# PipeOpDistrCompositor - Train one model with a baseline distribution,
# (Kaplan-Meier or Nelson-Aalen), and another with a predicted linear predictor.
task = mlr_tasks$get("rats")
leaner_lp = lrn("surv.gbm", bag.fraction = 1, n.trees = 50L)
leaner_distr = lrn("surv.kaplan")
prediction_lp = leaner_lp$train(task)$predict(task)
prediction_distr = leaner_distr$train(task)$predict(task)
prediction_lp$distr

# Doesn't need training. Base = baseline distribution. ph = Proportional hazards.

pod = po("distrcompose", param_vals = list(form = "ph", overwrite = FALSE))
prediction = pod$predict(list(base = prediction_distr, pred = prediction_lp))$output

# Now we have a predicted distr!

prediction$distr

# This can all be simplified by using the distrcompose wrapper

gbm.distr = distrcompositor(learner = lrn("surv.gbm", bag.fraction = 1, n.trees = 50L),
                             estimator = "kaplan",
                             form = "aft",
                             overwrite = FALSE)
gbm.distr$train(task)$predict(task)
```

### Benchmark Experiment

Finally, we conduct a small benchmark study on the `r ref("mlr_tasks_rats", text = "rats")` task using some of the integrated survival learners:

```{r 07-special-survival-004}
library(mlr3learners)

task = mlr_tasks$get("rats")

# some integrated learners
learners = lrns(c("surv.coxph", "surv.kaplan", "surv.ranger"))
print(learners)

# Harrell's C-Index for survival
measure = msr("surv.harrellC")
print(measure)

set.seed(1)
bmr = benchmark(benchmark_grid(task, learners, rsmp("cv", folds = 3)))
bmr$aggregate(measure)
autoplot(bmr, measure = measure)
```

The experiment indicates that both the Cox PH and the random forest have better discrimination than the Kaplan-Meier baseline estimator, but that the machine learning random forest is not consistently better than the interpretable Cox PH.
