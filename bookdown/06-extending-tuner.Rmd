## Adding new Tuners {#extending-tuners}

In this section, we show how to implement a custom tuner for `mlr3tuning`. 

## Adding a new Tuner via bbotk

The `bbotk` package provides black box optimization algorithms. 
If the new custom tuner is not restricted to hyperparameter tuning, it should be implemented in `bbotk`.
The optimizer is later transformed to a tuner. 

1. Check the tuner does not already exist as a `bbotk::Optimizer` or `mlr3tuning::Tuner`.
2. Add [`.optimize`](#tuner-optimize) private method to optimizer.
3. Optionally, overwrite the default [`.assign_result`](#tuner-add-result) private method.
4. Use the [`TunerFromOptimizer`](#tuner-from-optimizer) class in `mlr3tuning` to transform the `bbotk::Optimizer` to a `mlr3tuning::Tuner`.
5. Add [unit tests](#tuner-test) for the optimizer and the tuner.
6. Open a new pull request for the [`bbotk::Optimizer`](https://github.com/mlr-org/bbotk/pulls) and a second one for the [`mlr3tuning::Tuner`](https://github.com/mlr-org/mlr3tuning/pulls). 

## Adding a new Tuner via mlr3tuning

If the new custom tuner is to only usable for hyperparameter tuning, it should be directly implemented in `mlr3tuning`.

1. Check the tuner does not already exist as a `bbotk::Optimizer` or `mlr3tuning::Tuner`.
2. Add [`.optimize`](#tuner-optimize) private method to tuner.
3. Optionally, overwrite the default [`.assign_result`](#tuner-add-result) private method.
5. Add [unit tests](#tuner-test).
6. Open a new pull request for the [`bbotk::Optimizer`](https://github.com/mlr-org/bbotk/pulls) and a second one for the [`mlr3tuning::Tuner`](https://github.com/mlr-org/mlr3tuning/pulls). 

### Optimize method {#tuner-optimize}

The `$.optimize()` private method takes an instance, proposses new points and calls the `$eval_batch()` method of the instance to evaluate them. 

Optimization functions from external packages usually take an objective function as an argument. 
In this case, you can pass `inst$objective_function` which internally calls `$eval_batch()`.
Check out [`OptimizerGenSA`](https://github.com/mlr-org/bbotk/blob/master/R/OptimizerGenSA.R) for an example.

### Assign result method {#tuner-add-result}

The default `$.assign_result()` private method simply obtains the best performing result from the archive.
The default method can be overwritten if the new tuner determines the result of optimization in a different way.
The new function must call the `$assign_result()` method of the instance to write the final result to the instance.

### Transform optimizer to tuner {#tuner-from-optimizer}

The `TunerFromOptimizer` class transforms a `bbotk::Optimizer` to a `mlr3tuning::Tuner`.
Just add the `bbootk::Optimizer` to the `optimizer` field. 
See `TunerRandomSearch`() for an example.

### Add unit tests {#tuner-test}

The new custom tuner should be thoroughly tested with unit tests.
`mlr3tuning::Tuner`s can be tested with the `test_tuner()` helper function.
If you added the Tuner via a `bbootk::Optimizer`, you should additionally test the `bbotk::Optimizer` with the `test_optimizer()` helper function.
