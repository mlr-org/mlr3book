## Adding new Tuners {#extending-tuners}

In this section, we show how to implement a custom tuner for `r mlr_pkg("mlr3tuning")`. 
There are two ways to implement a new tuner:
a ) If the new custom tuner is not restricted to hyperparameter tuning, it should be implemented in `r mlr_pkg("bbotk")` as a `bbotk::Optimizer`.
The `r mlr_pkg("bbotk")` package provides black box optimization algorithms which can be easily transformed to a `mlr3tuning::Tuner` later.
b) If the new custom tuner is only usable for hyperparameter tuning, it should be directly implemented in `r mlr_pkg("mlr3tuning")` as a `mlr3tuning::Tuner`.

### Adding a new Tuner {#extending-tuners-summary}

This is a summary of steps for adding a new tuner. 
The fifth step is only required if the new tuner is added via `r mlr_pkg("bbotk")`.

1. Check the tuner does not already exist as a [`bbotk::Optimizer`](https://github.com/mlr-org/bbotk/tree/master/R) or [`mlr3tuning::Tuner`](https://github.com/mlr-org/mlr3tuning/tree/master/R) in the GitHub repositories.
2. Use one of the existing optimizers / tuners as a [template](#tuner-template).
3. Overwrite the [`.optimize`](#tuner-optimize) private method of the optimizer / tuner.
4. Optionally, overwrite the default [`.assign_result`](#tuner-add-result) private method.
5. Use the [`mlr3tuning::TunerFromOptimizer`](#tuner-from-optimizer) class to transform the `bbotk::Optimizer` to a `mlr3tuning::Tuner`.
6. Add [unit tests](#tuner-test) for the tuner and optionally for the optimizer.
7. Open a new pull request for the [`mlr3tuning::Tuner`](https://github.com/mlr-org/mlr3tuning/pulls) and optionally a second one for the [`bbotk::Optimizer`](https://github.com/mlr-org/bbotk/pulls).

### Template {#tuner-template}

If the new custom tuner is implemented via `r mlr_pkg("bbotk")`, use one of the existing optimizer as a template e.g. [`bbotk::OptimizerRandomSearch`](https://github.com/mlr-org/bbotk/blob/master/R/OptimizerRandomSearch.R). There are currently only two tuners that are not based on a `bbotk::Optimizer`: [`mlr3hyperband::TunerHyperband`](https://github.com/mlr-org/mlr3hyperband/blob/master/R/TunerHyperband.R) and [`mlr3tuning::TunerIrace`](https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerIrace.R). Both are rather complex but you can still use the documentation and class structure as a template. The following steps are identical for optimizers and tuners.

Rewrite the meta information in the documentation and create a new class name.
Scientific sources can be added in `R/bibentries.R` which are added under `@source` in the documentation.
The example and dictionary sections of the documentation are auto-generated based on the `@templateVar id <tuner_id>`.
Change the parameter set of the optimizer / tuner and document them under `@section Parameters`.
Do not forget to change `mlr_optimizers$add()` / `mlr_tuners$add()` in the last line which adds the optimizer / tuner to the dictionary.

### Optimize method {#tuner-optimize}

The `$.optimize()` private method takes an instance, proposes new points and calls the `$eval_batch()` method of the instance to evaluate them.
Usually, this is the main part of the custom tuner.
Optimization functions from external packages usually take an objective function as an argument. 
In this case, you can pass `inst$objective_function` which internally calls `$eval_batch()`.
Check out [`OptimizerGenSA`](https://github.com/mlr-org/bbotk/blob/master/R/OptimizerGenSA.R) for an example.

### Assign result method {#tuner-add-result}

The default `$.assign_result()` private method simply obtains the best performing result from the archive.
The default method can be overwritten if the new tuner determines the result of the optimization in a different way.
The new function must call the `$assign_result()` method of the instance to write the final result to the instance.
See [`mlr3tuning::TunerIrace`](https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerIrace.R) for an implementation of `$.assign_result()`.

### Transform optimizer to tuner {#tuner-from-optimizer}

This step is only needed if you implement via `r mlr_pkg("bbotk")`.
The `mlr3tuning::TunerFromOptimizer` class transforms a `bbotk::Optimizer` to a `mlr3tuning::Tuner`.
Just add the `bbotk::Optimizer` to the `optimizer` field.
See [`mlr3tuning::TunerRandomSearch`](https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerRandomSearch.R) for an example.

### Add unit tests {#tuner-test}

The new custom tuner should be thoroughly tested with unit tests.
`mlr3tuning::Tuner`s can be tested with the `test_tuner()` helper function.
If you added the Tuner via a `bbotk::Optimizer`, you should additionally test the `bbotk::Optimizer` with the `test_optimizer()` helper function.
