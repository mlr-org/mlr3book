---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Basics {#basics}

Chương này sẽ hướng dẫn những blocks cơ bản, R6 classes, và hoạt động của `r mlr_pkg("mlr3")` với machine learning.

Một quy trình machine learning điển hình trông như thế này:

```{r 02-basics-001, echo = FALSE}
knitr::include_graphics("images/ml_abstraction.png")
```


Dữ liệu, cái mà `r mlr_pkg("mlr3")` gói gọn trong [tasks](#tasks), được chia thành tập training và tập test một cách riêng rẽ

Chúng ta thường thích những mô hình mà tổng quát cho dữ liệu mới hơn là những mô hình chỉ tốt với tập dữ liệu training, và việc phân chia dữ liệu test cho phép đánh giá mô hình một cách khách quan.
Dữ liệu training được cung cấp cho 1 thuật toán ML, cái mà chúng ta gọi là một [learner](#learners) in `r mlr_pkg("mlr3")`.

[Learner](#learners) sử dụng dữ liệu training để xây dựng mô hình dựa trên mối quan hệ giữa thuộc tính đầu vào (input feature) để dự báo đầu ra.

Mô hình này sau đó cung cấp [predictions](#predicting) cho dữ liệu test, cái mà so sánh với dữ liệu thực tế để đánh giá chất lượng mô hình


`r mlr_pkg("mlr3")` cung cấp 1 số [measures](#measure) khác nhau để lượng hóa thế nào là một mô hình tốt dựa trên sự khác biệt giữa giá trị dự vào và giá trị thực tế.
Thông thường, [measures](#measure) này là một numeric score.


Quá trình chia dữ liệu thành tập training và test, xây dựng mô hình, đánh giá nó có thể lặp lại nhiều lần, mỗi lần như vậy gọi là [resampling](#resampling). Trong đó, mẫu training và test được thay đổi khác nhau dựa trên dữ liệu gốc ban đầu.
Nhiều lần lặp lại [resampling iterations](#resampling) như vậy cho phép chúng ta đánh giá 1 cách tổng quát về loại mô hình cụ thể vì nó được test trên các điều kiện khác nhau và ít có khả năng gặp may hoặc không may với 1 mẫu cá biệt.


Trong nhiều trường hợp, quy trình đơn giản này không đủ để giải quyết với dữ liệu thực tế, bởi còn nhiều bước như chuẩn hóa (normalization), xử lý missing, hay feature selection.
Chúng tôi sẽ đề cập những công việc phức tạp hơn này ở phần sau của sách.

Chương này gồm 1 số topics nhỏ sau:

[**Tasks**](#tasks)

Tasks đóng gói dữ liệu với thông tin meta, như biến mục tiêu là.

Chúng tôi hướng dẫn cách thức thực hiện

* Tiếp cận task đã được định nghĩa trước [predefined tasks](#tasks-predefined),
* Chỉ rõ [task type](#tasks-types),
* Tạo một [task](#tasks-creation),
* Làm việc với một task's [API](#tasks-api),
* Gán vai trò [rows and collums](#tasks-roles) cho một task,
* thực hiện các biến đổi [task mutators](#tasks-mutators), và
* [retrieve the data](#tasks-retrieved) cái mà được lưu trong 1 task.

[**Learners**](#learners)

[Learners](#learners) gói gọn các thuật toán ML để train mô hình và đưa ra dự đoán cho một `r ref("mlr3::Task")`.

Chúng được cung cấp bởi R và nhiều packages khác.

Chúng tôi sẽ hướng dẫn:

* tiếp cận danh sách [classification and regression learners](#learners-predefined) đi kèm với mlr3 và cách tìm kiếm một learner cụ thể
* tiếp cận danh sách tham số [hyperparameter values](#learners-predefined) của 1 learner và chỉnh sửa chúng

Cách chỉnh sửa và mở rộng learners được đề cập trong phần [advanced technical section](#ext-learner).

[**Train and predict**](#train-predict)

Phân này minh họa cách sử dụng [tasks](#tasks) và [learners](#learners) để huấn luyện một mô hình và đưa ra dự báo [predictions](#predicting) với tập dữ liệu mới 

Các bước bao gồm


* set up [tasks](#train-predict-objects) và [learners](#train-predict-objects) đúng cách,
* set up [train and test splits](#split-data) cho 1 task,
* [train](#training) learner dựa trên tập training để ra 1 mô hình
* tạo 1 dự báo [predictions](#predicting) dựa trên tập test và
* đánh giá hiệu quả của mô hình [performance](#measure) bằng việc so sánh giá trị dự báo và giá trị thực.

[**Resampling**](#resampling)

[Resampling](#resampling) là phương pháp chia training và test.

Các bước như:

* access and select [resampling strategies](#resamp-settings),
* khởi tạo [split into training and test sets](#resamp-inst) bằng cách lấy mẫu lại và
* thực hiện lấy mẫu lại để có được [results](#resamp-exec).

Thông tin thêm về resampling có thể tìm trong phần [nested resampling](#nested-resampling) trong chương [model optimization](#model-optim).


[**Benchmarking**](#benchmarking)

[Benchmarking](#benchmarking) được sử dụng để so sánh performance của những mô hình khác nhau, ví dụ mô hình đã được huấn luyện và những learners khác, tasks khác, resampling schemes khác.

Các bước như:

* tạo 1 [benchmarking design](#bm-design),
* [execute a design](#bm-exec) và tổng hợp kết quả và
* convert benchmarking objects to [resample objects](#bm-resamp). 


[**Binary classification**](#binary)

[Binary classification](#binary) là 1 trường hợp đặc biệt của bài toán phân loại với biến mục tiêu chỉ có 2 giá trị

Trong phần này, xem xét áp dụng bổ sung

* [ROC curves](#binary-roc) và ngưỡng để so sánh dự báo 1 classs với cái khác và
* ngưỡng tuning (WIP)


Trước khi chúng ta đi vào chi tiết cách sử dụng `r mlr_pkg("mlr3")` cho ML, chúng tôi giới thiệu ngắn gọn về R6 vì đây là 1 phần mới của R

`r mlr_pkg("mlr3")` dựa rất nhiều vào R6 và tất cả các blocks cơ bản được tạo bởi R6 classes

* [tasks](#tasks),
* [learners](#learners),
* [measures](#measures), and
* [resamplings](#resampling).

## Quick R6 Intro for Beginners {#r6}

R6 is one of R's more recent dialects for object-oriented programming (OO).
It addresses shortcomings of earlier OO implementations in R, such as S3, which we used in `r mlr_pkg("mlr")`.
If you have done any object-oriented programming before, R6 should feel familiar.
We focus on the parts of R6 that you need to know to use `r mlr_pkg("mlr3")` here.

* Objects are created by calling the constructor of an `R6Class()` object, specifically the `$new()` method.
  For example, `foo = Foo$new(bar = 1)` creates a new object of class `Foo`, setting the `bar` argument of the constructor to `1`.
* Classes have mutable state, which is encapsulated in their fields, which can be accessed through the dollar operator.
  We can access the `bar` value in the `Foo` class through `foo$bar` and set its value by assigning the field, e.g. `foo$bar = 2`.
* In addition to fields, objects expose methods that may allow to inspect the object's state, retrieve information, or perform an action that may change the internal state of the object.
  For example, the `$train` method of a learner changes the internal state of the learner by building and storing a trained model, which can then be used to make predictions given data.
* Objects can have public and private fields and methods.
  In `r mlr_pkg("mlr3")`, you can only access the public variables and methods.
  Private fields and methods are only relevant to change or extend `r mlr_pkg("mlr3")`.
* R6 variables are references to objects rather then the actual objects, which are stored in an environment.
  For example `foo2 = foo` does not create a copy of `foo` in `foo2`, but another reference to the same actual object.
  Setting `foo$bar = 3` will also change `foo2$bar` to `3` and vice versa.
* To copy an object, use the `$clone()` method and the `deep = TRUE` argument for nested objects, for example `foo2 = foo$clone(deep = TRUE)`.

For more details on R6, have a look at the [R6 vignettes](https://r6.r-lib.org/).

## Tasks {#tasks}

Tasks là đối tượng của dữ liệu và thông tin meta bổ sung cho bài toán ML.
Meta-data có thể là tên của biến mục tiêu với bài toán supervised ML, hay loại dữ liệu (e.g. a _spatial_ or _survival_).
Thông tin này được sử dụng cho các hoạt động cụ thể để thực hiện một task


### Task Types {#tasks-types}

Để tạo 1 task từ 1 đối tượng `r ref("data.frame()")` or `r ref("data.table()")`, loại task cần phải được chỉ định:


**Classification Task**: The target is a label (stored as `character()`or`factor()`) with only few distinct values.
<br/>→ `r ref("mlr3::TaskClassif")`

**Regression Task**: The target is a numeric quantity (stored as `integer()` or `double()`).
<br/>→ `r ref("mlr3::TaskRegr")`

**Survival Task**: The target is the (right-censored) time to an event.
<br/>→ `r ref("mlr3proba::TaskSurv")` in add-on package `r mlr_pkg("mlr3proba")`

**Ordinal Regression Task**: The target is ordinal.
<br/>→ `r ref("mlr3ordinal::TaskOrdinal")` in add-on package `r mlr_pkg("mlr3ordinal")`

**Cluster Task**: An unsupervised task type; there is no target and the aim is to identify similar groups within the feature space.
<br/>→ Not yet implemented

**Spatial Task**: Observations in the task have spatio-temporal information (e.g. coordinates).
<br/>→ Not yet implemented, but started in add-on package `r mlr_pkg("mlr3spatiotemporal")`

### Task Creation {#tasks-creation}

Như một ví dụ, chúng ta sẽ tạo 1 regression task sử dụng dữ liệu `mtcars` từ package `datasets` và dự báo cho biến mục tiêu `"mpg"` (miles per gallon).
Chúng ta chỉ dùng 2 features đầu tiên của dữ liệu cho ngắn gọn.

Đầu tiên, load và chuẩn bị dữ liệu.

```{r 02-basics-002}
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
```

Tiếp theo, tạo task sử dụng hàm tạo với regression task (`TaskRegr$new`) và cung cấp thông tin:

1. `id`: 1 định danh tùy ý cho task, được sử dụng trong plots và summaries.
2. `backend`: Tham số này cho phép kiểm soát chi tiết cách tiếp cận dữ liệu. Ở đây, chúng ta chỉ đơn giản là cung cấp dữ liệu cái mà sẽ được tự động chuyển thành `r ref("DataBackendDataTable")`. Chúng ta cũng có thể xây dựng `r ref("DataBackend")` bằng tay.
3. `target`: tên của biến mục tiêu


```{r 02-basics-003}
library(mlr3)

task_mtcars = TaskRegr$new(id = "cars", backend = data, target = "mpg")
print(task_mtcars)
```

Hàm `print()` đưa ra khái quát ngắn gọn cho task:
Nó có `r task_mtcars$nrow` quan sát và `r task_mtcars$ncol` cột với `r length(task_mtcars$feature_names)` features

Chúng ta cũng có thể vẽ biểu đồ của task sử dụng `r mlr_pkg("mlr3viz")` package, cái mà cung cấp thông tin cơ bản về biểu đồ và thuộc tính của nó


```{r 02-basics-004}
library(mlr3viz)
autoplot(task_mtcars, type = "pairs")
```

### Predefined tasks {#tasks-predefined}

`r mlr_pkg("mlr3")` lưu một số ML tasks được định nghĩa trước.
Tất cả tasks được lưu trong R6 `r ref("Dictionary")` với tên (a key-value store)  `r ref("mlr_tasks")`.
Khi in cần cung cấp keys (ở đây là tên của datasets):


```{r 02-basics-005}
mlr_tasks
```

Chúng ta cũng có thể lấy thêm thông tin từ tasks ví dụ bằng cách chuyển đổi dictionary sang `data.table()` object:


```{r 02-basics-006}
library(data.table)
as.data.table(mlr_tasks)
```

Để lấy 1 task từ dictionary, có thể sử dụng `$get()` method từ `mlr_tasks` class và trả về giá trị tới 1 object mới

Ví dụ, sử dụng [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) với loại task classif đã được định nghĩa săn:

```{r 02-basics-007}
task_iris = mlr_tasks$get("iris")
print(task_iris)
```

Cách khác, bạn cũng có thể sử dụng hàm `r ref("tsk()")`, để tạo 1 task từ dictionary.


```{r 02-basics-008}
tsk("iris")
```

### Task API {#tasks-api}

Tất cả thuộc tính và đặc điểm của task có thể được truy vấn sử dụng task's public fields and methods (see `r ref("Task")`).
Method cũng được sử dụng để thay đổi hành động của task

#### Retrieving Data {#tasks-retrieving}

Dữ liệu đã lưu của 1 task có thể lấy trực tiếp từ fields, ví dụ:

```{r 02-basics-009}
task_iris$nrow
task_iris$ncol
```

Thông tin thêm có thể có được từ methods của object, ví dụ:

```{r 02-basics-010}
task_iris$data()
```

Trong `r mlr_pkg("mlr3")` mỗi hàng (observation) có 1 định danh duy nhất.
Định danh này có thể là một `integer` or `character`.
Nó có thể được truyền như arguments với `$data()` method để chọn những dòng cụ thể.

_iris_ task sử dụng integer `row_ids`:

```{r 02-basics-011}
# iris uses integer row_ids
head(task_iris$row_ids)

# retrieve data for rows with ids 1, 51, and 101
task_iris$data(rows = c(1, 51, 101))
```

_mtcars_ task theo cách khác, sử dụng names cho `row_ids`, encoded as `character`:

```{r 02-basics-012}
task_mtcars = tsk("mtcars")
head(task_mtcars$row_ids)

# retrieve data for rows with id "Datsun 710"
task_mtcars$data(rows = "Datsun 710")
```

Chú ý: method `$data()` chỉ cho phép đọc dữ liệu, không cho phép chỉnh sửa nó.

Tương tư, môi cột cũng có 1 định danh hoặc tên.
Những tên này được lưu trong public slots `feature_names` và `target_names`.
Ở đây "target" là biến mà chúng ta muốn dự báo và "feature" là biến predictors.

```{r 02-basics-013}
task_iris$feature_names
task_iris$target_names
```

`row_id`s và column names có thể kết hợp trong khi lựa chọn tập con của dữ liệu:

```{r 02-basics-014}
# retrieve data for rows 1, 51, and 101 and only select column "Species"
task_iris$data(rows = c(1, 51, 101), cols = "Species")
```

Để xuất toàn bộ dữ liệu từ task, đơn giản chỉ cần convert nó thành một `data.table`:

```{r 02-basics-015}
summary(as.data.table(task_iris))
```

#### Roles (Rows and Columns) {#tasks-roles}

Có thể gán vai trò (roles) cho rows và columns.
Những roles ảnh hưởng tới hành vi của task với các hoạt động khác nhau.
Hơn nữa những roles này cũng cấp meta-data bổ sung cho nó.

Ví dụ, xem column roles của _mtcars_ task đã được xây từ trước:

```{r 02-basics-016}
print(task_mtcars$col_roles)
```

Để thêm row names của `mtcars` như một thuộc tính bổ sung, chúng ta thêm chúng thành cột đầu tiên của bảng dữ liệu và tạo lại task.

```{r 02-basics-017}
# with `keep.rownames`, data.table stores the row names in an extra column "rn"
data = as.data.table(mtcars[, 1:3], keep.rownames = TRUE)
task = TaskRegr$new(id = "cars", backend = data, target = "mpg")

# we now have integer row_ids
task$row_ids

# there is a new feature called "rn"
task$feature_names
```

Row names bây giờ thành 1 feature có chưa giá trị được lưu trong cột "rn".
Chúng ta thêm cột này vào đây chỉ với mục đích luyện tập.
Nói chung, không có feature nào có giá trị duy nhất tại mỗi dòng.
Hơn nữa, loại dữ liệu cũng có vấn đề với nhiều thuật toán ML.
Mã định danh có thể hữu ích khi gán nhãn với plots hoặc xác định outliers.
Để sử dụng cột mới chỉ cho mục đích này, chúng ta sẽ thay đổi role của cột "rn" và loại nó ra khỏi active features.


```{r 02-basics-018}
task$feature_names

# working with a list of column vectors
task$col_roles$name = "rn"
task$col_roles$feature = setdiff(task$col_roles$feature, "rn")

# "rn" not listed as feature anymore
task$feature_names

# does also not appear when we access the data anymore
task$data(rows = 1:2)
task$head(2)
```

Thay đổi role không làm thay đổi dữ liệu gốc.
Thay đổi chỉ làm thay đổi view on it.
Dữ liệu không được copy khi dùng code bên trên.
View chỉ được thay đổi tại chỗ, tức là task object bản thân nó được sửa đổi.

Giống như cột, cũng có thể gán role khác nhau cho các hàng.
Hàng có thể có 2 loại roles:

1. Role `use`
Rows thông thường dùng cho việc model fitting (mặc dù chúng cũng có thể sử dụng như tập test khi resampling). Role này được mặc định với hàng

2. Role `validation`
Rows mà không được sử dụng cho việc huấn luyện mô hình.
Rows mà có missing values với biến mục tiêu, khi tạo 1 task được tự động gán thành validation role.

Có vài lý do để giữ vài quan sát để xử lý 1 cách khác biệt

1. Thông thường để xác nhận 1 mô hình cuối cùng là tốt, phải dựa trên mẫu bên ngoài để đánh giá để tránh hiện tượng overfitting.
2. Một vài quan sát có thể không được gán nhãn, ví dụ trong cuộc thi trên [Kaggle](https://www.kaggle.com/).

Những quan sát này có thể không sử dụng cho việc huấn luyện mô hình nhưng có thể sử dụng để có được dự báo.

#### Task Mutators {#tasks-mutators}

Như đã nói ở trên, chỉnh sửa `$col_roles` or `$row_roles` chỉ làm thay đổi view on the data.
Phương pháp tiện dụng `$filter()` lấy tập con dựa trên row ids và `$select()` lấy tập con dựa trên feature names.


```{r 02-basics-019}
task = tsk("iris")
task$select(c("Sepal.Width", "Sepal.Length")) # keep only these features
task$filter(1:3) # keep only these rows
task$head()
```

Trong khi phương pháp đã thảo luận ở trên cho phép lấy tập con thì phương pháp `$rbind()` và `$cbind()` cho phép thêm dòng hoặc cột vào 1 task.
Đương nhiên dữ liệu gốc không thay đổi.
Dòng và cột được thêm chỉ ảnh hưởng tới view of the data.


```{r 02-basics-020}
task$cbind(data.table(foo = letters[1:3])) # add column foo
task$head()
```

### Plotting Tasks {#autoplot-task}

Package `r mlr_pkg("mlr3viz")` cung cấp nhiều phương tiện biểu đồ để thực hiện `r mlr_pkg("mlr3")`.
Loại biểu đồ phụ thuộc vào inherited class, nhưng tất cả biểu đồ được trả vể dưới dạng `r cran_pkg("ggplot2")` objects nên sẽ dễ dàng hiệu chỉnh.

Để biết về cách thực hiện đồ thị cho classification tasks (inheriting from `r ref("TaskClassif")`), see the documentation of `r ref("mlr3viz::autoplot.TaskClassif")`. Dưới đây là một vài ví dụ có ấn tượng:


```{r 02-basics-021, warning = FALSE, message = FALSE}
library(mlr3viz)

# get the pima indians task
task = tsk("pima")

# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))

# default plot: class frequencies
autoplot(task)

# pairs plot (requires package GGally)
autoplot(task, type = "pairs")

# duo plot (requires package GGally)
autoplot(task, type = "duo")
```

Đương nhiên, bạn có thể làm tương tự với regression tasks (inheriting from `r ref("TaskRegr")`) như tài liệu `r ref("mlr3viz::autoplot.TaskRegr")`:

```{r 02-basics-022, warning = FALSE, message = FALSE}
library(mlr3viz)

# get the boston housing task
task = tsk("mtcars")

# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))

# default plot: boxplot of target variable
autoplot(task)

# pairs plot (requires package GGally)
autoplot(task, type = "pairs")
```




## Learners {#learners}

Đối tượng của lớp `r ref("mlr3::Learner")` cung cấp giao diện đồng nhất cho nhiều thuật toán ML phổ biên trong R.
Chúng bao gồm các phương pháp để huấn luyện và dự báo một mô hình cho một `r ref("mlr3::Task")` và cung cấp thông tin meta về learners, như là hyperparameters mà bạn đặt.

Package này chứa tối thiểu thông tin của classification and regression learners để tranh phụ thuộc quá nhiều:

* `r ref("mlr_learners_classif.featureless")`: classification learner không dùng các feature, dự báo này chỉ ra phân nhóm có tần suất nhiều nhất.
* `r ref("mlr_learners_classif.rpart")`: Một LearnerClassif cho cây phân loại được triển khai trong `r cran_pkg("rpart")`. Tham số xval được đặt thành 0 để tiết kiệm thời gian tính toán.
* `r ref("mlr_learners_regr.featureless")`: Regression learner hồi quy không có feature, giá trị dự báo là mean.
* `r ref("mlr_learners_regr.rpart")`: LearnerRegr cho cây hồi quy được triển khai trong `r cran_pkg("rpart")`. Tham số xval được đặt thành 0 để tiết kiệm thời gian tính toán 

vài learners phổ biến được kết nối thông qua `r mlr_pkg("mlr3learners")` package:

* (penalized) linear and logistic regression
* $k$-Nearest Neighbors regression and classification
* Linear and Quadratic Discriminant Analysis
* Naive Bayes
* Support-Vector machines
* Gradient Boosting
* Random Regression Forests and Random Classification Forests
* Kriging

Các learners khác được sưu tập trên GitHub [mlr3learners organization](https://github.com/mlr3learners/), và [wiki](https://github.com/mlr-org/mlr3learners/wiki) của [mlr3learners repository](https://github.com/mlr-org/mlr3learners/).

Cơ sở của mỗi learner là `r ref("Learner")`, cho regression như `r ref("LearnerRegr")` classification là `r ref("LearnerClassif")`.
Ngược lại với `r ref("Task")`, việc tùy chỉnh Learner thường không cần thiết và không cần advanced topic.
Vì vậy, chúng tôi giới thiệu độc giả tới phần \@ref(ext-learner) và tiến hành với tổng quan giao diện đã được thực hiện learners.


### Predefined Learners {#learners-predefined}

Tương tự `r ref("mlr_tasks")`, `r ref("Dictionary")` `r ref("mlr_learners")` có thể được truy vấn với những learners có săn:

```{r 02-basics-023}
library(mlr3learners)
mlr_learners
```

Mỗi learner có thông tin đi kèm như:

* `feature_types`: loại feature mà learner cần giải quyết với.
* `packages`: packages yêu cầu để huấn luyện mô hình với learner và làm dự báo.
* `properties`: thuộc tính và khả năng khác.
Ví dụ, learner có thể xử lý "missings" và tính toán "importance" của features.
Danh sách đầy đủ để tham khảo [regression learners](https://mlr3.mlr-org.com/reference/LearnerRegr.html#construction) và [classification learners](https://mlr3.mlr-org.com/reference/LearnerClassif.html#construction).
* `predict_types`: loại có thể đưa ra dự báo. Ví dụ, một classification learner có thể dự báo labels ("response") hay xác suất ("prob"). Danh sách đầy đủ để tham khảo [mlr3 reference](https://mlr3.mlr-org.com/reference/Learner.html#construction).

Tổng quan về các thuộc tính của learners xem \@ref(list-learners).

Để có learner cụ thể cần sử dụng `id` của nó, được liệt kê dưới `key` trong dictionary:

```{r 02-basics-024}
learner = mlr_learners$get("classif.rpart")
print(learner)
```


Trường `param_set` lưu mô tả về hyperparameters mà learner có, khoảng giá trị, giá trị mặc định, 

```{r 02-basics-025}
learner$param_set
```

Tập giá trị hyperparameter được lưu trong cột `value` của trường `param_set`.
Bạn có thể thay đổi giá trị này bằng việc gán một danh sách các tên cho trường này:

```{r 02-basics-026}
learner$param_set$values = list(cp = 0.01, xval = 0)
learner
```

Chú ý rằng, hoạt động này chỉ viết đè lên các tham số đã có trước đó.
Nếu bạn muốn thêm hay cập nhật hypeparameters, bạn có thể sử dụng `r ref("mlr3misc::insert_named()")`:


```{r 02-basics-027}
learner$param_set$values = mlr3misc::insert_named(
  learner$param_set$values,
  list(cp = 0.02, minsplit = 2)
)
learner
```

Sau cập nhật này `cp` thành `0.02`, `minsplit` thành `2` và giữ nguyên tham số `xval`.

Cách viết khác ngắn gọn hơn `mlr_learners$get()` sử dụng `r ref("lrn()")`.
Hàm này cho phép chỉ rõ hyperparameters và những cài đặt định danh khác khi xây dựng learners 


```{r 02-basics-028}
lrn("classif.rpart", id = "rp", cp = 0.001)
```

Nếu bạn bỏ qua hypeparameters ở đây, tham số mặc định sẽ được thêm vào và thêm tham số sử dụng hàm `r ref("mlr3misc::insert_named()", text = "insert_named()")` như trên.

Thông tin chi tiết hơn về cách tùy chỉnh learners sử dụng mlr3, xem trong phần [extending learners](#ext-learner).

## Train and Predict {#train-predict}

Trong phần này, chúng tôi giải thích cách mà [tasks](#tasks) và [learners](#learners) được sử dụng để huấn luyện mô hình và dự báo với dữ liệu mới. Khái niệm này được minh họa trên suppervised classification sử dụng dữ liệu iris và **rpart** learner (classification tree).

Huấn luyện một [learner](#learners) có nghĩa là fitting một mô hình với dữ liệu đã có.
Sau đó, chúng ta muốn [predict](#predicting) cho quan sát mới.
Những [predictions](#predicting) này sau đó được so sánh với giá trị thực tế để đánh giá chất lượng mô hình.
Tóm lại, mục tiêu của huấn luyện và dự báo là để đánh giá khả năng dự báo của các mô hình khác nhau.

### Creating Task and Learner Objects {#train-predict-objects}

Đầu tiên, tạo các `r mlr_pkg("mlr3")` object từ [task dictionary](#tasks) và [learner dictionary](#learners) tương ứng:

1. The classification [task](#tasks):

```{r 02-basics-029}
task = tsk("sonar")
```

2. A [learner](#learners) for the classification tree:

```{r 02-basics-030}
learner = lrn("classif.rpart")
```

### Setting up the train/test splits of the data {#split-data}

Thông thường việc huấn luyện sẽ thực hiện trên phần lớn quan sát của dữ liệu.
Ở đây sử dụng 80% quan sát để huấn luyện và 20% quan sát còn lại để dự báo.
Để làm như vậy, chúng ta tạo 2 index vectors:

```{r 02-basics-031}
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)
```

### Training the learner {#training}

Trường `model` lưu mô hình được tạo ở bước huấn luyện.
Trước khi `train` method được gọi trên learner object, trường  này bằng `NULL`:

```{r 02-basics-032}
learner$model
```

Tiếp theo, classification tree được huấn luyện sử dụng tập train của iris task, áp dụng `$train()` của `r ref("Learner")`:

```{r 02-basics-033}
learner$train(task, row_ids = train_set)
```

Hoạt động này chỉnh sửa learner tại chỗ.
Chúng ta bây giờ có thể tiếp cận mô hình đã được lưu qua trường `$model`:

```{r 02-basics-034}
print(learner$model)
```

### Predicting {#predicting}

Sau khi mô hình đã được huấn luyện, chúng ta sử dụng phần còn lại của dữ liệu để dự báo.
Nhớ rằng, chúng ta đã chia dữ liệu [initially split the data](#split-data) thành `train_set` và `test_set`.

```{r 02-basics-035}
prediction = learner$predict(task, row_ids = test_set)
print(prediction)
```

Phương pháp dự báo `$predict()` của `r ref("Learner")` trả về một `r ref("Prediction")` object.
Chính xác hơn, là learner classification, một `r ref("LearnerClassif")` trả về một `r ref("PredictionClassif")` object.

Một prediction objects cố định row ids của tập test, nhãn tương ứng của giá trị thật và của giá trị dự báo.
Cách đơn giản nhất để xuất thông tin này là chuyển sang một `data.table()`:

```{r 02-basics-036}
head(as.data.table(prediction))
```

Với bài toán phân loại, bạn cũng có thể xuất confusion matrix:

```{r 02-basics-037}
prediction$confusion
```

### Changing the Predict Type {#predict-type}

Classification learners mặc định dự báo các class label.
Tuy nhiên, nhiều thuật toán cũng cung cấp dự báo label bằng xác suất.
Để chuyển sang phần dự báo bằng xác suất, trường `predict_type` của `r ref("LearnerClassif")` phải chuyển từ `"response"` sang `"prob"`:

```{r 02-basics-038}
learner$predict_type = "prob"

# re-fit the model
learner$train(task, row_ids = train_set)

# rebuild prediction object
prediction = learner$predict(task, row_ids = test_set)
```

Prediction object bây giờ có chứa đồng thời cả xác suất và response của tất cả class labels:

```{r 02-basics-039}
# data.table conversion
head(as.data.table(prediction))

# directly access the predicted labels:
head(prediction$response)

# directly access the matrix of probabilities:
head(prediction$prob)
```

Tương tự dự báo xác suất, nhiều `r ref("LearnerRegr", text = "regression learners")` hỗ trợ xuất sai số chuẩn bằng việc đặt predict type thành `"se"`.

### Plotting Predictions {#autoplot-prediction}

Tương tự [plotting tasks](#autoplot-task), `r mlr_pkg("mlr3viz")` cung cấp một `r ref("ggplot2::autoplot()", text = "autoplot()")` phương pháp.

Tất cả các loại được liệt kê trong page hướng dẫn sử dụng `r ref("autoplot.PredictionClassif()")` hoặc `r ref("autoplot.PredictionClassif()")` tương ứng.

```{r 02-basics-040, message = FALSE, warning = FALSE}
library(mlr3viz)

task = tsk("sonar")
learner = lrn("classif.rpart", predict_type = "prob")
learner$train(task)
prediction = learner$predict(task)
autoplot(prediction)
autoplot(prediction, type = "roc")
```

```{r 02-basics-041, message = FALSE, warning = FALSE}
library(mlr3viz)
library(mlr3learners)
local({ # we do this locally to not overwrite the objects from previous chunks
    task = tsk("mtcars")
    learner = lrn("regr.lm")
    learner$train(task)
    prediction = learner$predict(task)
    autoplot(prediction)
})
```


### Performance assessment {#measure}

Bước cuối cùng của việc mô hình thông thường là đánh giá hiệu quả.
Chất lượng dự báo của một mô hình trong `mlr3` có thể được đánh giá dựa trên các tiêu chí khác nhau.
Khi đánh giá, chúng tôi chọn một thước đo cụ thể để định lượng dự báo.
Việc này thực hiện bằng cách so sánh nhãn dự báo với nhãn thực tế.
Những thước đo có sẵn được lưu trong `r ref("mlr_measures")` hoặc với hàm tiện ích `r ref("msr()")`:

```{r 02-basics-042}
mlr_measures
```

Chúng tôi chọn accuracy (`r ref("mlr_measures_classif.acc", text = "classif.acc")`) và gọi phương thức `$score()` của `r ref("Prediction")` object.

```{r 02-basics-043}
measure = msr("classif.acc")
prediction$score(measure)
```

Chú ý rằng, nếu không có measure nào được chỉ ra, classification mặc định là classification error (`r ref("mlr_measures_classif.ce", text = "classif.ce")`) và regression mặc định là mean squared error (`r ref("mlr_measures_regr.mse", text = "regr.mse")`).

## Resampling {#resampling}

Chiến lược resampling thường được sử dụng để đánh giá hiệu quả của một thuật toán ML.
`mlr3` có sẵn 6 chiến lược [resampling](#resampling):
Cross-validation, Leave-one-out cross validation, Repeated cross-validation, Out-of-bag bootstrap and other variants (e.g. b632), Monte-Carlo cross-validation and Holdout.
Các mục sau đây sẽ cung cấp hướng dẫn cách thiết lập và lựa chọn chiến lược resampling và cách khởi tạo quy trình resampling.

Dưới đây là minh họa biểu đồ của quá trình resampling:

```{r 02-optimization-graphics-38, echo=FALSE}
knitr::include_graphics("images/ml_abstraction.png")
```

### Settings {#resamp-settings}

Trong phần ví dụ này, chúng tôi sử dụng _iris_ task và classification tree (package `r cran_pkg("rpart")`).

```{r 02-basics-044}
task = tsk("iris")
learner = lrn("classif.rpart")
```

Để thực hiện resampling với một tập dữ liệu, đầu tiên, chúng ta cần định nghĩa cách tiếp cận sẽ sử dụng.
Chiến lược resampling của _mlr3_ có thể được truy vấn sử dụng `.$keys()` là một phương thức của `r ref("mlr_resamplings")` dictionary

```{r 02-basics-045}
mlr_resamplings
```

Phương pháp resampling bổ sung trong trường hợp đặc biệt sử dụng packages mở rộng như `r gh_pkg("mlr-org/mlr3spatiotemporal")` cho spatial data (still in development).

Độ phù hợp của mô hình được thực hiện trong chương [train/predict/score](#train-predict) bằng với 1 "holdout", trước tiên hãy xem xét nó.
Chúng ta có thể truy vấn các phần tử từ dictionary `r ref("mlr_resamplings")` via `$get()` hoặc hàm tiện ích (`r ref("rsmp()")`):


```{r 02-basics-046}
resampling = rsmp("holdout")
print(resampling)
```

chú ý rằng, trường `Instantiated` được đặt bằng `FALSE`.
Có nhĩa là chúng ta không thực sự áp dụng chiến lược này cho tập dữ liệu, nhưng vẫn chạy chay (dry-run).
Áp dụng chiến lược cho dữ liệu được thực hiện trong phần tiếp theo [Instantiation](#instantiation).

Mặc định tỷ lệ phân chia quan sát là .66 / .33.
Có 2 cách để thay đổi tỷ lệ:

1. Ghi đè lên giá trị `.$param_set$values` đang dùng trong danh sách tên:


```{r 02-basics-047}
resampling$param_set$values = list(ratio = 0.8)
```

2. Chỉ rõ tham số resampling trong quá trình xây dựng:


```{r 02-basics-048}
rsmp("holdout", ratio = 0.8)
```

### Instantiation {#resampling-inst}

Cho đến nay, chúng ta mới chỉ thiết lập giai đoạn và chọn kịch bản resampling.
Để thực sự thực hiện phân chia dữ liệu, resampling cần một `r ref("Task")`.
Bằng việc gọi phương thức `instantiate()`, dữ liệu được chia thành tập training và test và được lưu vào `r ref("Resampling")` object:

```{r 02-basics-049}
resampling = rsmp("cv", folds = 3L)
resampling$instantiate(task)
resampling$iters
str(resampling$train_set(1))
str(resampling$test_set(1))
```

### Execution {#resampling-exec}

Với một `r ref("Task")`, một `r ref("Learner")` và `r ref("Resampling")` object chúng ta có thể gọi `r ref("resample()")` và tạo một `r ref("ResampleResult")` object.

Trước khi đi vào chi tiết, chúng ta thay đổi resampling thành "3-fold cross-validation" để minh họa tốt hơn những hoạt động nào có thể xảy ra với một `r ref("ResampleResult")`.
Ngoài ra, chúng ta sẽ nói với `r ref("resample()")` để giữ mô hình đã được fitted thông qua đánh dấu `store_models`:


```{r 02-basics-051}
task = tsk("pima")
learner = lrn("classif.rpart", maxdepth = 3, predict_type = "prob")
resampling = rsmp("cv", folds = 3L)

rr = resample(task, learner, resampling, store_models = TRUE)
print(rr)
```

Các hoạt động tiếp theo được hỗ trợ với `r ref("ResampleResult")` objects:

* Tính hiệu quả trung bình:
    ```{r 02-basics-052}
    rr$aggregate(msr("classif.ce"))
    ```

* Xuất hiệu quả của từng vòng lặp resampling:
    ```{r 02-basics-053}
    rr$score(msr("classif.ce"))
    ```

* Kiểm tra cảnh báo hoặc lỗi:
    ```{r 02-basics-054}
    rr$warnings
    rr$errors
    ```

* Xuất và kiểm tra 
    ```{r 02-basics-055}
    rr$resampling
    rr$resampling$iters
    str(rr$resampling$test_set(1))
    str(rr$resampling$train_set(1))
    ```

* Truy xuất [learner](#learners) của một vòng lặp cụ thể và kiểm tra nó:

    ```{r 02-basics-056}
    lrn = rr$learners[[1]]
    lrn$model
    ```
* Xuất kết quả dự báo:
    ```{r 02-basics-057}
    rr$prediction() # all predictions merged into a single Prediction
    rr$predictions()[[1]] # prediction of first resampling iteration
    ```

Chú ý rằng, nếu bạn muốn so sánh nhiều [learners](#learners), bạn nên chắc chắn rằng, mỗi learner hoạt động trên cùng mẫu resampling giống nhau.
Điều này làm giảm khác biệt của hiệu quả ước lượng.

Nếu mục đích của bạn để so sánh sự khác biệt `r ref("Task")`, `r ref("Learner")` hay `r ref("Resampling")`, tốt hơn, bạn nên sử dụng hàm `r ref("benchmark()")`, được đề cập trong phần tiếp theo [next section](#benchmarking).
Về cơ bản `r ref("resample()")` làm đơn giản hóa việc xử lý nhiều cài đặt.
Nếu bạn phát hiện ra điều này chỉ sau khi bạn chạy nhiều `r ref("resample()")`, đừng lo lắng.
Bạn có thể kết hợp nhiều `r ref("ResampleResult")` object vào một `r ref("BenchmarkResult")` (cũng được giải thích trong phần [next section](#benchmarking))

### Custom resampling {#resamp-custom}

Thỉnh thoảng, cần phải thực hiện resampling với mẫu tùy chỉnh.
Bạn làm như vậy vì bạn cần một mô hình cụ thể, đầu tiên xem mở rộng của _mlr3_ packages.
Điều quan trọng là phương pháp lấy mẫu kiểu này chưa được thực hiện.

Nếu phương pháp resampling tùy chỉnh rộng rãi trong lĩnh vực của bạn, bạn nên tích hợp nó vào một trong các phần mở rộng của _mlr3_ packages.

Bạn cũng có thể tạo phần mở rộng package của bạn.

Một ví dụ resampling có thể được tạo sử dụng `"custom"` template.


```{r 02-basics-059}
resampling = rsmp("custom")
resampling$instantiate(task,
  train = list(c(1:10, 51:60, 101:110)),
  test = list(c(11:20, 61:70, 111:120))
)
resampling$iters
resampling$train_set(1)
resampling$test_set(1)
```

### Plotting Resample Results {#autoplot-resampleresult}

Lần nữa, `r mlr_pkg("mlr3viz")` cung cấp một phương pháp `r ref("ggplot2::autoplot()", text = "autoplot()")`.

```{r 02-basics-060}
library(mlr3viz)

autoplot(rr)
autoplot(rr, type = "roc")
```

Tất cả loại plot được liệt kê trong phần hướng dẫn `r ref("autoplot.ResampleResult()")`.

## Benchmarking {#benchmarking}

So sánh performance của các learners khác nhau dựa trên nhiều task và/hoặc nhiều sơ đồ resampling khác nhau là công việc thường xuyên.
Hoạt động này thường gọi là "benchmarking" trong lĩnh vực ML.
`r mlr_pkg("mlr3")` package cung cấp hàm tiện ích `r ref("benchmark()")`.

### Design Creation {#bm-design}

Trong _mlr3_ yêu cầu chúng ta cung cấp một "design" của thử nghiệm benchmark.
Theo "design" chúng ta cơ bản tạo một ma trận các cài đặt bạn muốn thực hiện.
Một "design" bao gồm `r ref("Task")`, `r ref("Learner")` và `r ref("Resampling")`.

Ở đây, chúng ta gọi `r ref("benchmark()")` để thực hiện một thử nghiệm đơn giản với holdout split, một task đơn giản và 2 learners.
Chúng ta sử dụng hàm `r ref("benchmark_grid()")` để tạo một thiết kế toàn diện và khởi tạo chính xác việc resampling:


```{r 02-basics-061}
library(data.table)
design = benchmark_grid(
  tasks = tsk("iris"),
  learners = list(lrn("classif.rpart"), lrn("classif.featureless")),
  resamplings = rsmp("holdout")
)
print(design)
bmr = benchmark(design)
```

Chú ý rằng, holdout splits được tự động khởi tạo cho mỗi dòng của design.
Như kết quả, `rpart` learner sử dụng tập training khác so với `featureless` learner.
Tuy nhiên, để so sánh learners bạn thường muốn learners sử dụng cùng một tập train và tập test.
Để khắc phục vấn đề này, chiến lược resampling cần phải thực hiện thủ công [**manually instantiated**](#resampling-inst) trước khi tạo design.

Giao diện của `r ref("benchmark()")` rất linh hoạt.
Mặc dù, việc tạo ra các bảng design này rất tẻ nhạt.
Qua đó, `r mlr_pkg("mlr3")` cung cấp một hàm tiện ích để nhanh chóng tạo bảng design và khởi tạo chiến lược resampling trong toàn bộ lưới : `r ref("benchmark_grid()")`.


```{r 02-basics-062}
# get some example tasks
tasks = lapply(c("german_credit", "sonar"), tsk)

# get some learners and for all learners ...
# * predict probabilities
# * predict also on the training set
library(mlr3learners)
learners = c("classif.featureless", "classif.rpart", "classif.ranger", "classif.kknn")
learners = lapply(learners, lrn,
  predict_type = "prob", predict_sets = c("train", "test"))

# compare via 3-fold cross validation
resamplings = rsmp("cv", folds = 3)

# create a BenchmarkDesign object
design = benchmark_grid(tasks, learners, resamplings)
print(design)
```

### Execution and Aggregation of Results {#bm-exec}

Sau khi [benchmark design](#bm-design) đã sẵn sàng, chúng ta có thể gọi trực tiếp `r ref("benchmark()")`:

```{r 02-basics-063}
# execute the benchmark
bmr = benchmark(design)
```

Chú ý rằng, chúng tôi không thực hiện ví dụ resampling.
`r ref("benchmark_grid()")` sẽ hướng dẫn đầy đủ công việc đó: Việc thêm các chiến lược resampling sẽ tạo được một lưới đầy đủ.

Sau benchmark, có thể tính toán và tổng hợp performance với phương thức `.$aggregate()`:


```{r 02-basics-064}
# measures:
# * area under the curve (auc) on training
# * area under the curve (auc) on test
measures = list(
  msr("classif.auc", id = "auc_train", predict_sets = "train"),
  msr("classif.auc", id = "auc_test")
)
bmr$aggregate(measures)
```

Sau đó, chúng ta có thể có bước tổng hợp kết quả xa hơn.
Ví dụ, chúng ta có thể quan tâm learner nào có thể thực hiện tốt nhất các tasks trong cùng 1 lúc.
Tổng hợp một các đơn giản performances với trung bình thường không phải là phương pháp thống kê tốt.
Thay vào đó, chúng ta tính hạng thống kê (rank statistic) cho mỗi learner theo nhóm task.
Sau đó tính ranks nhóm theo learner để có được tổng hợp.
Vì AUC phải tính theo giá trị lớn nhất, chúng ta nhân với $-1$ để có được learner tốt nhất với rank = 1.


```{r 02-basics-065}
tab = bmr$aggregate(measures)
ranks = tab[, .(learner_id, rank_train = rank(-auc_train), rank_test = rank(-auc_test)), by = task_id]
print(ranks)

ranks[, .(mrank_train = mean(rank_train), mrank_test = mean(rank_test)), by = learner_id][order(mrank_test)]
```

Không ngạc nhiên khi learner featureless hiệu quả kém nhất.

### Plotting Benchmark Results {#autoplot-benchmarkresult}

Tương tự để plot [tasks](#autoplot-task), [predictions](#autoplot-prediction) hay [resample results](#autoplot-resampleresult), `r mlr_pkg("mlr3viz")` cũng cung cấp một phương pháp`r ref("ggplot2::autoplot()", text = "autoplot()")` cho kết quả benchmark.

```{r 02-basics-066}
library(mlr3viz)
library(ggplot2)

autoplot(bmr) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Chúng ta cũng có thể plot ROC curves.
Để làm vậy, chúng ta cần filter `r ref("BenchmarkResult")` để chỉ chứa một `r ref("Task")`:

```{r}
autoplot(bmr$clone()$filter(task_id = "german_credit"), type = "roc")
```

Tất cả các loại được liệt kê trong trang `r ref("autoplot.BenchmarkResult()")`.

### Extracting ResampleResults {#bm-resamp}

A `r ref("BenchmarkResult")` object is essentially a collection of multiple `r ref("ResampleResult")` objects.
As these are stored in a column of the aggregated `data.table()`, we can easily extract them:


```{r 02-basics-067}
tab = bmr$aggregate(measures)
rr = tab[task_id == "sonar" & learner_id == "classif.ranger"]$resample_result[[1]]
print(rr)
```

We can now investigate this resampling and even single resampling iterations using one of the approach shown in [the previous section](#bm-exec):

```{r 02-basics-068}
measure = msr("classif.auc")
rr$aggregate(measure)

# get the iteration with worst AUC
perf = rr$score(measure)
i = which.min(perf$classif.auc)

# get the corresponding learner and train set
print(rr$learners[[i]])
head(rr$resampling$train_set(i))
```

### Converting and Merging ResampleResults

It is also possible to cast a single `r ref("ResampleResult")` to a `r ref("BenchmarkResult")` using the converter `r ref("as_benchmark_result()")`.

```{r}
task = tsk("iris")
resampling = rsmp("holdout")$instantiate(task)

rr1 = resample(task, lrn("classif.rpart"), resampling)
rr2 = resample(task, lrn("classif.featureless"), resampling)

# Cast both ResampleResults to BenchmarkResults
bmr1 = as_benchmark_result(rr1)
bmr2 = as_benchmark_result(rr2)

# Merge 2nd BMR into the first BMR
bmr1$combine(bmr2)

bmr1
```


## Binary classification {#binary}

Classification problems with a target variable containing only two classes are called "binary".
For such binary target variables, you can specify the *positive class* within the `r ref("TaskClassif", text = "classification task")` object during task creation.
If not explicitly set during construction, the positive class defaults to the first level of the target variable.

```{r 02-basics-069}
# during construction
data("Sonar", package = "mlbench")
task = TaskClassif$new(id = "Sonar", Sonar, target = "Class", positive = "R")

# switch positive class to level 'M'
task$positive = "M"
```

### ROC Curve and Thresholds {#binary-roc}

ROC Analysis, which stands for "receiver operating characteristics", is a subfield of machine learning which studies the evaluation of binary prediction systems.
We saw earlier that one can retrieve the confusion matrix of a `r ref("Prediction")` by accessing the `$confusion` field:

```{r 02-basics-070}
learner = lrn("classif.rpart", predict_type = "prob")
pred = learner$train(task)$predict(task)
C = pred$confusion
print(C)
```

The confusion matrix contains the counts of correct and incorrect class assignments, grouped by class labels.
The columns illustrate the true (observed) labels and the rows display the predicted labels.
The positive is always the first row or column in the confusion matrix.
Thus, the element in $C_{11}$ is the number of times our model predicted the positive class and was right about it.
Analogously, the element in $C_{22}$ is the number of times our model predicted the negative class and was also right about it.
The elements on the diagonal are called True Positives (TP) and True Negatives (TN).
The element $C_{12}$ is the number of times we falsely predicted a positive label, and is called False Positives (FP).
The element $C_{21}$ is called False Negatives (FN).

We can now normalize in rows and columns of the confusion matrix to derive several informative metrics:

* **True Positive Rate (TPR)**: How many of the true positives did we predict as positive?
* **True Negative Rate (TNR)**: How many of the true negatives did we predict as negative?
* **Positive Predictive Value PPV**: If we predict positive how likely is it a true positive?
* **Negative Predictive Value NPV**: If we predict negative how likely is it a true negative?


```{r 02-basics-071, echo = FALSE, out.width="98%"}
knitr::include_graphics("images/confusion_matrix(wikipedia).png")
```

Source: [Wikipedia](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers)

It is difficult to achieve a high TPR and low FPR in conjunction, so one uses them for constructing the ROC Curve.
We characterize a classifier by its TPR and FPR values and plot them in a coordinate system.
The best classifier lies on the top-left corner.
The worst classifier lies at the diagonal.
<!-- FIXME Why is the best classifier on the top-left? The argument here only shows that classifiers at the diagonal are inferior but there is no argument in place, illustrating why the other (top left) classifiers are superior. -->
Classifiers lying on the diagonal produce random labels (with different proportions).
If each positive $x$ will be randomly classified with 25\% as "positive", we get a TPR of 0.25.
If we assign each negative $x$ randomly to "positive" we get a FPR of 0.25.
In practice, we should never obtain a classifier below the diagonal, as inverting the predicted labels will result in a reflection at the diagonal.
<!-- FIXME Why is that reflection bad as such ? One sentence to elaborate would add here-->

A scoring classifier is a model which produces scores or probabilities, instead of discrete labels.
Nearly all modern classifiers can do that.
Thresholding flexibly converts measured probabilities to labels.
Predict $1$ (positive class) if $\hat{f}(x) > \tau$ else predict $0$.
Normally, one could use $\tau = 0.5$ to convert probabilities to labels, but for imbalanced or cost-sensitive situations another threshold could be more suitable.
After thresholding, any metric defined on labels can be used.

For `mlr3` prediction objects, the ROC curve can easily be created with `r mlr_pkg("mlr3viz")` which relies on the `r cran_pkg("precrec")` to calculate and plot ROC curves:


```{r 02-basics-072}
# TPR vs FPR / Sensitivity vs (1 - Specificity)
ggplot2::autoplot(pred, type = "roc")

# Precision vs Recall
ggplot2::autoplot(pred, type = "prc")
```


### Threshold Tuning

<!--
When we are interested in class labels based on scores or probabilities, we can set the classification threshold according to our target performance measure.
This threshold however can also be **tuned**, since the optimal threshold might differ for different (custom) measures or in situations like const-sensitive classification.

This can be also done with `mlr3`.
-->
