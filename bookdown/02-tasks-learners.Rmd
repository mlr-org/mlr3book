# Tasks & Learners

Tasks and learners are two essential building blocks that are required to execute any machine-learning experiment.

A **task** wraps the data and store additional information about it.

**Learners** store information about the algorithms that should be used in the experiment.

## Tasks {#tasks}

**Tasks** are objects that include the data set and additional meta information about a machine-learning problem.
This could be the name of the target variable for supervised problems or whether the data set belongs to a specific community of datasets (e.g. a _spatial_ or _survival_ dataset).
This information can be used at different points of the workflow to account for specific characteristics of these dataset types.

### Task Types

To create a task from a `r ref("data.frame()")` or `r ref("data.table()")` object, the task type needs to be selected:

* **Classification Task**: Target column is labels (stored as `character()`/`factor()`) with only few distinct values.
  <br>$\Rightarrow$ `r ref("mlr3::TaskClassif")`
* **Regression Task**: Target column is numeric (stored as `integer()`/`double()`).
  <br>$\Rightarrow$ `r ref("mlr3::TaskRegr")`
* **Survival Task**: Target is the (right-censored) time to event.
  <br>$\Rightarrow$ `r ref("mlr3survival::TaskSurv")` in add-on package `r mlr_pkg("mlr3surival")`
* **Ordinal Regression Task**: Target is ordinal.
  <br>$\Rightarrow$ `r ref("mlr3ordinal::TaskOrdinal")` in add-on package `r mlr_pkg("mlr3ordinal")`
* **Cluster Task**: You don't have a target but want to identify similarities in the feature space.
  <br>$\Rightarrow$ Not yet implemented
* **Spatial Task**: The observations come with spatio-temporal information (e.g. coordinates).
  <br>$\Rightarrow$ Not yet implemented in add-on package `r mlr_pkg("mlr3spatiotemporal")`

### Task Creation

Let's assume we want to create a simple regression task using the `mtcars` data set from the package `datasets` to predict the column `"mpg"` (miles per gallon).
For this showcase we only take the first two features to keep the output in the following examples compact.

```{r 02-tasks-learners-001}
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
```

Next, we create the task by providing the following information:

1. `id`: Identifier for the task, used in plots and summaries.
2. `backend`: Here, we simply provide the dataset. It is internally converted to a `r ref("DataBackendDataTable")`.
   For more fine-grain control over how the data is stored internally, we could also construct a `r ref("DataBackend")` manually.
3. `target`: Column name of the target column for the regression problem.

```{r 02-tasks-learners-002}
task_mtcars = TaskRegr$new(id = "cars", backend = data, target = "mpg")
print(task_mtcars)
```

The `print()` method gives a short summary of the task: It has `r task_mtcars$nrow` observations, `r task_mtcars$ncol` columns of which `r length(task_mtcars$feature_names)` columns are features.

We can also print the task using the `r mlr_pkg("mlr3viz")` package:
```{r 02-tasks-learners-003}
library(mlr3viz)
autoplot(task_mtcars, type = "pairs")
```

### Predefined tasks

`mlr3` ships with some predefined machine-learning tasks.
These are stored in a R6 `r ref("Dictionary")`, which is a simple key-value storage named `mlr3::mlr_tasks`.
If we simply print it out, we see that is has `r length(mlr_tasks$keys())` entries:

```{r 02-tasks-learners-004}
mlr_tasks
```

We can obtain a summarizing overview of all stored tasks by converting the dictionary to a `data.table()` object

```{r 02-tasks-learners-005}
as.data.table(mlr_tasks)
```

To create a **task** from the dictionary (think of it as a book shelf), we use the `$get()` method from the `mlr_tasks` class and assign it to a new object.

For example, if we would like to use the [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) for classification:

```{r 02-tasks-learners-006}
task_iris = mlr_tasks$get("iris")
print(task_iris)
```

### Task API

All **task** properties and characteristics can be queried using the task's public member values and methods (see `r ref("Task")`).

```{r 02-tasks-learners-007}
task_iris = mlr_tasks$get("iris")
```

- Member values: Values stored in the object that can be queried by the user

```{r 02-tasks-learners-008}
# public member values
task_iris$nrow
task_iris$ncol
```

- Member methods: Functions from the object that can accept arguments and return information stored in the object

```{r 02-tasks-learners-009}
# public member methods
task_iris$head(n = 3)
```

#### Retrieve Data

In `mlr3`, each row (observation) has a unique identifier which can be either `integer` or `character`.
These can be used to select specific rows.

The _iris_ dataset uses integer `row_ids`:

```{r 02-tasks-learners-010}
# iris uses integer row_ids
head(task_iris$row_ids)

# retrieve data for rows with ids 1, 51, and 101
task_iris$data(rows = c(1, 51, 101))
```

While the _mtcars_ dataset uses names for its `row_ids`, encoded as `character`:

```{r 02-tasks-learners-011}
head(task_mtcars$row_ids)

# retrieve data for rows with id "Datsun 710"
task_mtcars$data(rows = "Datsun 710")
```

Note that the method `$data()` is only an accessor and does not modify the underlying data/task.

Analogously, each column has an identifier, which is often just called "column name".
These are stored in the public slots `feature_names` and `target_names`.
Here "target" refers to the response variable and "feature" to the predictor variables of the task.

```{r 02-tasks-learners-012}
task_iris$feature_names
task_iris$target_names
```

The `row_id` names and the "column names" can be combined for subsetting:

```{r 02-tasks-learners-013}
# retrieve data for rows 1, 51, and 101 and only select column "Species"
task_iris$data(rows = c(1, 51, 101), cols = "Species")
```

To extract the complete dataset from the task, we need to convert the task to a `data.table`:

```{r 02-tasks-learners-014}
summary(as.data.table(task_iris))
```

#### Roles (Rows and Columns)

It is possible to assign a special meanings (aka "roles") to (subsets of) rows and columns.

For example, the previously constructed _mtcars_ task has the following column roles:

```{r 02-tasks-learners-015}
print(task_mtcars$col_roles)
```

Now, we want the original `rownames()` of `mtcars` to be a regular feature column.
Thus, we first preprocess the `data.frame` and then re-create the task.

```{r 02-tasks-learners-016}
library("data.table")
# with `keep.rownames`, data.table stores the row names in an extra column "rn"
data = as.data.table(mtcars[, 1:3], keep.rownames = TRUE)
task = TaskRegr$new(id = "cars", backend = data, target = "mpg")

# we now have integer row_ids
task$row_ids

# there is a new "feature" called "rn"
task$feature_names
```

The column "rn" is now a regular feature.
As this is a unique string column, most machine-learning algorithms will have problems to process this feature without some kind of preprocessing.
However, we still might want to carry `rn` around for different reasons.
For example, we can use the row names in plots or to associate outliers with the row names.
This being said, we need to change the role of the row names column `rn` and remove it from the set of active features.

```{r 02-tasks-learners-017}
task$feature_names
task$set_col_role("rn", new_roles = "label")

# "rn" not listed as feature any more
task$feature_names

# also vanished from "data" and "head"
task$data(rows = 1:2)
task$head(2)
```

Note that no copies of the underlying data is inflicted by this operation.
By changing roles, only the view on the data is changed, not the data itself.

Just like columns, it is also possible to assign different roles to rows.
Rows can have two different roles:

1. Role `"use"`:
   Rows that are generally available for model fitting (although they may also be used as test set in resampling).
   This is the default role.
2. Role `"validation"`:
   Rows that are held back (see below).
   Rows which have missing values in the target column upon task creation are automatically moved to the validation set.

There are several reasons to hold some observations back or treat them differently:

1. It is often good practice to validate the final model on an external validation set to uncover possible overfitting.
1. Some observations may be unlabeled, e.g. in data mining cups or [Kaggle](https://www.kaggle.com/) competitions.
   These observations cannot be used for training a model, but you can still predict labels.

#### Task Mutators

Task methods `.$set_col_role()` and `.$set_row_role()` change the view on the data and can be used to subset the task.
For convenience, method `.$filter()` subsets the task based on row ids, and `.$select()` subsets the task based on feature names.
All these operations only change the view on the data, without creating a copy of it, but modify the task in-place.

```{r 02-tasks-learners-018}
task = mlr_tasks$get("iris")
task$select(c("Sepal.Width", "Sepal.Length")) # keep only these features
task$filter(1:3) # keep only these rows
task$head()
```

Additionally, methods `.$rbind()` and `.$cbind()` allow to add extra rows and columns to a task, respectively.
Method `.$replace_features()` is a convenience wrapper around `.$select()` and `.$cbind()`.
Again, the original data set stored in the original `mlr3::DataBackend` is not altered in any way.

```{r 02-tasks-learners-019}
task$cbind(data.table(foo = letters[1:3])) # add column foo
task$head()
```

## Learners {#learners}

Objects of class `mlr3::Learner` provide a unified interface to many popular machine-learning algorithms in R.
They consist of methods to train and predict on a `mlr3::Task`, and additionally provide meta information about the algorithms.

The package ships with only a rather minimal set of classification and regression learners, more are implemented in the [mlr3learners](https://mlr3learners.mlr-org.com) package.
Furthermore, [mlr3learners](https://mlr3learners.mlr-org.com) has some documentation on creating custom learners.

### Predefined Learners

Similar to `mlr3::mlr_tasks`, the `mlr3misc::Dictionary` `mlr3::mlr_learners` can be queried for available learners:

```{r 02-tasks-learners-020}
mlr_learners
as.data.table(mlr_learners)
```

As listed in the output, each learner comes with the following information:

* `feature_types`: what kind of features can be processed.
* `packages`: which packages are required to run `train()` and `predict()`.
* `properties`: additional properties and capabilities. For example, a learner has the property "missings" if it is able to handle missing values, and "importance" if it is possible to extract feature importance values.
* `predict_types`: what predict types are possible. For example, a classification learner can predict labels ("response") or probabilities ("prob").

To extract a specific learner, use the corresponding `"id"`:

```{r 02-tasks-learners-021}
learner = mlr_learners$get("classif.rpart")
print(learner)
```

In the output we see that all information from the previous table is also accessible via public slots (`id`, `feature_types`, `packages`, `properties`, `predict_types`).
Additionally, `predict_type` returns the currently selected predict type of the learner.

Slot `param_set` stores a description of hyperparameter settings:

```{r 02-tasks-learners-022}
learner$param_set
```

The set of hyperparameter values is stored inside the parameter set in the `values` slot.
By assigning a named list to this slot, we change the active hyperparameters of the learner:

```{r 02-tasks-learners-023}
learner$param_set$values = list(cp = 0.01)
learner
```

The slot `model` stores the result of the training step.
As we have not yet trained a model, this slot is `NULL`:

```{r 02-tasks-learners-024}
learner$model
```
